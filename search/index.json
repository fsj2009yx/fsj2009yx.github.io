[{"content":"图论\r图的定义\r在数据结构中，图（Graph） 是一种由**节点（Node）和边（Edge）**组成的非线性结构。\n图是一种较线性表和树更加复杂的数据结构。在图形结构中，结点之间的关系可以是任意的，图中任意两个数据元素之间都可能相关。\n节点（Vertex，简称 V）：图中的每个点称为一个节点。\n边（Edge，简称 E）：连接两个节点之间的线称为边。\n一个图通常表示为： G = (V, E) 其中：\n$V$ 是节点（顶点）的集合。 $E$ 是边的集合，每条边都是节点之间的连接。 图的分类\r连通\r在图论中，连通（connected）指的是图中任意两个顶点之间都存在路径相连。如果一个图是连通的，意味着从任何一个顶点出发都可以到达其他所有顶点。\n连通性的分类：\n无向图： 如果图是连通的，称为连通图；如果存在顶点之间没有路径相连，称为不连通图。 有向图： 强连通（strongly connected）：如果图中任意两个顶点 u 和 v 都有路径从 u 到 v 和从 v 到 u，则称该图为强连通图。 弱连通（weakly connected）：如果将有向图中的所有边视为无向边后是连通的，则称该图为弱连通图。 网\r边权重（Edge Weight）： 是一种在图中边上附加的信息，通常用于表示从一个节点到另一个节点之间的某种度量关系\n度、入度和出度\r度：节点的度（Degree） 是指与该节点直接相连的边的数量。\n对于有向图，需要考虑入度和出度：\n入度：指有向边指向该节点的数量。\n出度：指有向边从该节点指向其他节点的数量。\n回路\r在图论中，回路（或环）是指从一个节点出发，通过一系列边返回到该节点的路径。回路的特点是：\n起点和终点相同：回路的起始节点和结束节点是同一个。 边的序列：路径中的每一条边都必须是图中的边。 节点不重复：在简单图中，除了起始和结束节点外，路径中的其他节点不能重复。 欧拉路径||欧拉回路\rC++ 图论算法之欧拉路径、欧拉回路算法（一笔画完）_欧拉路径问题-CSDN博客\n[欧拉图，欧拉通路，欧拉回路，Hierholzer算法详解-CSDN博客](https://blog.csdn.net/EQUINOX1/article/details/140912802?ops_request_misc=%7B%22request%5Fid%22%3A%2261B0E8FE-3939-4B09-8FAA-87DF416CC17D%22%2C%22scm%22%3A%2220140713.130102334..%22%7D\u0026request_id=61B0E8FE-3939-4B09-8FAA-87DF416CC17D\u0026biz_id=0\u0026utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-140912802-null-null.142^v100^pc_search_result_base8\u0026utm_term=Hierholzer 算法\u0026amp;spm=1018.2226.3001.4187)\n欧拉回路判别：\n无向图：\n存在欧拉通路的充要条件： 非零度顶点是连通的 恰有 2 个奇度顶点 存在欧拉回路的充要条件： 非零度顶点是连通的 顶点的度数都是偶数 有向图：\n存在欧拉通路的充要条件： 非零度顶点是弱连通的 至多一个顶点的出度与入度之差为 1 至多一个顶点的入度与出度之差为 1 其他顶点的入度和出度相等 存在欧拉回路的充要条件： 非零度顶点是强连通的 每个顶点的入度和出度相等 Hierholzer 算法（寻找欧拉回路或欧拉路径）\rHierholzer算法也称逐步插入回路法，是一个非常简单且容易理解的算法。\n一般使用邻接表存储图，便于寻找入度和出度，以及遵循字典序规则\n算法流程： 根据无向图/有向图，要找的是欧拉通路/欧拉路径，选择起始结点u 遍历 u 的出边 (u, v) 删掉 (u, v) 递归进 v，做同样操作 回溯时，将边(u, v) 加入答案数组 最终得到的 ans 就是欧拉路径的逆序，因为我们是在回溯后才加边的，所以是逆序\n时间复杂度: O(M)，M为图中边数\n欧拉路径起点选择：\n在 Hierholzer 算法中，**DFS 的起点（即欧拉路径的起点）**选择取决于图的性质，具体如下：\n1. 有向图\n起点选择：应选择出度大于入度的顶点（如果存在）。通常，这个顶点是唯一的，且出度比入度多 1（如果存在两个以上，则欧拉路径不存在） 如果不存在这样的顶点，可以选择任意出度大于 0 的顶点。 2. 无向图\n起点选择：应选择度为奇数的顶点（如果存在）。如果没有奇数度的顶点，选择任意一个顶点即可。 如果图是连通的，则从任意一个有边的顶点开始也是有效的。 连通分量\r连通分量（connected component）是指在一个图中，任意两个顶点都可以通过路径相连的最大子图。在无向图中，每个连通分量都是一个连通图，而在有向图中，可以定义强连通分量，其中每个分量中的任意两个顶点都可以相互到达。\n连通分量的特性：\n无向图：一个连通分量包含至少一个顶点，并且与图中其他顶点没有连接。 有向图：强连通分量的每个顶点可以通过路径到达其他顶点。 计算连通分量的方法通常使用深度优先搜索（DFS）或广度优先搜索（BFS）\n极大强连通子图\r极大强连通子图（maximal strongly connected subgraph）是在有向图中，任意两个顶点之间都存在路径相连的子图，并且无法再通过添加其他顶点而扩展这个子图。也就是说，极大强连通子图是强连通分量的一个实例。\n特点：\n强连通性：在极大强连通子图中，任意两个顶点 u 和 v 都存在从 u 到 v的路径和从 v 到 u 的路径 极大性：如果尝试添加任何其他顶点，子图将不再保持强连通性 在有向图中，所有极大强连通子图的集合构成了图的强连通分量。常用的方法来寻找这些子图包括 Kosaraju 算法和 Tarjan 算法。\n图的存储\r图的存储有多种方式，如邻接矩阵、邻接表（常用）、十字链表、邻接多重表、边集数组 等\n着重讲解邻接矩阵和邻接表\n邻接矩阵\r图的邻接矩阵(Adjacency Matrix) 存储方式是用两个数组来表示图。一个一维数组存储图中顶点信息，一个**二维数组(称为邻接矩阵)**存储图中的边或弧的信息\n对于一个有 $n$ 个顶点的图，邻接矩阵是一个 $n \\times n$ 的矩阵 $G$，其中：\n$G[i][j]=1$ 表示从顶点 i 到顶点 j 有一条边（无向图中 $G[i][j]=G[j][i]$）。 $G[i][j]=0$ 表示从顶点 i 到顶点 j 没有边。 如果是带权图，则 $G[i][j]$ 存储的是边的权重（例如 $w_{ij}$），没有边时可能存储为 $\\infty$ 或某个特殊值。 邻接矩阵更适合于稠密图 代码示例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; const int INF = 1e9; // 表示无穷大，用于表示无边（权重无效） const int MAXN = 100; // 最大顶点数 int adjMatrix[MAXN][MAXN]; // 邻接矩阵 // 构建邻接矩阵 void buildGraph(int n, int m, bool isDirected = false) { // 初始化邻接矩阵，所有顶点间默认没有边 for (int i = 0; i \u0026lt; n; ++i) { for (int j = 0; j \u0026lt; n; ++j) { adjMatrix[i][j] = (i == j ? 0 : INF); // 自环为0，其它初始化为无穷大（无边） } } cout \u0026lt;\u0026lt; \u0026#34;请输入 \u0026#34; \u0026lt;\u0026lt; m \u0026lt;\u0026lt; \u0026#34; 条边的信息 (起点 终点 权重):\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; m; ++i) { int u, v, w; cin \u0026gt;\u0026gt; u \u0026gt;\u0026gt; v \u0026gt;\u0026gt; w; // 输入边的信息：起点 u，终点 v，权重 w adjMatrix[u][v] = w; // 设置权重 if (!isDirected) { // 如果是无向图，则对称设置 adjMatrix[v][u] = w; } } } // 打印邻接矩阵 void printMatrix(int n) { cout \u0026lt;\u0026lt; \u0026#34;邻接矩阵如下：\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; n; ++i) { for (int j = 0; j \u0026lt; n; ++j) { if (adjMatrix[i][j] == INF) cout \u0026lt;\u0026lt; \u0026#34;INF \u0026#34;; // 无边输出 INF else cout \u0026lt;\u0026lt; adjMatrix[i][j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; // 有边输出权重 } cout \u0026lt;\u0026lt; endl; } } int main() { int n, m; cout \u0026lt;\u0026lt; \u0026#34;请输入顶点数和边数: \u0026#34;; cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m; // 输入图的顶点数和边数 buildGraph(n, m); // 构建图 printMatrix(n); // 输出邻接矩阵 return 0; } 邻接表\r邻接表是一种基于链表或动态数组的结构，用来表示图中每个顶点的邻接顶点列表。\n每个顶点对应一个链表（或数组），其中存储该顶点的所有邻接点。 对于带权图，链表中的每个邻接点还会附带一个边的权重值。 邻接表更适合于稀疏图 表示形式：\n用一个数组（大小为顶点数）存储每个顶点的链表头指针。 每个链表中的节点表示一个邻接点及其边权。 优点：\n空间复杂度低，为 $O(V+E)$，其中 V 是顶点数，E 是边数，适合稀疏图。 插入和删除边操作较快。 缺点：\n查找两点是否有边的时间复杂度为 $O(\\text{邻接点个数})$ 编程实现比邻接矩阵稍复杂。 代码示例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; // 定义边结构体，用于存储目标顶点和权重 struct Edge { int to; // 目标顶点 int weight; // 边的权重 }; // 邻接表表示为二维向量，外层向量存储每个顶点的边列表 vector\u0026lt;vector\u0026lt;Edge\u0026gt;\u0026gt; adjList; // 邻接表 // 构建邻接表 void buildGraph(int n, int m, bool isDirected = false) { adjList.resize(n); // 初始化邻接表大小为 n 个顶点 cout \u0026lt;\u0026lt; \u0026#34;请输入 \u0026#34; \u0026lt;\u0026lt; m \u0026lt;\u0026lt; \u0026#34; 条边的信息 (起点 终点 权重):\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; m; ++i) { int u, v, w; cin \u0026gt;\u0026gt; u \u0026gt;\u0026gt; v \u0026gt;\u0026gt; w; // 输入边的信息：起点 u，终点 v，权重 w adjList[u].push_back({v, w}); // 将边 (u -\u0026gt; v) 加入到 u 的邻接表中 if (!isDirected) { // 如果是无向图，则对称添加边 (v -\u0026gt; u) adjList[v].push_back({u, w}); } } } // 打印邻接表 void printAdjList(int n) { cout \u0026lt;\u0026lt; \u0026#34;邻接表如下：\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; n; ++i) { cout \u0026lt;\u0026lt; \u0026#34;顶点 \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;: \u0026#34;; for (const auto\u0026amp; edge : adjList[i]) { cout \u0026lt;\u0026lt; \u0026#34;(\u0026#34; \u0026lt;\u0026lt; edge.to \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; edge.weight \u0026lt;\u0026lt; \u0026#34;) \u0026#34;; // 输出目标顶点和权重 } cout \u0026lt;\u0026lt; endl; } } int main() { int n, m; cout \u0026lt;\u0026lt; \u0026#34;请输入顶点数和边数: \u0026#34;; cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m; // 输入图的顶点数和边数 buildGraph(n, m); // 构建图 printAdjList(n); // 输出邻接表 return 0; } 图的遍历\r有DFS和BFS两种遍历方式\nDFS(深度优先搜索)\r代码示例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 void DFS (Graph\u0026lt;T, E\u0026gt;\u0026amp; G, const T\u0026amp; v) {//从顶点v出发对图G进行深度优先遍历的主过程 int i, loc, n = G.NumberOfVertices(); //顶点个数 bool *visited = new bool[n]; //创建辅助数组 for (i = 0; i \u0026lt; n; i++) visited [i] = false;\t//辅助数组visited初始化\tloc = G.getVertexPos(v); DFS (G, loc, visited); //从顶点0开始深度优先搜索 delete [] visited;\t//释放visited } void DFS (Graph\u0026lt;T, E\u0026gt;\u0026amp; G, int v, bool visited[]) { cout \u0026lt;\u0026lt; G.getValue(v) \u0026lt;\u0026lt; \u0026#39; \u0026#39;; //访问顶点v visited[v] = true;\t//作访问标记 int w = G.getFirstNeighbor (v); //第一个邻接顶点 while (w != -1) {\t//若邻接顶点w存在 if ( !visited[w] ) DFS(G, w, visited); //若w未访问过, 递归访问顶点w w = G.getNextNeighbor (v, w); //下一个邻接顶点 } } DFS (Graph\u0026lt;T, E\u0026gt;\u0026amp; G, const T\u0026amp; v)：\n这是主函数，用于从图的某个顶点 v 开始进行深度优先搜索（DFS）。实现细节如下：\n参数说明: Graph\u0026lt;T, E\u0026gt;\u0026amp; G：图的引用，使用模板 T 和 E 来表示顶点和边的类型。 const T\u0026amp; v：开始遍历的顶点。 实现步骤: G.NumberOfVertices() 获取图中顶点数 n。 创建辅助数组 visited，大小为 n，用于标记是否访问过某顶点。 将 visited 初始化为 false。 使用 G.getVertexPos(v) 获取顶点 v 的位置（序号）。 调用递归函数 DFS (G, loc, visited)，从该顶点开始进行递归深度优先遍历。 释放 visited 数组。 DFS (Graph\u0026lt;T, E\u0026gt;\u0026amp; G, int v, bool visited[])：\n这是递归函数，用于实际执行深度优先遍历。\n参数说明: Graph\u0026lt;T, E\u0026gt;\u0026amp; G：图的引用。 int v：当前访问的顶点序号。 bool visited[]：辅助数组，记录每个顶点是否已访问。 实现步骤: cout \u0026lt;\u0026lt; G.getValue(v)：访问当前顶点 v，输出其值。 将 visited[v] 标记为 true，表示已经访问。 使用 G.getFirstNeighbor(v) 获取顶点 v 的第一个邻接顶点序号。 在循环中： 如果邻接顶点存在且未被访问，则递归调用 DFS(G, w, visited) 访问该顶点。 使用 G.getNextNeighbor(v, w) 获取下一个邻接顶点，直到所有邻接顶点被访问完毕。 性能分析\r设图G有n个顶点、e条边。\nDFS对每一条边处理一次，每个顶点访问一次。\n以邻接矩阵作存储结构：处理所有的边需$O(n^2)$的时间 ，故总代价为$O(n^2)$\n以邻接表作存储结构：由于对邻接表中的每个边结点仅检测一次，而边结点共有2e个，所以处理所有边的时间可记为O(e)，故总代价为$O(n+e)$\nBFS(广度优先搜索)\r和树的广度优先遍历原理相似\n代码示例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 void BFS (Graph\u0026lt;T, E\u0026gt;\u0026amp; G, const T\u0026amp; v) { int i, w, n = G.NumberOfVertices(); //图中顶点个数 bool *visited = new bool[n];\tfor (i = 0; i \u0026lt; n; i++) visited[i] = false; int loc = G.getVertexPos (v);\t//取顶点号 cout \u0026lt;\u0026lt; G.getValue (loc) \u0026lt;\u0026lt; \u0026#39; \u0026#39;; //访问顶点v visited[loc] = true; //做已访问标记 Queue\u0026lt;int\u0026gt; Q; Q.EnQueue (loc); //顶点进队列, 实现分层访问 while (!Q.IsEmpty() ) {\t//循环, 访问所有结点 Q.DeQueue (loc); w = G.getFirstNeighbor (loc); //第一个邻接顶点 while (w != -1) {\t//若邻接顶点w存在 if (!visited[w]) {\t//若未访问过 cout \u0026lt;\u0026lt; G.getValue (w) \u0026lt;\u0026lt; \u0026#39; \u0026#39;;\t//访问 visited[w] = true; Q.EnQueue (w); //顶点w进队列 } w = G.getNextNeighbor (loc, w); //找顶点loc的下一个邻接顶点 } }\t//外层循环，判队列空否 delete [] visited; }; 性能分析\r例题\r下图是两者遍历方式的流程：\n最小生成树\r基本概念\r最小生成树 (Minimum Spanning Tree, MST) 的定义：\n在一个无向连通加权图中：\n最小生成树是一个包含图中所有顶点的子图（子树）。 性质： 是一棵树：连通且无环。 包含所有的顶点，且边数为 n-1（其中 n 是顶点的数量）。 权值总和最小：所选边的权值之和最小。 最小生成树需要满足的条件：\n连通性：原图必须是连通图，否则最小生成树不存在，因为无法覆盖所有顶点。 无环性：最小生成树不能形成环，这确保了其是一个树结构。 权值最小：在所有可能的生成树中，最小生成树的边权和是最小的。 Prim算法\r基本概念\rPrim 算法的核心思想是贪心策略： 从一个起点开始，每次选取权值最小且不会形成环的边，把未访问的顶点加入树中，直到把所有顶点都覆盖\n我们以下图作为例子来帮助理解：\n第一次我们以 结点1 作为起点，将它加入到生成树 $MST$ 的顶点集 $V_{MST}$ 中，然后我们找到与结点1相关联的边，即 1-2,1-3-1-4并从中选出权值最小的边即 1-3(1)\n第二次将 结点3 放入到生成树 $MST$ 的顶点集 $V_{MST}$ 中，然后我们找到与结点1，3相关联的边，即在原来的基础上添加了 3-2,3-4,3-5,3-6，并从中选取权值最小的边 3-6(4)\n依次类推下去，每次选取与顶点集 $V_{MST}$ 中的顶点相连的边中权值最小的一条，并将相连的顶点放入顶点集 $V_{MST}$ 中\n代码实现\r要实现Prim算法，我们需要借助构建小根堆来实现每次选出权值最小的边和顶点：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // Prim最小生成树（使用最小堆） T primMST() { vector\u0026lt;bool\u0026gt; inMST(V, false); // 记录是否已经加入MST vector\u0026lt;T\u0026gt; key(V, numeric_limits\u0026lt;T\u0026gt;::max()); // 存储到MST的最小权值边 key[0] = 0; // 起始点的权值设为0 T totalWeight = 0; // 最小堆，存储pair\u0026lt;权值, 顶点\u0026gt; priority_queue\u0026lt;pair\u0026lt;T, int\u0026gt;, vector\u0026lt;pair\u0026lt;T, int\u0026gt;\u0026gt;, greater\u0026lt;\u0026gt;\u0026gt; pq; pq.emplace(0, 0); // 初始顶点 while (!pq.empty()) { auto [weight, u] = pq.top(); pq.pop(); if (inMST[u]) continue; // 如果顶点u已在MST中，跳过 inMST[u] = true; totalWeight += weight; // 加入MST总权值 // 遍历顶点u的所有邻居 for (auto \u0026amp;[neighbor, edgeWeight] : adjList[u]) { if (!inMST[neighbor] \u0026amp;\u0026amp; edgeWeight \u0026lt; key[neighbor]) { key[neighbor] = edgeWeight; // 更新最小权值 pq.emplace(key[neighbor], neighbor); // 插入最小堆 } } } return totalWeight; } 代码解释：\n初始化变量：\nvector\u0026lt;bool\u0026gt; inMST(V, false)用于标记顶点是否在 MST 中\nvector\u0026lt;T\u0026gt; key(V, numeric_limits\u0026lt;T\u0026gt;::max())用于存储当前生成树到每个顶点的最小边权值，其中每个顶点的初始边权值被设置为最大值 numeric_limits\u0026lt;T\u0026gt;::max()，这样可以保证在后续操作中找到更小的边权值时会被更新\n循环构建MST：\npriority_queue\u0026lt;pair\u0026lt;T, int\u0026gt;, vector\u0026lt;pair\u0026lt;T, int\u0026gt;\u0026gt;, greater\u0026lt;\u0026gt;\u0026gt; pq;是一种快速构建小根堆的方式\nwhile (!pq.empty())操作是为了每次从最小堆中取出当前权值最小的边\nfor (auto \u0026amp;[neighbor, edgeWeight] : adjList[u])用于对当前顶点 u 的邻居进行遍历：\nadjList 是邻接表的数据结构，每个 u 的邻居都存储在这个表中 检查是否可以通过更小的边权值到达邻居 neighbor。如果neighbor还没有加入生成树并且边权值 edgeWeight 小于当前存储的 key[neighbor]： 更新 key[neighbor] 将新的边权值和目标顶点重新插入到最小堆 pq。 返回总权值：\n当最小堆为空时，所有顶点都已经加入生成树。\n返回总权值 totalWeight，即最小生成树中所有边的权值之和。\nKruskal算法\r基本概念\r可以利用伪代码更好的理解算法：\n代码实现\r实现Kruskal算法的核心在于选取的边是否会和已选择的边构成回路，为此我们需要设计判断回路是否存在的算法\n推荐使用并查集1实现回路的判断：\n首先将$V(G)$分为n个等价类，每个等价类包括一个顶点 然后以权值的大小为顺序处理各条边，如果某条边连接两个不同等价类的顶点，则这条边被添加到MST（选取的边与前面选取的边不构成回路），两个等价类被合并为一个 反复执行此过程，直到只剩下一个等价类 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 const int MAXN = 1000; struct Edge { int u, v, weight; // 按权重升序排序 bool operator\u0026lt;(const Edge\u0026amp; other) const { return weight \u0026lt; other.weight; } }; int parent[MAXN]; //记录每个节点的父节点 int rankArr[MAXN]; //用于记录树的深度（即秩），并帮助进行高效的合并操作 // 并查集初始化 void init(int V) { for (int i = 0; i \u0026lt; V; ++i) { parent[i] = i; rankArr[i] = 0; } } // 查找节点x所在连通分量的根节点，同时进行路径压缩 int find(int x) { if (parent[x] != x) parent[x] = find(parent[x]); // 路径压缩 return parent[x]; } // 合并两个节点所在连通分量 void unionSets(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX != rootY) { if (rankArr[rootX] \u0026lt; rankArr[rootY]) swap(rootX, rootY); parent[rootY] = rootX; if (rankArr[rootX] == rankArr[rootY]) rankArr[rootX]++; } } // 使用Kruskal算法构建最小生成树 int kruskal(int V, vector\u0026lt;Edge\u0026gt;\u0026amp; edges) { init(V); int mstWeight = 0; int edgeCount = 0; sort(edges.begin(), edges.end()); // 按边权重升序排序 for (const auto\u0026amp; edge : edges) { if (find(edge.u) != find(edge.v)) { unionSets(edge.u, edge.v); mstWeight += edge.weight; edgeCount++; if (edgeCount == V - 1) // 如果生成树边数达到V-1，则完成构建 break; } } if (edgeCount \u0026lt; V - 1) return -1; // 图不连通，无法构建生成树 return mstWeight; } int main() { int V = 4; // 节点数量 vector\u0026lt;Edge\u0026gt; edges = { {0, 1, 1}, {1, 2, 2}, {2, 3, 3}, {0, 3, 4} }; int mstWeight = kruskal(V, edges); if (mstWeight != -1) cout \u0026lt;\u0026lt; \u0026#34;Minimum Spanning Tree Weight: \u0026#34; \u0026lt;\u0026lt; mstWeight \u0026lt;\u0026lt; endl; else cout \u0026lt;\u0026lt; \u0026#34;Graph is not connected.\u0026#34; \u0026lt;\u0026lt; endl; return 0; } 性能分析\r最短路径\r定义：从源点到终点所经过的边上的权值之和（简称距离）为最小的路径\n注意：最短路径与最小生成树不同，路径上不一定包含n个顶点\nDijkstra算法\r基本概念\rDijkstra是一种非负权值单源最短路径的算法，意思就是所有边的权值都是非负数\n代码实现\r分为邻接矩阵和邻接表两种版本\n基于邻接矩阵的存储方式\r代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #define INF std::numeric_limits\u0026lt;int\u0026gt;::max() void dijkstra(int V, int adj[100][100], int src) { int dist[100]; bool visited[100] = {false}; for (int i = 0; i \u0026lt; V; ++i) dist[i] = INF; dist[src] = 0; for (int i = 0; i \u0026lt; V; ++i) { int min_dist = INF, u = -1; for (int j = 0; j \u0026lt; V; ++j) { if (!visited[j] \u0026amp;\u0026amp; dist[j] \u0026lt; min_dist) { min_dist = dist[j]; u = j; } } if (u == -1) return; // 所有节点都已经访问过了 visited[u] = true; for (int v = 0; v \u0026lt; V; ++v) { if (adj[u][v] != INF \u0026amp;\u0026amp; dist[u] != INF \u0026amp;\u0026amp; dist[u] + adj[u][v] \u0026lt; dist[v]) { dist[v] = dist[u] + adj[u][v]; } } } // 输出结果 std::cout \u0026lt;\u0026lt; \u0026#34;Vertex \\t Distance from Source\u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; V; ++i) std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34; \\t\\t \u0026#34; \u0026lt;\u0026lt; dist[i] \u0026lt;\u0026lt; std::endl; } int main() { int V = 5; int adj[100][100]; // 初始化邻接矩阵 for (int i = 0; i \u0026lt; V; ++i) for (int j = 0; j \u0026lt; V; ++j) adj[i][j] = (i == j) ? 0 : INF; adj[0][1] = 10; adj[0][3] = 30; adj[1][2] = 50; adj[2][3] = 10; adj[3][4] = 2; int src = 0; dijkstra(V, adj, src); return 0; } 代码解释：\n邻接矩阵定义：\n使用一个二维数组 adj 来存储节点之间的边权重。\n如果没有边，则将 adj[u][v] 设置为正无穷 (INF)。\nadj[i][j] 表示从节点 i 到节点 j 之间边的权重。\n初始化距离数组：\n1 2 3 for (int i = 0; i \u0026lt; V; ++i) dist[i] = INF; dist[src] = 0; 初始化一个数组 dist，它存储从源节点到其他节点的最短距离。 源节点 src 到自身的距离是 0，其他节点初始化为正无穷。 寻找当前最短路径节点： 1 2 3 4 5 6 7 int min_dist = INF, u = -1; for (int j = 0; j \u0026lt; V; ++j) { if (!visited[j] \u0026amp;\u0026amp; dist[j] \u0026lt; min_dist) { min_dist = dist[j]; u = j; } } 在每轮循环中，从所有未访问的节点中找到当前具有最短距离的节点 u。 使用 visited 数组标记已访问的节点。 更新邻接节点的距离： 1 2 3 4 5 for (int v = 0; v \u0026lt; V; ++v) { if (adj[u][v] != INF \u0026amp;\u0026amp; dist[u] != INF \u0026amp;\u0026amp; dist[u] + adj[u][v] \u0026lt; dist[v]) { dist[v] = dist[u] + adj[u][v]; } } 遍历节点 u 的所有邻接节点 v。 如果通过节点 u 到节点 v 的路径更短，则更新 dist[v]。 时间复杂度：\n寻找当前最短节点：每次扫描所有 $V$ 个节点，时间复杂度为 $O(V)$ 更新邻接节点：对每个节点进行一次遍历，时间复杂度也为 $$O(V^2)$$ 总时间复杂度：$O(V^2)$ 基于邻接表的存储方式\r代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #define INF std::numeric_limits\u0026lt;int\u0026gt;::max() using namespace std; struct Edge { int to, weight; }; void dijkstra(int V, vector\u0026lt;Edge\u0026gt; adj[100], int src) { int dist[100]; fill(dist, dist + V, INF); dist[src] = 0; priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt;, vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;, greater\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;\u0026gt; pq; pq.push({0, src}); while (!pq.empty()) { int curr_dist = pq.top().first; int u = pq.top().second; pq.pop(); if (curr_dist \u0026gt; dist[u]) continue; for (const auto \u0026amp;edge : adj[u]) { int v = edge.to; int weight = edge.weight; if (dist[u] != INF \u0026amp;\u0026amp; dist[u] + weight \u0026lt; dist[v]) { dist[v] = dist[u] + weight; pq.push({dist[v], v}); } } } cout \u0026lt;\u0026lt; \u0026#34;Vertex \\t Distance from Source\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; V; ++i) cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34; \\t\\t \u0026#34; \u0026lt;\u0026lt; dist[i] \u0026lt;\u0026lt; endl; } int main() { int V = 5; vector\u0026lt;Edge\u0026gt; adj[100]; adj[0].push_back({1, 10}); adj[0].push_back({3, 30}); adj[1].push_back({2, 50}); adj[2].push_back({3, 10}); adj[3].push_back({4, 2}); int src = 0; dijkstra(V, adj, src); return 0; } 代码解释：\n邻接表定义： 使用一个向量数组 adj，每个节点存储一个 Edge 列表。 每个 Edge 包含目标节点 to 和边的权重 weight。 更节省空间，适合稀疏图。 初始化距离数组： 1 2 3 int dist[100]; fill(dist, dist + V, INF); dist[src] = 0; 初始化 dist 数组，将所有节点的距离设置为正无穷。 源节点 src 到自身的距离为 0。 使用优先队列（Priority Queue）： 1 2 priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt;, vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;, greater\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;\u0026gt; pq; pq.push({0, src}); 使用一个**优先队列（最小堆）**来维护当前距离源节点最近的节点。 每次从队列中取出当前具有最短距离的节点进行访问。 更新邻接节点的距离： 1 2 3 4 5 6 7 8 9 for (const auto \u0026amp;edge : adj[u]) { int v = edge.to; int weight = edge.weight; if (dist[u] != INF \u0026amp;\u0026amp; dist[u] + weight \u0026lt; dist[v]) { dist[v] = dist[u] + weight; pq.push({dist[v], v}); } } 遍历节点 u 的邻接列表。 如果当前路径更短，就更新目标节点 v 的最短距离。 并将更新后的节点重新加入队列中。 时间复杂度：\n使用优先队列（最小堆）维护节点：取出最短节点的时间复杂度为 $O(log V)$。 更新邻接节点：对于每条边的访问时间为 $O(E log V)$。 总体时间复杂度：$O((V + E) log V)$。 Floyd算法\r基本概念\rDijkstra算法用于求某一个起点到其他顶点的最短路径，而Floyd算法的目的是求出每一对顶点之间的最短路径\n算法过程：\n从任意一条单边路径开始。左右两点之间的距离是边的权，如果两点之间没有边相连，则权为无穷大。 对于每一对顶点u和v，看是否存在一个顶点w使得从u到w再到v比已知的路径更短，如果更短，则更新它。 代码示例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 template \u0026lt;class T, class E\u0026gt; void Floyd (Graph\u0026lt;T, E\u0026gt;\u0026amp; G, E a[][], int path[][]) { //a[i][j]是顶点i和j之间的最短路径长度。path[i][j]是相应路径上顶点j的前一顶点的顶点号 int i,j,k,n=G.NumberOfVertices(); for (i = 0; i \u0026lt; n; i++) //矩阵a与path初始化 for (j = 0; j \u0026lt; n; j++) { a[i][j] = G.getWeight (i, j); if (i != j \u0026amp;\u0026amp; a[i][j] \u0026lt; maxValue) path[i][j] = i; else path[i][j] = -1；} for (k = 0; k \u0026lt; n; k++) //针对每一个k, 产生a(k)及path(k) for (i = 0; i \u0026lt; n; i++) for (j = 0; j \u0026lt; n; j++) if (a[i][k] + a[k][j] \u0026lt; a[i][j]) { a[i][j] = a[i][k] + a[k][j]; path[i][j] = path[k][j]; } //缩短路径长度, 绕过 k 到 j }; 代码解释：\nGraph\u0026lt;T, E\u0026gt; G：表示图。 a：二维数组表示顶点之间的边权重。 path：二维数组，表示路径信息。 初始化矩阵 a 和 path： 1 2 3 4 5 6 7 8 9 10 11 int i, j, k, n = G.NumberOfVertices(); for (i = 0; i \u0026lt; n; i++) { for (j = 0; j \u0026lt; n; j++) { a[i][j] = G.getWeight(i, j); // 初始化a[i][j]为图中当前从i到j的边权重。 if (i != j \u0026amp;\u0026amp; a[i][j] \u0026lt; maxValue) { path[i][j] = i; // 如果存在边并且不是自环，则设置路径中j的前一个节点为i。 } else { path[i][j] = -1; // 否则，路径不可达。 } } } 作用：\n遍历所有顶点对 (i, j)。 使用 G.getWeight(i, j) 获取当前从顶点 i 到顶点 j 的边权重。 如果存在边并且 i 不是等于 j 且边权重小于 maxValue，就将 path[i][j] 设置为 i。 如果没有边或是自环，则将 path[i][j] 设置为 -1。 Floyd-Warshall 主循环 1 2 3 4 5 6 7 8 9 10 for (k = 0; k \u0026lt; n; k++) { for (i = 0; i \u0026lt; n; i++) { for (j = 0; j \u0026lt; n; j++) { if (a[i][k] + a[k][j] \u0026lt; a[i][j]) { a[i][j] = a[i][k] + a[k][j]; // 如果通过节点k可以缩短路径，则更新路径长度。 path[i][j] = path[k][j]; // 同时更新路径中j的前一个节点。 } } } } 详细解释：\n外层循环 (for (k = 0; k \u0026lt; n; k++))：\n每次选择一个中间节点 k。 目标是检查是否可以通过中间节点 k 来缩短任意两个节点 (i, j) 之间的路径。 中间两层循环 (for (i = 0; i \u0026lt; n; i++) 和 for (j = 0; j \u0026lt; n; j++))：\n遍历所有顶点对 (i, j)。 检查是否通过中间节点 k 可以更新路径： 1 if (a[i][k] + a[k][j] \u0026lt; a[i][j]) 如果 a[i][k] 到 a[k][j] 的路径长度之和小于当前路径长度 a[i][j]，说明可以通过中间节点 k 来缩短路径。\n如果满足条件：\n更新路径长度：\n1 a[i][j] = a[i][k] + a[k][j]; 更新路径数组 path ：\n1 path[i][j] = path[k][j]; 拓扑问题\r拓扑排序\r基本概念\r拓扑排序是一个先决条件问题：将一个有向无环图中所有顶点在不违反先决条件关系的前提下排成线性序列的过程称为拓扑排序\n拓扑序列：对于有向无环图G=(V, E)，所有顶点组成的线性序列如果满足:\n若在有向无环图G中从顶点$V_i$到$V_j$有一条路径，则在序列中顶点$V_i$必在顶点$V_j$之前 则该线性序列可称作一个拓扑序列\n注意：\n拓扑序列不唯一 任何有向无环图的所有顶点都可以排在一个拓扑序列里 代码实现\r代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 template \u0026lt;class T, class E\u0026gt; void TopologicalSort (Graph\u0026lt;T, E\u0026gt;\u0026amp; G) { int i, j, w, v, top = -1; //入度为零顶点的栈初始化 int n = G.NumberOfVertices(); //网络中顶点个数 int *count = new int[n]; //入度数组兼入度为零顶点栈 for (i = 0; i \u0026lt; n; i++) count[i] = 0; cin \u0026gt;\u0026gt; i \u0026gt;\u0026gt; j; //输入一条边(i, j) while (i \u0026gt; -1 \u0026amp;\u0026amp; i \u0026lt; n \u0026amp;\u0026amp; j \u0026gt; -1 \u0026amp;\u0026amp; j \u0026lt; n) { G.insertEdge (i, j); count[j]++; cin \u0026gt;\u0026gt; i \u0026gt;\u0026gt; j; } for (i = 0; i \u0026lt; n; i++) //检查网络所有顶点 if (count[i] == 0) { count[i] = top; top = i; } //入度为零的顶点进栈 for (i = 0; i \u0026lt; n; i++) //期望输出n个顶点 if (top == -1) { //中途栈空,转出 cout \u0026lt;\u0026lt; “网络中有回路！\u0026#34; \u0026lt;\u0026lt; endl;\treturn; } else { //继续拓扑排序 v = top; top = count[top]; //退栈v cout \u0026lt;\u0026lt; G.getValue(v) \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; endl; //输出 w = G.GetFirstNeighbor(v); while (w != -1) { //扫描顶点v的出边表 count[w]--; //邻接顶点入度减一 if (!count[w]) //入度减至零,进栈 { count[w] = top; top = w; } w = G.GetNextNeighbor (v, w); } //一个顶点输出后，调整其邻接顶点入度 } //输出一个顶点，继续for循环 }; 性能分析\rAOV网络\r如果用有向图表示一个工程：\n顶点表示活动/子工程，\n有向边\u0026lt;$V_i$, $V_j$\u0026gt;表示活动 $V_i$ 必须先于活动 $Vj$ 进行。\n顶点表示活动的网，即为 AOV 网\nAOV网络中不能出现回路\nAOE网络\rAOV网络属于顶点表示活动的网，而AOE网络属于边表示活动的网\n用带权有向无环图表示一个工程：\n顶点表示事件/状态 有向边\u0026lt;$V_i$, $V_j$\u0026gt;活动，对应的权值表示活动持续时间 边表示活动的网，即 AOE 网\nAOE网和AOV网比较\r关键路径\r图解：什么是关键路径？-CSDN博客\n代码实现\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 template \u0026lt;class T, class E\u0026gt;void CriticalPath(graph\u0026lt;T, E\u0026gt;\u0026amp; G) {\t//求AOE网的各关键活动 int i, j, k; E Ae, Al, w; int n = G.NumberOfVertices(); E *Ve = new E[n]; E *Vl = new E[n]; for (i = 0; i \u0026lt; n; i++) Ve[i] = 0; for (i = 0; i \u0026lt; n; i++) { //正向计算Ve[] j = G.getFirstNeighbor(i); while (j != -1) { w= G.getWeight (i, j); if (Ve[i]+w \u0026gt; Ve[j]) Ve[j] = Ve[i]+w; j = G.getNextNeighbor(i, j); } } 并查集（Union-Find）是一种数据结构，用于处理一些不交集的合并及查询问题\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-12-14T17:48:35+08:00","permalink":"https://fsj2009yx.github.io/posts/post_4562331710674/","title":"图论"},{"content":"样本与抽样分布\r基本概念\r在概率论中，我们所研究的随机变量，它的分布都是假设已知的，在这一前提下去研究它的性质、特点和规律性，例如求出它的数字特征，讨论随机变量函数的分布，介绍常用的各种分布等。\n在数理统计中，我们研究的随机变量，它的分布是未知的，人们是通过对所研究的随机变量进行重复独立的观察，得到许多观察值对这些数据进行分析，从而对所研究的随机变量的分布作出种种推断的。\n总体\r在数理统计中，我们将研究对象的全体称为总体，组成总体的每个元素称为个体。\n**容量:**总体中所包含的个体的个数 **有限总体:**容量为有限的总体 **无限总体:**容量为无限的总体 如引例中某建筑材料厂生产的空心砖就是一个总体，每一块砖就是个体。\n总体中的每一个个体是随机试验的一个观察值，也是某一随机变量$X$的值，所以一个总体就对应一个$X$\n对总体的研究就是对一个随机变量X的研究，X的分布函数和数字特征也就是总体的分布函数和数字特征\n样本\r总体分布一般是未知的。按一定规则从总体中抽取若干个个体进行观察试验，获取有关总体的信息。这一过程叫做抽样，所抽取的部分个体称为样本。样本包含的个体数目叫做样本容量。\n随机抽取样本的方法必须满足如下要求:\n随机性：即总体中每个个体被抽到的可能性相同 独立性：即样本中每个个体的取值不影响其他个体的取值（每抽取一个个体都不会改变总体的分布） 具有随机性和独立性的抽样方法叫做简单随机抽样，样本选定后得到一组具体数值称为样本观察值或样本值\n注意:由于抽样的随机性与独立性，因此容量为 n 的样本具有两重性:在抽取之前是n个相互独立且与总体同分布的随机变量 $X_1,X_2,\u0026hellip;,X_n$，或n维随机变量 $(x_1,x_2,\u0026hellip;,x_n)$ 。样本一旦选定就是一组样本观察值，它也是n维随机变量 $(X_1,X_2,..,X_n)$ 的一组取值\n比如：假设一个装有红球、蓝球、绿球的箱子，从中随机抽取 n=3n = 3n=3 个球：\n抽取之前：每个球的颜色是未知的，用 $X_1, X_2, X_3$ 表示，它们是相互独立且颜色分布与箱子一致的随机变量。 抽取之后：假设结果是 红、蓝、绿，那么样本观察值为 (红,蓝,绿)，这是 $(X_1, X_2, X_3)$ 的一次具体取值。 常见的抽样方法可分为放回抽样和不放回抽样：\n对于有限总体，采用放回抽样就能得到简单随机样本，但放回抽样使用起来不方便，当个体的总数N比要得到的样本的容量n大得多时，在实际中可将不放回抽样近似地当作放回抽样来处理 至于无限总体，因抽取一个个体不影响它分布，所以总是不放回抽样，例如，在生产过程中，每隔一定时间抽取一个个体，抽取n个就得到一个简单随机样本，实验室中的记录，水文、气象等观察资料都是样本，试制新产品得到的样品的质量指标，也常被认为是样本 计算公式\r经验分布函数\r定义\r设$(x_1,x_2…x_n,)$是总体$X$的一个容量为n的样本值,先将$x_1,x_2,…x_n$按自小到大的次序排列,并重新编号,设为$x_{(1)}\u0026lt;x_{(2)}\u0026lt;\u0026hellip;\u0026lt;x_{(n)}$\n则经验分布函数$F(x)$为：\n性质\r$F_n(x)$为不减的左连续函数 $lim_{x→∞}F_n(X)=0$，$lim_{x→∞}F_n(x)=1$ 因此，$F_n(x)$是一个分布函数，被称为总体X的经验分布函数或样本分布函数。\n$F_n(x)$的值表示n次独立重复试验中，事件“$X≤x$”发生的频率\n格利纹科定理\r定理：设总体X的分布函数为$F(x)$，样本分布函数为$F_n(x)$。则当$n→∞$时$F_n(x)$以概率1收敛于分布函数$F(x)$\n样本数字特征\r统计量\r设$X_1,X_2,\u0026hellip;,X_n$是来自总体X的一个样本，而$g(X_1,X_2,\u0026hellip;,X_n)$是$X_1,X_2,\u0026hellip;,X_n$的函数\n如果函数$g$中不包含任何的未知参数，则$g$为统计量。\n由于$X_1,X_2,\u0026hellip;,X_n$都是随机变量，而统计量是随机变量的函数，所以统计量是随机变量，并且将统计量的分布称作抽样分布。\n样本均值及定理\r定义：\n定理：\n\u0026ldquo;样本均值“的期望：$E(\\overline X)=μ$ ”样本均值“的方差：$D(\\overline X)=σ^2/n$ 注意：样本均值本身只是一个随机变量，不同的样本会有不同的样本均值\n对样本均值计算期望才能得到对总体均值的估计\n样本方差及定理\r定义：\n定理：\n样本均方差$S^2$计算公式：$S^2=\\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\overline X)^2$ == $S^2=\\frac{1}{n-1}(\\sum_{i=1}^nX_i^2-n\\overline X^2) $ (注意这里的分母为n-1) 样本方差的期望等于总体方差（$E(S^2)=\\sigma^2$） 样本矩\r定义：\n样本k阶原点矩和样本k阶中心矩\n定理：\n样本一阶原点矩即样本均值($A_1=\\overline X$) 样本二阶中心矩不是样本方差：因为样本方差的计算公式为 $S^2=\\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\overline X)^2$ ，而样本二阶中心矩为$S^2=\\frac{1}{n}\\sum_{i=1}^n(X_i-\\overline X)^2$，分母不同 样本二阶中心矩和总体方差的关系：$E((S_n)^2)=\\frac{n-1}{n}\\sigma^2$ 公式总结\r四种统计量及其分布\r上侧分位数和双侧分位数\r伽马函数\r卡方分布及其性质\r定义\r卡方分布是多个独立的标准正态随机变量的平方和的分布。\n自由度：指卡方分布中独立正态变量的个数 (如下方的$X_1,X_2,\u0026hellip;,X_n$，总共n个独立正态变量，自由度就为n)\n服从卡方分布的注意点：\n$X_1,X_2,\u0026hellip;,X_n$都相互独立，则自由度为n 都服从正态分布$N(0,1)$ $X=\\sum_{i=1}^nX_i^2$ 卡方分布的图像\r性质\r注意：对于卡方分布的自由度n过大的情况：\n例题\r下面我们用卡方分布的性质解题：\n由题，(1)可直接查表得到答案，(2)可以通过正态分布上α百分位点的公式计算\nT统计量及其分布\rt分布的定义\rt分布是由一个标准正态分布随机变量和一个独立的 $\\chi^2$ 分布随机变量的比值定义的\n服从t分布的要点：\nt分布针对两个随机变量，正态分布X和卡方分布Y X和Y相互独立 t分布的图像\rt分布的性质\rt分布的分位点：\nT统计量的定义及其性质\rt分布和T统计量的区别在于：一个X是正态分布，一个X是正态分布总体的样本\n例题\rF统计量及其分布\r定义\r服从F统计量的要点：\nX与Y相互独立 X与Y分别服从卡方分布，自由度可以不同 F分布的图像\r性质\r对于自由度为$n_1,n_2$的两个F分布的关系，有：\n$$F\\sim F(n1,n2)=\\frac{1}{F\\sim F(n_2,n_1)}$$\n例题\r(1)题直接查表，(2)题需要通过公式$F_{1-α}(n_1,n_2)=\\frac{1}{F_α(n_2,n_1)}$转换\n综合例题\r该题求卡方分布，先将每一个随机变量转成标准正态分布，再利用卡方分布的性质解答\n题目中，$X_1+X_2+X_3$和$X_4+X_5+X_6$分别是一个正态分布独立变量 (看做成一个整体)，于是总体自由度为2\n","date":"2024-12-13T16:45:43+08:00","permalink":"https://fsj2009yx.github.io/posts/post_501199214716/","title":"样本与抽样分布"},{"content":"参数估计\r参数估计问题的定义及其理解\r矩估计法\r矩估计法（Method of Moments, MoM），也称为数字特征法，是一种常用的参数估计方法。其基本思想是利用样本矩来估计总体矩，即用样本的统计量代替总体的相应统计量进行估计。\n样本矩和总体矩\r样本矩：\n对于一组样本 $X_1, X_2, \u0026hellip;, X_n$，样本的第 $k$ 阶矩定义为：\n$m_k = \\frac{1}{n} \\sum_{i=1}^n X_i^k$\n总体矩：\n对于一个随机变量 X，其理论上的 k 阶矩定义为：\n$$μ_k = E(X^k)$$ 下面我们举例说明：\n假设我们有一个正态分布随机变量 $X \\sim N(\\mu, \\sigma^2)$，我们想要估计正态分布的参数 $μ$（均值）和 $\\sigma^2$（方差）。\n**目标：**我们通过样本来估计以下参数：\n均值 $μ$ 方差 $\\sigma^2$ 一、样本矩计算\n假设我们有一个样本：$X = { X_1, X_2, \u0026hellip;, X_n }$\n样本均值 $\\hat{\\mu}$： $$\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i$$ 样本方差 $S^2$： $$S^2 = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\hat{\\mu})^2$$二、总体矩计算\n这里我们设总体矩为正态分布，则理论均值为$μ$，理论方差为$ \\sigma^2$;\n将样本矩和总体矩等式：有$\\hat{\\mu}=μ$，$S^2≈σ^2$\n因此，矩估计法中：\n使用样本均值 $\\hat{\\mu}$ 作为总体均值 $μ$ 的估计。 使用样本方差 $S^2$ 作为总体方差 $\\sigma^2$ 的估计。 例题\r由于样本均值=总体均值，我们令$A_1=\\frac{1}{n}\\sum_{i=1}^nX_i=\\overline X=E(X)$\n并且使用$E(X)=\\int_{-∞}^{+∞}xf(x)dx$求出总体期望，构建等式\n极大似然估计法\r极大似然法是在总体类型已知条件下使用的一种参数估计方法\n基本思路：根据样本的具体情况来选择未知参数0的估计量，使样本发生的可能性最大。\n似然函数\r分为离散型和连续性\n离散型总体\r设总体X的分布为$P{X=x}=p(x,\\theta)$，样本$X_1,X_2\u0026hellip;X_n$是来自X的样本，样本观察值为x1,x2\u0026hellip;xn\n则($X_1,X_2\u0026hellip;X_n$)的联合分布律为：\n$$P\\{X_1=x_1,X_2=X_2,...,X_n=x_n\\}=\\prod^n_{i=1}p\\{x_i;\\theta\\}$$1\n它是未知参数的函数，记作\n$$L(\\theta)=L(x_1,x_2…,x_n;\\theta)=\\prod^n_{i=1}p(x_i;\\theta)$$上面的函数称为样本的似然函数\n连续性总体\r设总体X的概率密度$f(x;\\theta)$，此时样本的似然函数为\n$$L(\\theta)=L(x_1,x_2…,x_n;\\theta)=\\prod^n_{i=1}f(x_i;\\theta)$$最大似然估计值和最大似然估计量\r区别 最大似然估计量 (MLE) 最大似然值 (Likelihood Value) 定义 参数 $θ$ 使得似然函数最大化 使用最大似然估计量代入似然函数 含义 是一个参数的估计值（如 $\\hat{\\theta}$ ） 是似然函数的具体数值 目标 求解参数估计值 在给定参数下计算似然函数的值 L(θ)的最大值求法\r由微积分学知识，若似然函数L(θ)关于θ有连续偏导数，则最大似然估计0 一般可从方程(组)：\n$$\\frac{\\partial L(θ)}{\\partial θ_i}=0，i=1,2,...k$$又因为lnL(θ)和L(θ)同时取得最大值，等式可转换为：\n$$\\frac{\\partial lnL(θ)}{\\partial θ_i}=0，i=1,2,...k$$\n似然函数的性质\r例题\r离散型随机变量求似然函数：\n由题我们知道，有5个样本值，分别为1，2，1，3，1，将这5个样本值进行连乘，得到似然函数L(θ)，解似然函数方程得到最大似然估计值\n接下来是矩估计值的计算：\n步骤 1: 样本矩\n样本数据为 $x_1 = 1, x_2 = 2, x_3 = 1, x_4 = 3, x_5 = 1$，其样本均值为：$\\bar{x} = \\frac{1+2+1+3+1}{5} = \\frac{8}{5} = 1.6$\n步骤 2: 理论矩\n理论均值（总体期望）为：\n$$E[X]=1⋅P(X=1)+2⋅P(X=2)+3⋅P(X=3)$$$$=\u003eE[X] = 1 \\cdot \\theta^2 + 2 \\cdot 2\\theta(1-\\theta) + 3 \\cdot (1-\\theta)^2$$$$=\u003eE[X] = \\theta^2 + 4\\theta(1-\\theta) + 3(1-\\theta)^2$$展开整理：\n$$E[X] = \\theta^2 + 4\\theta - 4\\theta^2 + 3 - 6\\theta + 3\\theta^2$$$$=\u003eE[X] = 3 - 2\\theta$$步骤 3: 矩估计方程\n令理论均值等于样本均值：\n$$3 - 2\\theta = 1.6$$解方程：\n$$2\\theta = 3 - 1.6$$$$=\u003e\\hat{\\theta} =0.7$$因此，矩估计值为：\n$$\\hat\\theta_\\text{MME} = 0.7$$ 连续性随机变量：\n对连续性随机变量使用连乘公式计算\n估计量的评估标准\r对同一参数用不同的方法进行估计可能会得到不同的估计量，那么采用哪种估计量为好，这就涉及到用什么样的标准来评价估计量的问题\n无偏性\r定义\r设$\\hat\\theta=\\hat\\theta(X_1,X_2,\u0026hellip;,X_n)$是未知参数$\\theta$的估计量，如果\n$$E( \\hatθ )=θ$$则称 $\\hat\\theta$ 是 $\\theta$ 的无偏估计量\n记$b_n=E(\\hat\\theta)-\\theta$,称 $b_n$ 为估计量 $\\hat \\theta$ 的偏差\n当$b_n≠0$，称 $\\hat\\theta$ 是 $\\theta$ 的有偏估计\n若 $\\lim_{x \\to \\infty} b_n=0$,称 $\\hat\\theta$ 是 $\\theta$ 的渐近无偏估计\n性质\r不论总体X服从什么分布，当总体的 k 阶矩存在时，样本的 k 阶原点矩 $A_k$ 是总体 k 阶原点矩的无偏估计量。\n特别地，样本均值 $\\overline{X}$ 是总体均值E(X)的无偏估计量。\n(解释：由于样本均值的期望$E(\\overline X)$等于总体均值(第六章性质)，如果样本均值也等于总体均值，则 样本均值是总体均值的无偏估计量)\n有效性\r定义\r无偏估计并不是唯一的，多个无偏估计之中就存在优劣问题。\n我们希望 $\\theta$ 的取值能集中于 $\\theta$ 附近,而且密集的程度越高越好,方差是描述随机变量取值的集中程度的\n因此这里提出所谓**“有效性”**标准：\n例题\r由题，这里两种无偏估计量其实就对应两个样本均值,则求出样本均值的方差并做比较\n一致性与结合性\r定义\r一致性：\n相合性：\n相合性被认为是对估计的一个最基本要求\n如果一个估计量，在样本量不断增大时，它都不能把被估参数估计到任意指定的精度，那么这个估计是很值得怀疑的。通常，不满足相合性要求的估计一般不予考虑。\n证明估计的相合性一般可应用大数定律或直接由定义来证\n例题\r区间估计\r点估计值仅仅是未知参数的一个近似值，近似程度如何?误差范围多大?可信程度又如何?这些问题是点估计无法回答的。而区间估计正好弥补了点估计的这个缺陷\n区间估计要求根据样本给出未知参数的一个范围，并保证参数的真值以指定的较大概率属于这个范围。即以区间的形式给出未知参数的一个范围，同时还给出此区间包含参数真值的可信程度，这种形式的估计称为区间估计\n区间估计的概念\r定义 设总体$X\\sim F(x, \\theta)$，$\\theta $是未知参数,$X_1,X_2,\u0026hellip;,Xn$是来自总体的样本，对于给定值$(0\u0026lt;\\alpha \u0026lt;1)$，如果存在两个统计量$\\hat\\theta_1=\\hat\\theta_1(X_1,X_2,，…,X_i)$和$\\hat\\theta_2=\\hat\\theta_2(X_1,X_2…X_i)$\n如果满足\n$$P\\{\\hat\\theta_1\u003c \\theta \u003c\\hat\\theta_2\\}≥1-a$$则称随机区间$(\\hat\\theta_1,\\hat\\theta_2)$是 $\\theta $ 的置信度为 $1-α$ 的置信区间 1-α为置信水平, $\\hat\\theta_1$ 和 $\\hat\\theta_2$ 分别称为置信下限和置信上限\n评价置信区间好坏标准:\n精度: $\\hat\\theta_2-\\hat \\theta_1$ 越小越好\n**置信度:**越大越好\n对置信区间的解释\r最常出现的对95%置信区间的错误理解：\n在95%置信区间内，有95%的概率包括真实参数 （错误！！）\n在95%置信区下构建的模型，意味着模型参数对于试图近似的函数有95%的概率是真实值的估计值（错误！！）\n正确解释应为：\n95%置信区间，意味着如果你用同样的步骤，去选样本，计算置信区间，那么100次这样的独立过程，有95%的概率你计算出来的区间会包含真实参数值，即大概会有95个置信区间会包含真值。\n对于某一次计算得到的某一个置信区间，其包含真值的概率，我们无法讨论。\n对于未知参数 $\\theta$ 的真值，不能说 $\\theta$ 以 $1-\\alpha $ 的概率落入该随机区间，只能说区间 $(\\hat\\theta_1,\\hat\\theta_2)$ 套住了该参数的真值\n因为$\\theta$ 是一个固定但未知的值，不能将他看作是一个随机变量\n构建置信区间的一般步骤：\n例题\r我们以下图为例：\n正态分布图像如下：\n根据分位点$\\alpha$的大小，我们可以求得X坐标也就是 $z_{\\alpha/2}$ 的大小，进而也就得到了该题中的未知参数 $\\mu$ 的置信区间\n单个正态总体参数的置信区间\r均值的置信区间\r分为方差 $\\sigma^2$ 已知和未知的情况\n方差已知时：(枢轴变量法)\n其中$Z_{\\alpha/2}$和$U_{\\alpha/2}$都是标准正态分布下满足 $P(Z\u0026gt;Z_{α/2})=α/2$ 的分位点\n方差未知时：\n不能选择正态分布构造置信区间，可以选择t分布：\n方差的置信区间\r分为**$μ$已知和未知**的情况\n（已知的情况上面已经讨论过，看未知的情况）\n两个正态总体参数的置信区间\r如果有两个相互独立的正态总体，我们关心的主要是两个总体的均值差和方差比的估计\n设$X\\sim N(μ_1,\\sigma_1^2)，Y\\sim N(μ_2,\\sigma_2^2)$，$X_1,X_2,\u0026hellip;,X_{n1}$ 和 $Y_1,Y_2,\u0026hellip;,Y_{n2}$ 分别是总体 X 和 Y 的样本\n我们有$\\overline X- \\overline Y$是$μ_1-μ_2$的无偏点估计\n$\\sigma_1^2$，$\\sigma_2^2$已知\r由上，由期望和方差的性质，我们易得 $\\overline X-\\overline Y \\sim N(μ_1-μ_2,\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2})$\n两个总体的方差相等，但是方差未知 (即$\\sigma_1^2=\\sigma_2^2=\\sigma^2$，但是$\\sigma^2$未知)\r单侧置信区间\r上面的置信区间都是双向且对称的，也存在置信区间单向的情况\n对单侧置信区间，要分单侧置信下限和单侧置信上限\n图像如下：\n其中绿色部分为置于信区间上限，红色部分为置信区间下限的情况。\n它们的概率都为 $1-\\alpha$\n例题\r总结\r$\\prod$符号表示连乘\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-12-13T16:42:55+08:00","permalink":"https://fsj2009yx.github.io/posts/post_4465171773288/","title":"参数估计"},{"content":"Vue组件基础及特性\r组件注册\r一个 Vue 组件在使用前需要先被**“注册”**，这样 Vue 才能在渲染模板时找到其对应的实现。\n有全局注册和局部注册两种方式\n全局注册\r使用 Vue 应用实例 的 .component() 方法，让组件在当前 Vue 应用中全局可用。\n1 2 3 4 5 6 7 8 9 10 11 12 import { createApp } from \u0026#39;vue\u0026#39; const app = createApp({}) app.component( // 注册的名字 \u0026#39;MyComponent\u0026#39;, // 组件的实现 { /* ... */ } ) 该代码属于main.js的一部分，也就是说可以在main.js中实现全局组件注册。\n如果使用单文件组件，你可以注册被导入的 .vue 文件：\n1 2 3 4 5 6 7 8 import ComponentA from \u0026#39;./components/ComponentA.vue\u0026#39;; import ComponentB from \u0026#39;./components/ComponentB.vue\u0026#39;; import ComponentC from \u0026#39;./components/ComponentC.vue\u0026#39;; app .component(\u0026#39;ComponentA\u0026#39;, ComponentA) .component(\u0026#39;ComponentB\u0026#39;, ComponentB) .component(\u0026#39;ComponentC\u0026#39;, ComponentC) 该代码使用了链式方法调用来快速注册多个全局组件\n全局注册的组件可以在此应用的任意组件的模板中使用\n局部注册\r全局注册有以下几个问题：\n全局注册但并没有被使用的组件无法在生产打包时被自动移除 (也叫**“tree-shaking”**)。如果你全局注册了一个组件，即使它并没有被实际使用，它仍然会出现在打包后的 JS 文件中。\n全局注册在大型项目中使项目的依赖关系变得不那么明确。在父组件中使用子组件时，不太容易定位子组件的实现。和使用过多的全局变量一样，这可能会影响应用长期的可维护性。\n相比之下，局部注册的组件需要在使用它的父组件中显式导入，并且只能在该父组件中使用。它的优点是使组件之间的依赖关系更加明确，并且对 tree-shaking更加友好。\n举例说明：\n1 2 3 4 5 6 7 \u0026lt;script setup\u0026gt; import ComponentA from \u0026#39;./ComponentA.vue\u0026#39; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;ComponentA /\u0026gt; \u0026lt;/template\u0026gt; 在使用 \u0026lt;script setup\u0026gt; 的单文件组件中，导入的组件可以直接在模板中使用，无需注册。局部注册的组件在后代组件中不可用。在这个例子中，ComponentA 注册后仅在当前组件可用，而在任何的子组件或更深层的子组件中都不可用。\nprops、attributes与插槽slots\rprops\r如果我们正在构建一个博客，我们希望所有的博客文章分享相同的视觉布局，但有不同的内容。要实现这样的效果自然必须向组件中传递数据，例如每篇文章标题和内容，这就会使用到 props。\nprops传递\rProps 是一种特别的 attributes（属性），你可以在组件上声明注册。要传递给博客文章组件一个标题，我们必须在组件的 props 列表上声明它。\n1 2 3 4 5 6 7 8 \u0026lt;!-- BlogPost.vue --\u0026gt; \u0026lt;script setup\u0026gt; defineProps([\u0026#39;title\u0026#39;]) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;h4\u0026gt;{{ title }}\u0026lt;/h4\u0026gt; \u0026lt;/template\u0026gt; 代码如上。这里我们使用了宏defineProps()，defineProps 是一个仅 \u0026lt;script setup\u0026gt; 中可用的编译宏命令，并不需要显式地导入。声明的 props 会自动暴露给模板。defineProps 会返回一个对象，其中包含了可以传递给组件的所有 props （比如代码中的[\u0026rsquo;title\u0026rsquo;]）。\n一个组件可以有任意多的 props，默认情况下，所有 prop 都接受任意类型的值。我们可以以类似HTML标签元素attributes的方式传入想要传入的属性值，举例如下：\n1 2 3 \u0026lt;BlogPost title=\u0026#34;My journey with Vue\u0026#34; /\u0026gt; \u0026lt;BlogPost title=\u0026#34;Blogging with Vue\u0026#34; /\u0026gt; \u0026lt;BlogPost title=\u0026#34;Why Vue is so fun\u0026#34; /\u0026gt; 这里title就是一个props,通过对props赋值改变组件模板中的title插值\nProp 名字格式\r如果一个 prop 的名字很长，应使用 camelCase 形式，因为它们是合法的 JavaScript 标识符，可以直接在模板的表达式中使用，也可以避免在作为属性 key 名时必须加上引号：\n1 2 3 defineProps({ greetingMessage: String }) 1 \u0026lt;span\u0026gt;{{ greetingMessage }}\u0026lt;/span\u0026gt; 静态 vs. 动态 Props\r上面的例子属于静态传递props，下面介绍动态传递props\n示例代码如下：\n子组件 (ChildComponent.vue)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Message: {{ message }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Count: {{ count }}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; import { defineProps } from \u0026#39;vue\u0026#39;; defineProps({ message: String, count: Number, }); \u0026lt;/script\u0026gt; 父组件 (app.vue)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;ChildComponent :=\u0026#34;propsData\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; import { ref } from \u0026#39;vue\u0026#39;; import ChildComponent from \u0026#39;./ChildComponent.vue\u0026#39;; // 定义响应式对象 const propsData = ref({ message: \u0026#39;Hello Vue 3!\u0026#39;, count: 42, }); \u0026lt;/script\u0026gt; 该语法使用了v-bind的缩写:将响应式对象propsData与DOM元素的属性绑定，即message和count，从而动态传递属性值，自动更新DOM元素\n所有的 props 都遵循着单向绑定原则，props因父组件的更新而变化，自然地将新的状态向下流往子组件，而不会逆向传递。这避免了子组件意外修改父组件的状态的情况，不然应用的数据流将很容易变得混乱而难以理解。\n透传atrributes\r“透传 attribute”指的是传递给一个组件，却没有被该组件声明为 props 或 emits 的 attribute 或者 v-on 事件监听器。最常见的例子就是 class、style 和 id。\n当一个组件以单个元素为根作渲染时，透传的 attribute 会自动被添加到根元素上。举例来说，假如我们有一个 \u0026lt;MyButton\u0026gt; 组件，它的模板长这样：\n1 2 \u0026lt;!-- \u0026lt;MyButton\u0026gt; 的模板 --\u0026gt; \u0026lt;button\u0026gt;Click Me\u0026lt;/button\u0026gt; 一个父组件使用了这个组件，并且传入了 class：\n1 \u0026lt;MyButton class=\u0026#34;large\u0026#34; /\u0026gt; 最后渲染出的 DOM 结果是：\n1 \u0026lt;button class=\u0026#34;large\u0026#34;\u0026gt;Click Me\u0026lt;/button\u0026gt; 这里，\u0026lt;MyButton\u0026gt; 并没有将 class 声明为一个它所接受的 prop，所以 class 被视作透传 attribute，自动透传到了 \u0026lt;MyButton\u0026gt; 的根元素上。\n如果你不想要一个组件自动地继承 attribute，你可以在组件选项中设置 inheritAttrs: false，示例如下：\n1 2 3 4 5 6 \u0026lt;script setup\u0026gt; defineOptions({ inheritAttrs: false }) // ...setup 逻辑 \u0026lt;/script\u0026gt; 插槽 Slots\r在某些场景中，我们可能想要为子组件传递一些模板片段，让子组件在它们的组件中渲染这些片段。\n举例来说，这里有一个 \u0026lt;FancyButton\u0026gt; 组件，可以像这样使用：\n1 2 3 \u0026lt;FancyButton\u0026gt; Click me! \u0026lt;!-- 插槽内容 --\u0026gt; \u0026lt;/FancyButton\u0026gt; 而 \u0026lt;FancyButton\u0026gt; 的模板是这样的：\n1 2 3 \u0026lt;button class=\u0026#34;fancy-btn\u0026#34;\u0026gt; \u0026lt;slot\u0026gt;\u0026lt;/slot\u0026gt; \u0026lt;!-- 插槽出口 --\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;slot\u0026gt; 元素是一个插槽出口 (slot outlet)，标示了父元素提供的插槽内容 (slot content) 将在哪里被渲染。\n最终渲染出的 DOM 是这样：\n1 \u0026lt;button class=\u0026#34;fancy-btn\u0026#34;\u0026gt;Click me!\u0026lt;/button\u0026gt; 这里，父组件是\u0026lt;button\u0026gt;标签，子组件是FancyButton。我们可以将子组件中的\u0026lt;slot\u0026gt;理解成一个代码模板占位符，而FancyButton就是一个代码模板。父组件可以将任意内容放置在子组件标签之间，这些内容会替换子组件模板中 \u0026lt;slot\u0026gt; 的位置。\n这种方法可以提高组件的复用性，可以将组件插入多个位置，实现了不同位置的不同内容共享相同的模板和样式。\nSlots和Props的比较\rslots和props在功能上有一定的相似性，比如：\n组件间通信：\nProps 和 Slots 都用于父子组件间的数据和内容传递。\n它们都可以让父组件向子组件提供信息。\n灵活性：\nVue 都提供了一定的可复用性和扩展性。\n可以通过传递属性和模板内容，提高组件复用性。\n主要区别：\n特性 Props Slots 目的 主要用于传递数据和属性 主要用于传递模板内容或片段 使用场景 适合配置、状态、参数传递等 适合自定义内容、布局、插槽替换 灵活性 只能传递基本数据（字符串、数字等） 可以传递复杂模板、HTML、组件等 默认值设置 可以在子组件中指定默认属性值 可以在子组件模板中指定默认内容 作用域支持 通常不支持作用域 作用域插槽（Scoped Slots）可访问子组件数据 ","date":"2024-12-10T17:27:43+08:00","permalink":"https://fsj2009yx.github.io/posts/post_18773214774361/","title":"Vue组件基础及特性"},{"content":"群\r半群和独异点\r普通半群\r定义：设S是非空集合，#是S上的二元运算 如果#在S上满足封闭性，可结合性，则称\u0026lt;S,#\u0026gt;是半群\n普通独异点\r定义：设\u0026lt;M.#\u0026gt;是个半群，如果#运算含有幺元1，则称\u0026lt;M.#\u0026gt;是独异点，也就是含幺半群\n简单记忆：含有单位元的半群===独异点\n我们以具体的例子来说明，哪些属于半群哪些属于独异点：\n有以下几个代数结构：\u0026lt;N,+\u0026gt;，\u0026lt;R,×\u0026gt;，\u0026lt;P(E),∩\u0026gt;，\u0026lt;P(E),$\\oplus$\u0026gt;，\u0026lt;R,÷\u0026gt;，\u0026lt;N，-\u0026gt;\n对于\u0026lt;N,+\u0026gt;：“+”运算在自然数集合上是封闭的（1），并且”+“法运算是可结合的（2）， 故其属于半群\n同理，\u0026lt;R,×\u0026gt;，\u0026lt;P(E),∩\u0026gt;，\u0026lt;P(E),$\\oplus$\u0026gt;都属于半群\n而\u0026lt;N,+\u0026gt;的单位元是0，\u0026lt;R,×\u0026gt;的单位元是1，\u0026lt;P(E),∩\u0026gt;、\u0026lt;P(E),$\\oplus$\u0026gt;的单位元分别是E和0； 它们都拥有单位元，所以它们同时也是独异点\n而对于$÷$、$-$ 等运算，它们不满足结合律，故它们不是半群\n例：考察代数结构\u0026lt;$N_6$,$+_6$\u0026gt;，$N_6={0,1,2,3,4,5}$；根据模k加法2的定义，算出该代数结构的运算表如下：\n从表中我们看出：运算是封闭的，通过验证也可以得知$+_6$运算是可结合的，故它属于半群； 又因为表中得知单位元为0，它也是独异点\n可交换半群和可交换独异点\r可交换半群： 设\u0026lt;S,★\u0026gt;是半群，如★是可交换的，则称\u0026lt;S,★\u0026gt;是可交换半群。\n可交换独异点： \u0026lt;M,★\u0026gt;是独异点，如★是可交换的，则称\u0026lt;M,★\u0026gt;是可交换独异点。\n例:\u0026lt;R,+\u0026gt;，\u0026lt;N,ㄨ\u0026gt;，\u0026lt;P(E),∩\u0026gt;，\u0026lt;P(E),$\\oplus$\u0026gt;都是可交换半群，亦是可交换独异点。\n子半群和子独异点\r子半群：\n定义：若\u0026lt;S,★\u0026gt;是个半群，$B\\subseteq S$；如果★在B上封闭，则称\u0026lt;B,★\u0026gt;是\u0026lt;S,★\u0026gt;的子半群。\n例如，\u0026lt;N,+\u0026gt;是\u0026lt;l,+\u0026gt;的子半群\n子独异点：\n定义：\u0026lt;M,*\u0026gt;是个独异点，$B\\subseteq M$，如果★在B上封闭，且单位元$e∈B$，则称\u0026lt;B,★\u0026gt;是\u0026lt;M,★\u0026gt;的子独异点。\n半群和独异点的性质\r定理1：设\u0026lt;M,★\u0026gt;是可交换独异点，A是M中所有幂等元3构成的集合，则\u0026lt;A,★\u0026gt;是\u0026lt;M,★\u0026gt;的子独异点。\n定理的证明如下：\n关键在于任取$a,b∈A$，有（a★b）★(a★b)=a★b,得到a★b同样是幂等元\n群\r群的定义\r设\u0026lt;G,★\u0026gt;是代数系统，如果★运算在G上满足封闭性、可结合性、\u0026lt;G,*\u0026gt;中有单位元且G中的每个元素均可逆，则称\u0026lt;G,★\u0026gt;是群\n如果集合G是有限集，则\u0026lt;G,★\u0026gt;是有限群，反之则为无限群\n简单记忆：若独异点中集合的的每个元素均可逆，则该独异点就是群\n群的性质\r群除了具有封闭、可结合、有单位元、每个元素均可逆这四个性质外，还有一些其它性质\n性质一：群中无零元\r定理：若\u0026lt;G,★\u0026gt;是群，如果|G|4≥2，则G中没有零元\n证明如下：\n性质二：群中的每个元素都是可消去元\r定理：设\u0026lt;G,★\u0026gt;是个群，则对任何 $a,b,c∈G$\n如果有 (1)a★b=a★c 则b=c。 (2)b★a=c★a 则b=c。\n证明如下：\n性质三：群中除了单位元外，没有其他的幂等元\r定理：设\u0026lt;G,★\u0026gt;是群，则G中有且只有单位元是幂等元\n证明如下：\n性质四：群方程有唯一解\r定理：设\u0026lt;G,★\u0026gt;是群，则对任何$a,b∈G$ (1)存在唯一元素x∈G,使得 a★x=b (2)存在唯一元素y∈G,使得y★a=b\n由此性质我们可以知道：若方程a★x=b的解 为$a^{-1}$★b，则方程y★a=b的解为 b★$a^{-1}$\n性质五：有限群表的特征\r定理：若\u0026lt;G,★\u0026gt;是有限群，则G中的每一个元素★在运算表中的每一行（列）都必出现并且只出现一次\n其他定理\r定理：\u0026lt;G,★\u0026gt;是个群，对任何 $a,b∈G$，有\n$(a^{-1})^{-1}=a$ $(a★b)^{-1}= b^{-1}★a^{-1}$ 推论：\u0026lt;G,★\u0026gt;是个群，对任何$a∈G$，有\n$(a^n)^{-1} =(a^{-1})^n$\n群的阶\r定义:设\u0026lt;G,★\u0026gt;是群，如果|G|=n，则称\u0026lt;G,★\u0026gt;是n阶群。\n当 G 所包含的元素个数为有限时，群\u0026lt;G,★\u0026gt;的阶为 G 所包含的元素个数。 当 G 所包含的元素个数为无限时，群\u0026lt;G,★\u0026gt;为无限群。 给出群\u0026lt;{a},★\u0026gt;，\u0026lt;{a,b},★\u0026gt;，\u0026lt;{a,b,c},★\u0026gt;分别是1、2、3 阶群\n假定a是单位元，根据有限群运算表的特征，它们的运算表分别是:\n由运算表我们可以看出：所有的一阶群都同构5，所有的二阶群都同构，所有的三阶群都同构\n由此我们可以得到：同阶的所有群都是同构的\n群中元素的阶\r定义:设\u0026lt;G,★\u0026gt;是群，$a∈G$，使得$a^k$=e6成立的最小正整数 k 称为a的阶，记作|a|=k，称a为k阶元。\n若不存在这样的正整数k，则称a的阶是无限的。比如群\u0026lt;l,+\u0026gt;是一个无限群，只有单位元 0 的阶是1，其余元素的阶都是无限的。\n给出一个示例：\n由题目我们看出，对群中的每个元素做幂运算，得到四个元素的阶分别是1，2，4，4\n定理：设\u0026lt;G,★\u0026gt;是群，$a∈G$且|a|=k。设n是正整数\n当且仅当n是k的整数倍，有$a^n=e$ $|a^{-1}|=|a|$ 幺元：即单位元的意思\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n模k加法：一种对整数进行加法运算后取模的运算。具体操作为：对两个整数进行加法运算，得到结果c；对c进行取模运算，即将c除以k所得的余数即为模k加法运算的结果。假设$N_k$是模k同余关系中的余数等价类，即$N_k={[0][1][2],\u0026hellip;[k-1]}$，那么$N_k$上的模k加法运算$+_k$定义为：任取$x,y\\in N，x +_k y=(x+y)(mod \\ k)$\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n幂等元：如果\u0026lt;G,°\u0026gt;是群,$a∈G$,有$a$是$G$的单位元$\\iff$$a$是幂等元；用语言描述的话，就是在某二元运算下，自身与自身进行运算后，结果仍然是它自身的元素。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n符号$|G|$表示集合$G$的元素个数，也称为该集合的阶（Cardinality）或规模。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n同构：同构通常指的是两个数学结构之间存在一种一一对应的映射关系。在集合论中，如果存在一个双射函数 f:A\u0026ndash;\u0026gt;B，并且 f 保留集合间的结构关系,则集合A和B同构。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这里e代表单位元\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-12-10T12:03:39+08:00","permalink":"https://fsj2009yx.github.io/posts/post_208132376826979/","title":"群论"},{"content":"排序算法\r插入排序\r算法思路\r从第一个元素开始，该元素可以认为已经被排序 取下一个元素tem，从已排序的元素序列从后往前扫描 如果该元素大于tem，则将该元素移到下一位 重复步骤3，直到找到已排序元素中小于等于tem的元素 tem插入到该元素的后面，如果已排序所有元素都大于tem，则将tem插入到下标为0的位置 重复步骤2~5 一句话总结：每次取第$i+1$个元素，依次与前一个元素比较直到找到一个比它小的元素，插入到它的后面\n代码\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 void InsertSort(int* arr, int n) { for (int i = 0; i \u0026lt; n - 1; ++i) { //记录有序序列最后一个元素的下标 int end = i; //待插入的元素 int tem = arr[end + 1]; //单趟排 while (end \u0026gt;= 0) { //比插入的数大就向后移 if (tem \u0026lt; arr[end]) { arr[end + 1] = arr[end]; end--; } //比插入的数小，跳出循环 else { break; } } //tem放到比插入的数小的数的后面 arr[end + 1] = tem; //代码执行到此位置有两种情况: //1.待插入元素找到应插入位置（break跳出循环到此） //2.待插入元素比当前有序序列中的所有元素都小（while循环结束后到此） } } 时间复杂度：最坏情况下为O(N²)，此时待排序列为逆序，或者说接近逆序\n最好情况下为O(N)，此时待排序列为升序，或者说接近升序。\n空间复杂度：O(1)\n希尔排序\r思路：\n先选定一个小于N的gap作为第一增量，然后将所有距离为gap的元素分在同一组，并对每一组的元素进行直接插入排序。然后再取一个比第一增量小的整数作为第二增量，重复上述操作 当增量的大小减到1时，就相当于整个序列被分到一组，进行一次直接插入排序，排序完成。 一句话总结：第一次取gap=n/2，然后距离为gap的两个元素按照大小顺序决定是否交换，然后第二次取gap=gap/2，以此类推，直到gap减小到1，进行一次直接插入排序，排序完成\n如上图所示，在初始位置gap=10/2=5，将距离为5的元素分在同一组，即（8，3）、（9，5）、（1，4）、（7，6）、（2、0），每组内的两个元素比较后依照插入排序更新位置 排序结束后取gap/=2，以相同方法再次排序\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 //希尔排序 void ShellSort(int* arr, int n) { int gap = n; while (gap\u0026gt;1) { //每次对gap折半操作 gap = gap / 2; //单趟排序 for (int i = 0; i \u0026lt; n - gap; ++i) { int end = i; int tem = arr[end + gap]; while (end \u0026gt;= 0) { if (tem \u0026lt; arr[end]) { arr[end + gap] = arr[end]; end -= gap; } else { break; } } arr[end + gap] = tem; } } } 时间复杂度（平均）：O（N^1.3） 空间复杂度：O（1）\n选择排序\r思路： 每次从待排序列中选出一个最小值，然后放在序列的起始位置，直到全部待排数据排完即可。 实际上，我们可以一趟选出两个值，一个最大值一个最小值，然后将其放在序列开头和末尾，这样可以使选择排序的效率快一倍。\n一句话总结：每趟选出一个最小放在前面，一直排到末尾；\n我们可以一趟选出两个值，一个最大值一个最小值，然后将其放在序列开头和末尾，效率更快\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 //选择排序 void swap(int* a, int* b) { int tem = *a; *a = *b; *b = tem; } void SelectSort(int* arr, int n) { //保存参与单趟排序的第一个数和最后一个数的下标 int begin = 0, end = n - 1; while (begin \u0026lt; end) { //保存最大值的下标 int maxi = begin; //保存最小值的下标 int mini = begin; //找出最大值和最小值的下标 for (int i = begin; i \u0026lt;= end; ++i) { if (arr[i] \u0026lt; arr[mini]) { mini = i; } if (arr[i] \u0026gt; arr[maxi]) { maxi = i; } } //最小值放在序列开头 swap(\u0026amp;arr[mini], \u0026amp;arr[begin]); //防止最大的数在begin位置被换走 if (begin == maxi) { maxi = mini; } //最大值放在序列结尾 swap(\u0026amp;arr[maxi], \u0026amp;arr[end]); ++begin; --end; } } 时间复杂度：最坏情况：O(N^2)\n最好情况：O(N^2)\n空间复杂度：O(1)\n计数排序\r计数排序是一种非比较排序，其核心是将序列中的元素作为键存储在额外的数组空间中，而该元素的个数作为值存储在数组空间中，通过遍历该数组排序。\n计数排序的应用场景\r序列中最大值和最小值之间的差值不能过大，这主要是防止建立数组时造成内存的浪费。 序列中存在的元素是整数，因为我们使用的是该元素作为键存储在额外的数组空间中，如果不是整数，不能作为键。 代码\r创建临时数组\r我们先创建一个临时的数组tmp并且该数组的最大下标为原数组中元素的最大值（里面的元素初始化为0）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //先遍历原数组找到最大值 int max = a[0]; for (int i = 1; i \u0026lt; n; i++) { if (max \u0026lt; a[i]) { max = a[i]; } } //动态内存开辟max+1个int空间并初始化为0用calloc int* tmp = (int)calloc(max+1, sizeof(int)); if (tmp == NULL) { perror(\u0026#34;calloc fail!\\n\u0026#34;); return; } 统计次数\r然后遍历一遍原数组，原数组中出现哪个元素就在tmp数组中与该元素数值相同的下标对应的地方进行加加操作来记录该元素出现的次数。\n1 2 3 4 5 //统计次数 for (int i = 0; i \u0026lt; n; i++) { tmp[a[i]]++; } 排序\r最后我们再进行排序，记住tmp的下标对应原数组可能出现的元素，而里面的值对应该元素出现的次数，如果为0就说明该元素在原数组不存在。遍历tmp数组，将对应的下标覆盖原数组即可完成排序。\n1 2 3 4 5 6 7 8 9 10 11 12 //排序 int j = 0; for (int i = 0; i \u0026lt; max + 1; i++)//第一层循环遍历tmp数组 { while (tmp[i]--)//对应元素出现的次数 { a[j++] = i;//tmp的下标对应的就是原数组可能出现的元素 } } //释放资源，避免内存泄漏 free(tmp); tmp = NULL; 简单版本\r完整代码如下：(c++版本)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;iterator\u0026gt; void CountSort(std::vector\u0026lt;int\u0026gt;\u0026amp; a) { // 如果数组为空，直接返回 if (a.empty()) return; // 使用std::max_element找到数组中的最大值 int max = *std::max_element(a.begin(), a.end()); // 创建一个大小为(max + 1)的数组，初始值都为0 std::vector\u0026lt;int\u0026gt; tmp(max + 1, 0); // 统计每个元素的出现次数 for (int num : a) { tmp[num]++; } // 排序阶段 int j = 0; // 遍历tmp数组，按照每个元素出现的次数重新填充原数组a for (int i = 0; i \u0026lt;= max; ++i) { // 当tmp[i]不为0时，将i填充到a数组中tmp[i]次 while (tmp[i]--) { a[j++] = i; } } } int main() { // 示例数组 std::vector\u0026lt;int\u0026gt; arr = {4, 2, 2, 8, 3, 3, 1}; // 调用计数排序函数 CountSort(arr); // 输出排序后的数组 for (int num : arr) { std::cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; return 0; } 优化\r如果我们的数据是这样的，如果还像之前那样开辟空间，会有大量的空间浪费遍历的次数增大，就存在性能的降低 如图，数据的最小值为100，而按照原代码则浪费了0-100中的数组空间，导致不必要的内存开销\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; void CountSort(std::vector\u0026lt;int\u0026gt;\u0026amp; a) { if (a.empty()) return; // 使用std::min和std::max找出数组的最小值和最大值 int min = *std::min_element(a.begin(), a.end()); int max = *std::max_element(a.begin(), a.end()); int range = max - min + 1; // 创建一个大小为range的vector，初始化为0 std::vector\u0026lt;int\u0026gt; tmp(range, 0); // 统计每个元素出现的次数 for (int num : a) { tmp[num - min]++; } // 排序阶段 int j = 0; for (int i = 0; i \u0026lt; range; ++i) { // 将tmp[i]个i+min值填充到a中 while (tmp[i]--) { a[j++] = i + min; } } } int main() { // 示例数组 std::vector\u0026lt;int\u0026gt; arr = {4, 2, 2, 8, 3, 3, 1}; // 调用计数排序函数 CountSort(arr); // 输出排序后的数组 for (int num : arr) { std::cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; return 0; } 空间复杂度：除原数组外，计数排序额外开辟了一个大小为N的临时空间，所以计数排序的空间复杂度为O(N)。 时间复杂度：遍历找最大最小值取范围的时间复杂度为O(N)，遍历原数组统计次数的时间复杂度为O(N)，而排序里面，虽有两层循环，但从思想和本质来看，它只不过是将原来的元素按顺序覆盖了原数组，其执行循环的次数任然为O(N)，所以计数排序的时间复杂度为O(N).\n归并排序\r算法思路\r归并排序算法有两个基本的操作，一个是分，也就是把原数组划分成两个子数组的过程。另一个是治，它将两个有序数组合并成一个更大的有序数组。\n将待排序的线性表不断地切分成若干个子表，直到每个子表只包含一个元素，这时，可以认为只包含一个元素的子表是有序表。 将子表两两合并，每合并一次，就会产生一个新的且更长的有序表，重复这一步骤，直到最后只剩下一个子表，这个子表就是排好序的线性表。\n一句话总结：第一次分为两组，第二次每一组又分为两组，也就是$2^2=4$组，以此类推，直到每组的元素个数为1；\n按照大小顺序逐个合并，最后还原排好序的数组\n代码\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; struct MergeSort { // 主排序函数 void sort(std::vector\u0026lt;int\u0026gt;\u0026amp; arr) { if (!arr.empty()) { mergeSort(arr, 0, arr.size() - 1); } } private: // 合并两个已排序的子数组 void merge(std::vector\u0026lt;int\u0026gt;\u0026amp; arr, int left, int mid, int right) { int n1 = mid - left + 1; // 左子数组的大小 int n2 = right - mid; // 右子数组的大小 std::vector\u0026lt;int\u0026gt; L(n1); // 创建左子数组 std::vector\u0026lt;int\u0026gt; R(n2); // 创建右子数组 // 将数据拷贝到临时数组 L[] 和 R[] for (int i = 0; i \u0026lt; n1; i++) L[i] = arr[left + i]; for (int j = 0; j \u0026lt; n2; j++) R[j] = arr[mid + 1 + j]; // 合并临时数组 int i = 0; // 初始索引 L int j = 0; // 初始索引 R int k = left; // 初始索引合并后的数组 while (i \u0026lt; n1 \u0026amp;\u0026amp; j \u0026lt; n2) { if (L[i] \u0026lt;= R[j]) { arr[k] = L[i]; i++; } else { arr[k] = R[j]; j++; } k++; } // 复制 L[] 中剩余的元素 while (i \u0026lt; n1) { arr[k] = L[i]; i++; k++; } // 复制 R[] 中剩余的元素 while (j \u0026lt; n2) { arr[k] = R[j]; j++; k++; } } // 归并排序函数 void mergeSort(std::vector\u0026lt;int\u0026gt;\u0026amp; arr, int left, int right) { if (left \u0026lt; right) { int mid = left + (right - left) / 2; // 递归排序左右半部分 mergeSort(arr, left, mid); mergeSort(arr, mid + 1, right); // 合并已排序的部分 merge(arr, left, mid, right); } } }; // 主函数 int main() { std::vector\u0026lt;int\u0026gt; arr = {38, 27, 43, 3, 9, 82, 10}; std::cout \u0026lt;\u0026lt; \u0026#34;原数组: \u0026#34;; for (int num : arr) { std::cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; MergeSort sorter; sorter.sort(arr); // 调用排序函数 std::cout \u0026lt;\u0026lt; \u0026#34;排序后的数组: \u0026#34;; for (int num : arr) { std::cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; return 0; } 堆排序\r算法思路\r因为建小堆可以选出最小的数即根节点，我们将每次建好的小堆的最后一个叶子节点和根节点进行交换，交换后不把最后一个数看作堆里的数据，此时根的左右子树依旧是大堆，然后我们再用向下调整算法选出次小的如此循环直到堆里剩一个数结束\n• 升序建大堆 • 降序建小堆\n代码\r堆排序(降序)实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //降序 void HeapSort(int* a, int n) { //建小堆 for (int i = (n - 1 - 1) / 2; i \u0026gt;= 0; --i) { AdjustDown(a, n, i); } int end = n - 1; //把最小的换到最后一个位置，不把最后一个数看作堆里的 //每次选出剩下数中最小的 //从后往前放 while (end \u0026gt; 0) { int tem = a[end]; a[end] = a[0]; a[0] = tem; //选出次小的数 AdjustDown(a, end, 0); --end; } } 最坏的情况及满二叉树，且每个节点都需要调整\n由以上推论过程可得建堆的时间复杂度为$O(N)$; 向下调整算法的时间复杂度为$O(log_2N$); 所以堆排序的时间复杂度为$O(Nlog_2N$);\n快速排序\r快排的实现方法有三种，逐一介绍：\nhoare版本(左右指针法)\r算法思路\r1、选出一个key，一般是最左边或是最右边的。 2、定义一个begin和一个end，begin从左向右走，end从右向左走。（需要注意的是：若选择最左边的数据作为key，则需要end先走；若选择最右边的数据作为key，则需要begin先走）。 3、在走的过程中，若end遇到小于key的数，则停下，begin开始走，直到begin遇到一个大于key的数时，将begin和right的内容交换，end再次开始走，如此进行下去，直到begin和end最终相遇，此时将相遇点的内容与key交换即可。（选取最左边的值作为key） 4.此时key的左边都是小于key的数，key的右边都是大于key的数 5.将key的左序列和右序列再次进行这种单趟排序，如此反复操作下去，直到左右序列只有一个数据，或是左右序列不存在时，便停止操作，此时此部分已有序\n单趟动图如下：\n代码\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 //快速排序 hoare版本(左右指针法) void QuickSort(int* arr, int begin, int end) { //只有一个数或区间不存在 if (begin \u0026gt;= end) return; int left = begin; int right = end; //选左边为key int keyi = begin; while (begin \u0026lt; end) { //右边选小 等号防止和key值相等 防止顺序begin和end越界 while (arr[end] \u0026gt;= arr[keyi] \u0026amp;\u0026amp; begin \u0026lt; end) { --end; } //左边选大 while (arr[begin] \u0026lt;= arr[keyi] \u0026amp;\u0026amp; begin \u0026lt; end) { ++begin; } //小的换到右边，大的换到左边 swap(\u0026amp;arr[begin], \u0026amp;arr[end]); } swap(\u0026amp;arr[keyi], \u0026amp;arr[end]); keyi = end; //[left,keyi-1]keyi[keyi+1,right] QuickSort(arr, left, keyi - 1); QuickSort(arr,keyi + 1,right); } 挖坑法\r代码可分为递归和非递归两种\n算法思路\r挖坑法思路与hoare版本(左右指针法)思路类似 1.选出一个数据（一般是最左边或是最右边的）存放在key变量中，在该数据位置形成一个坑 2、还是定义一个L和一个R，L从左向右走，R从右向左走。（若在最左边挖坑，则需要R先走；若在最右边挖坑，则需要L先走）\n单趟动图如下：\n代码可分为递归和非递归两种\n递归算法代码\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 //快速排序法 挖坑法 void QuickSort1(int* arr, int begin, int end) { if (begin \u0026gt;= end) return; int left = begin,right = end; int key = arr[begin]; while (begin \u0026lt; end) { //找小 while (arr[end] \u0026gt;= key \u0026amp;\u0026amp; begin \u0026lt; end) { --end; } //小的放到左边的坑里 arr[begin] = arr[end]; //找大 while (arr[begin] \u0026lt;= key \u0026amp;\u0026amp; begin \u0026lt; end) { ++begin; } //大的放到右边的坑里 arr[end] = arr[begin]; } arr[begin] = key; int keyi = begin; //[left,keyi-1]keyi[keyi+1,right] QuickSort1(arr, left, keyi - 1); QuickSort1(arr, keyi + 1, right); } 非递归算法代码\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 //单趟排 int PartSort(int* arr, int begin, int end) { int key = arr[begin]; while (begin \u0026lt; end) { while (key \u0026lt;= arr[end] \u0026amp;\u0026amp; begin \u0026lt; end) { --end; } arr[begin] = arr[end]; while (key \u0026gt;= arr[begin] \u0026amp;\u0026amp; begin \u0026lt; end) { ++begin; } arr[end] = arr[begin]; } arr[begin] = key; int meeti = begin; return meeti; } void QuickSortNoR(int* arr, int begin, int end) { stack\u0026lt;int\u0026gt; st; //先入右边 st.push(end); //再入左边 st.push(begin); while (!st.empty()) { //左区间 int left = st.top(); st.pop(); //右区间 int right = st.top(); st.pop(); //中间数 int mid = PartSort(arr, left, right); //当左区间\u0026gt;=mid-1则证明左区间已经排好序了 if (left \u0026lt; mid - 1) { st.push(mid - 1); st.push(left); } //当mid+1\u0026gt;=右区间则证明右区间已经排好序 if (right \u0026gt; mid + 1) { st.push(right); st.push(mid + 1); } } } 前后指针法\r算法思路\r1、选出一个key，一般是最左边或是最右边的。 2、起始时，prev指针指向序列开头，cur指针指向prev+1。 3、若cur指向的内容小于key，则prev先向后移动一位，然后交换prev和cur指针指向的内容，然后cur指针++；若cur指向的内容大于key，则cur指针直接++。如此进行下去，直到cur到达end位置，此时将key和++prev指针指向的内容交换即可。\n经过一次单趟排序，最终也能使得key左边的数据全部都小于key，key右边的数据全部都大于key。\n然后也还是将key的左序列和右序列再次进行这种单趟排序，如此反复操作下去，直到左右序列只有一个数据，或是左右序列不存在时，便停止操作\n代码\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //快速排序法 前后指针版本 void QuickSort2(int* arr, int begin, int end) { if (begin \u0026gt;= end) return; int cur = begin, prev = begin - 1; int keyi = end; while (cur != keyi) { if (arr[cur] \u0026lt; arr[keyi] \u0026amp;\u0026amp; ++prev != cur) { swap(\u0026amp;arr[cur], \u0026amp;arr[prev]); } ++cur; } swap(\u0026amp;arr[++prev],\u0026amp;arr[keyi]); keyi = prev; //[begin,keyi -1]keyi[keyi+1,end] QuickSort2(arr, begin, keyi - 1); QuickSort2(arr, keyi + 1, end); } 一句话总结：快速排序的模糊解释就是先选择一个元素作为标准元素key，让比key小的放在key左边，比key大的放在key右边，最后在key的两边分别做相同的排序，得到最终排序结果\n","date":"2024-12-09T00:11:27+08:00","permalink":"https://fsj2009yx.github.io/posts/post_251061473025222/","title":"排序算法"},{"content":"异或和之和\rP9236 \\[蓝桥杯 2023 省 A\\] 异或和之和 - 洛谷 | 计算机科学教育新生态\n问题\r给定一个数组 $A_i$，分别求其每个子段的异或和，并求出它们的和。或者说，对于每组满足 $1 \\leq L \\leq R \\leq n$ 的 $L,R$，求出数组中第 $L$ 至第 $R$ 个元素的异或和。然后输出每组 $L,R$ 得到的结果加起来的值。\n输入格式\r输入的第一行包含一个整数 $n$ 。\n第二行包含 $n$ 个整数 $A_i$，相邻整数之间使用一个空格分隔。\n输出格式\r输出一行包含一个整数表示答案。\n样例 #1\r样例输入 #1\r1 2 5 1 2 3 4 5 样例输出 #1\r1 39 提示\r【评测用例规模与约定】\r对于 $30 %$ 的评测用例，$n \\leq 300$；\n对于 $60 %$ 的评测用例，$n \\leq 5000$;\n对于所有评测用例，$1 \\leq n \\leq 10^5$，$0 \\leq A_i \\leq 2^{20}$。\n我的解答（未AC）\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;bits/stdc++.h\u0026gt; typedef long long ll; using namespace std; int a[100001]; int b[100001] = {0}; int main() { ios::sync_with_stdio(false); cin.tie(0), cout.tie(0); int n; cin \u0026gt;\u0026gt; n; ll ans = 0; for (int i = 1; i \u0026lt;= n; i++) { cin \u0026gt;\u0026gt; a[i]; b[i] = b[i - 1] ^ a[i]; ans += b[i]; } for (int i = n; i \u0026gt;= 1; i--) { for (int j = 1; j \u0026lt; i; j++) { if (b[i] == b[j]) { continue; } else { ans += (b[i] ^ b[j]); } } } cout \u0026lt;\u0026lt; ans \u0026lt;\u0026lt; endl; } 通过异或前缀和数组暴力枚举算出ans，时间复杂度为O（n²），只能拿到60分\n优化\r要对前缀异或数组中元素两两异或的时间复杂度$O(n^2)$进行优化，考虑到异或的性质，我们可以选择将整数转为二进制，按位运算：\n1 2 3 4 for (int j = 0; j \u0026lt;= 20; ++j) { a[i][j] = (x \u0026gt;\u0026gt; j) \u0026amp; 1; a[i][j] ^= a[i - 1][j]; } 考虑到数字的范围$2^{20}$，我们开a[20]来存每一个元素的每一位；\na[i][j] = (x \u0026gt;\u0026gt; j) \u0026amp; 1;的作用是求出x二进制的每一位，方法是先右移再和1做位与运算 a[i][j] ^= a[i - 1][j];即在每一位上求异或前缀和 现在求得了所有元素的异或前缀和数组，这样我们可以在每一位上两两异或并累加求得该位的区间异或和 这里我们使用空间换时间的方式，将$n^2$压缩到$n$：\n1 2 3 4 5 6 7 8 9 for (int j = 0; j \u0026lt;= 20; ++j) { map\u0026lt;int, int\u0026gt; m; m[0]++; for (int i = 1; i \u0026lt;= n; ++i) { int x = m[a[i][j] ^ 1]; ans += 1LL * (1 \u0026lt;\u0026lt; j) * x; m[a[i][j]]++; } } 这里对代码进行逐行解释：\n1 int x = m[a[i][j] ^ 1] a[i][j] ^ 1是对该位取反，属于异或运算的基本应用 如果异或和区间在该位上的元素（0、1）想对最终结果做出贡献，就必须让$a_i\\oplus a_{i+1}\\oplus\u0026hellip;\\oplus a_m$的结果为$1$，在异或前缀和上就是$b_{i-1}\\oplus b_{m} $的结果为$1$：由于这里只有$0、1$两个元素，某个元素的异或就是另一个元素，我们使用map（vector[2]同理）来存储0和1的出现次数，以空间换时间; x即与a[i][j]异或值为1的元素个数 1 2 ans += 1LL * (1 \u0026lt;\u0026lt; j) * x; m[a[i][j]]++; (1 \u0026lt;\u0026lt; j) * x;对1左移$j$位再乘上x,即异或前缀和元素在该位上两两异或为1的总次数，并将其还原成十进制计算结果\nm[a[i][j]]++记录该位，用于后续该位元素的计算\n通过这种方法，我们将时间复杂度$O(n^2)$压缩到了$O(20n)$，成功AC\n总结\r这道题的思路在于，题目给出了$A_i$元素的范围$2^{20}$，提示了我们可以将他转换成二进制数，也就是拆位；\n又因为每一位只可能是1或0，我们可以借助长度为2的数组对记录元素出现的次数，避免了双重循环\n","date":"2024-12-07T23:20:47+08:00","permalink":"https://fsj2009yx.github.io/posts/post_279452484721406/","title":"异或和之和"},{"content":"自治系统内部的路由选择\r路由信息协议（RIP）\r路由信息协议（Routing Information Protocol，RIP）是内部网关协议(IGP)中最先得到广泛应用的协议。RIP是一种分布式的基于距离向量的路由选择协议，其最大优点就是简单。\n该协议的规定及工作原理：\r网络中的每个路由器都要维护从它自身到其他每个目的网络的距离记录。 距离也称跳数（Hop Count)，规定从一个路由器到直接连接网络的距离（跳数）为1。而每经过一个路由器，距离（跳数）加1。 RIP认为好的路由就是它通过的路由器的数目少，即优先选择跳数少的路径。 RIP 允许一条路径最多只能包含15个路由器（即最多允许15跳)。因此距离等于16时，它表示网络不可达。可见RIP只适用于小型互联网。距离向量路由可能会出现环路的情况，规定路径上的最高跳数的目的是为了防止数据报不断循环在环路上，减少网络拥塞的可能性。 RIP默认在任意两个使用RIP的路由器之间每30秒广播一次RIP路由更新信息，以便自动建立并维护路由表（动态维护)。 在RIP中不支持子网掩码的RIP广播，所以RIP中每个网络的子网掩码必须相同。 RIP协议缺点：\rRIP限制了网络的规模，它能使用的最大距离为15（16表示不可达)。 路由器之间交换的是路由器中的完整路由表，因此网络规模越大，开销也越大。 网络出现故障时，会出现慢收敛现象（即需要较长时间才能将此信息传送到所有路由器)，俗称“坏消息传得慢”，使更新过程的收敛时间长 RIP协议特点：\r仅和相邻路由器交换信息。 路由器交换的信息是当前路由器所知道的全部信息，即自己的路由表。 按固定的时间间隔交换路由信息，如每隔30秒。 毒性逆转\r当一个路由器检测到某个邻居路由器不可达时，它会向邻居路由器发送一个距离值为无穷大的路由更新消息，以表明该路由不可达。\n然而，在毒性逆转中，路由器会将这个不可达的路由信息发送回给原来的邻居路由器，但是将距离值设置为无穷大。这样做的目的是告诉邻居路由器，如果它要发送数据到这个不可达的路由，它应该通过其他路径而不是通过当前路由器。\n例如，假设路由器 A 通过路由器 B 到达目的地 D，但是路由器 B 告诸路由器 A 目的地 D 不可达。在普通的距离向量路由选择算法中，路由器 A 会将目的地 D 的距离值设置为无穷大，并向其他邻居路由器发送更新消息。而在毒性逆转中，路由器 A 会将目的地 D 的距离值设置为无穷大，并将这个更新消息发送回给路由器 B。这样一来，路由器 B 就知道了目的地 D 不可达，并且不会再将数据发送给路由器 A。\n毒性逆转的作用是通过明确标记不可达路径来防止路由环路的产生。具体来说，当节点通过某条链路学到某目的地的路由后，它会向相邻节点通告该目的地的距离为无穷大，以避免对方将该信息再次传播回来，从而有效避免路由振荡和环路问题。\n开放最短路径优先（OSPF）协议\r开放最短路径优先（OSPF）协议是使用分布式链路状态路由算法的典型代表，也是内部网关协议(IGP)的一种。\n当网络规模扩大时，路由器的路由表成比例地增大。这会消耗路由器缓冲区空间，还需要用更多CPU时间，用更多的带宽来交换路由状态信息。因此路由选择必须按照层次的方式进行。\n如图，每个链路状态分组仅在它所属的区域内泛洪，从而限制了链路状态分组泛洪的范围和数量\nBackbone 指的是主干区域（Backbone Area），通常被标记为 Area 0。它是 OSPF 路由体系的核心部分，负责连接并协调多个非主干区域的通信。\n如果是跨区域通信，需要以下流程：\n链路状态分组首先路由到边界路由器 由边界路由器路由到backbone 由backbone路由到目标区域，再在目标区域内由边界路由器路由到目标子网路由器 层次路由与自治系统\r层次路由方法\r因特网将整个互联网划分为较小的自治系统（一个自治系统中包含很多局域网)，每个自治系统内部有自己的路由选择协议。 如果两个自治系统需要通信，则需要自治系统之间的协议来屏蔽掉这些差异，在下一个部分会介绍响应的路由协议。 自治系统(Autonomous System，AS):\r单一技术管理下的一组路由器，这些路由器使用一种AS内部的路由选择协议和共同的度量来确定分组在该AS内的路由，同时还使用一种AS之间的路由选择协议来确定分组在AS之间的路由。 注： 一个自治系统内的所有网络都由一个行政单位管辖，一个自治系统的所有路由器在本自治系统内都必须是连通的。\nOPSF协议就是一种层次路由协议\n边界网关协议（BGP）\r边界网关协议（Border Gateway Protocol，BGP)是不同自治系统的路由器之间交换路由信息的协议，是一种外部网关协议，基于距离矢量（DV）算法。边界网关协议常用于互联网的网关之间。\neBGP：AS区域之间的路由选择协议 iGBP：AS区域内部的路由选择协议 如图，1c，2a，2c，3a分别为所属AS区域的网关，一方面参与AS区域内部的路由选择运算，收集内部AS子网可达信息\n另一方面将子网可达信息传递给相邻的AS区域\n例如2c和3a，2c可以告诉它自己所属区域AS2的子网可达信息，也可以告诉3a通过1c\u0026mdash;2a传递过来的AS1子网可达信息\nBGP路径选择\r热土豆路由选择\r热土豆路由选择算法 (Hot Potato Routing) 是一种简单的、分布式的路由算法，主要用于局域网环境，特别是那些具有广播能力的网络，例如以太网。它的核心思想是尽快将数据包“扔出去”，而不是选择最佳路径。\n当一个节点需要发送数据包到另一个节点时，它会检查其直接相连的邻居节点。如果其中一个邻居节点更接近目标节点（这个“接近”通常是指物理距离或跳数，但并不一定精确计算），则立即将数据包转发给该邻居。否则，它会随机选择一个邻居节点转发数据包。\n它不尝试寻找最佳路径，而是优先选择任何一个看起来更近的节点，尽力让数据包尽快离开自己。 就好比烫手的山芋，尽快扔给别人\n如图，2d通过iBGP获取到信息，了解到可以通过2a或者2c网关到达X\n由于2d和2c与2d直接相连，直接将分组转给2a和2c中能离开本地网络开销最小的那一个，即使是选择另一个到达X的跳数更多（201\u0026lt;263，即选择2a）\n也就是说热土豆路由选择是一种局部最优，不考虑全局最优的路由选择策略\n热土豆路由选择的准则：\r一个节点拥有多个可能的出口（通常通往不同的外部网络或自治系统）。 节点会基于转发数据包的代价（例如链路延迟、跳数、距离等）来选择出口。 选择的出口是： 离开本地网络代价最小的出口。 通过路径通告执行策略\r","date":"2024-12-06T22:27:00+08:00","permalink":"https://fsj2009yx.github.io/posts/post_301732386019327/","title":"自治系统内部的路由选择"},{"content":"三门问题的python代码模拟和原理解释\r刷视频时偶然刷到了三门问题，于是好奇的查阅了一下\n先给出三门问题的简单介绍（引用自百度）：\n三门问题（Monty Hall problem）亦称为蒙提霍尔问题、蒙特霍问题或蒙提霍尔悖论，大致出自美国的电视游戏节目Let\u0026rsquo;s Make a Deal。问题名字来自该节目的主持人蒙提·霍尔（Monty Hall）。\n参赛者会看见三扇关闭了的门，其中一扇的后面有一辆汽车，选中后面有车的那扇门可赢得该汽车，另外两扇门后面则各藏有一只山羊。\n当参赛者选定了一扇门，但未去开启它的时候，节目主持人开启剩下两扇门的其中一扇，露出其中一只山羊。 主持人其后会问参赛者要不要换另一扇仍然关上的门。问题是：换另一扇门会否增加参赛者赢得汽车的机率。如果严格按照上述的条件，那么答案是会。不换门的话，赢得汽车的几率是1/3。换门的话，赢得汽车的几率是2/3。 虽然该问题的答案在逻辑上并不自相矛盾，但十分违反直觉。\n开始和大多数人想的一样，会选择继续开第一扇门或者认为换和不换的概率都为$1/2$，答案显然不是。\n为更直观的看到三门问题的正确性，我写了一段python代码模拟这个过程\n代码\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import random num :int =10000000 doors=[\u0026#39;sheep\u0026#39;,\u0026#39;sheep\u0026#39;,\u0026#39;car\u0026#39;] win_num :int =0 for i in range(num): random.shuffle(doors) #随机打乱 #首先选择第一个门，主持人开启另一个门 #choice=doors[0] #展示另一个门为山羊 if doors[1]==\u0026#39;sheep\u0026#39;: sheep=doors[1] index=2 else: sheep=doors[2] index=1 #选择换门 choice=doors[index] if choice==\u0026#39;car\u0026#39;: win_num+=1 print(f\u0026#34;获奖的概率为{win_num/num*100}%\u0026#34;) 经过多次运行，在$10000000$次试验的环境下，最后的输出结果接近于$66.7%$，也就是$2/3$\n原理解释\r很显然这是一个概率论的问题，我们来构建更加具体的概率问题：\n问题简述：\n有三扇门，其中一扇门后面藏有一辆车，另外两扇门后面藏有山羊。 你首先选择一扇门。 主持人知道哪个门后面有车，之后会打开一扇没有车的门，通常是两扇你没选的门中的一扇。 然后主持人会问你是否要换门。如果你换门，你会选择剩下的未被你选中且未被主持人打开的门。 问题是：是否换门能增加获胜的概率？\n假定选手选择第一扇门\nA=第一扇门中是车 B=第二扇门中是车 C=第三扇门中是车 D=主持人选择打开第三扇门 在初始情况下：$P(A)=P(B)=P(C)=1/3$;\n然后，主持人打开了第三扇门，且我们知道第三扇门后面是山羊。\n此时注意：由于主持人并不是固定打开三号门，主持人需要选择不是车的那个门来打开，只是在事例中，我们事先假定了三号门为羊\n如果第一扇门后面有车（事件A），也就是说主持人选择第二扇门和第三扇门都可以。所以，在事件A下，主持人选择打开第三扇门的概率是 $P(D|A)=1/2$，\n如果第二扇门后面有车（事件B），主持人只能打开第三扇门（因为第三扇门后有山羊）。因此，在事件B下，主持人打开第三扇门的概率是 1,即$P(D|B)=1$\n如果第三扇门后面有车（事件C），主持人就不能打开第三扇门了。因此，在事件C下，主持人只能选择打开第二扇门，$P(D|B)=0$\n现在我们需要计算在主持人打开第三扇门的情况下，是否换门能够增加获胜的概率：\n在换门的情况下，最终选择第二扇门 由贝叶斯公式，计算$P(B | D) = \\frac{P(D | B)P(B)}{P(D)}$ 由全概率公式，计算$P(D)$=$P(D|A)P(A)+P(D|B)P(B)+P(D|C)P(C)=(1/21/3)+11/3+0=1/2$; 由上面的条件知：$P(B | D) = \\frac{P(D | B)P(B)}{P(D)}=(1*1/3)/(1/2)=2/3$;\n由此我们得知，在主持人打开了第三扇门的条件下，我们选择第二扇门的概率为$2/3$，因此，我们换门的获奖几率更大\n总结\r在这个场景中，我在思考主持人选择第三扇门的部分耗费了不少时间，原因是我没有理解到，主持人并不是固定打开三号门，只是在问题场景中打开了第三扇门，而第三扇门恰好为羊。而实际上，主持人为了保证打开结果为羊的门，是否打开三号门是根据门后的物品排放来决定的。\n","date":"2024-12-06T19:10:09+08:00","permalink":"https://fsj2009yx.github.io/posts/post_243711766418750/","title":"三门问题的python代码模拟和原理解释"},{"content":"计算机网络计算\r时延\r总时延=处理时延+排队时延+传输时延+传播时延\n处理时延\n处理时延的计算通常依赖于设备的处理能力，与数据包的大小有关 排队时延\n分组在进入路由器后要现在输入队列中排队等待处理。在路由器确定了转发接口后，还要在输出队列中排队等待转发 传输时延（发送时延）\n是主机或路由器发送数据帧所需要的时间，也就是从发送数据帧的第一个比特算起，到该帧的最后一个比特发送完毕所需的时间 计算公式：数据帧长度(b) / 信道带宽(b/s) 传播时延\n电磁波在信道中传播一定的距离需要花费的时间 计算公式： 信道长度(m) / 电磁波在信道上的传播速率(m/s) 例题：\r【例】考虑两台主机A和主机B由一条带宽为R bps、长度为M米的链路互连，信号传播速率为V m/s。假设主机A从t=0时刻开始向主机B发送分组，分组长度为L比特。试求：\n传播延迟（时延）dp；\n传输延迟dt；\n若忽略结点处理延迟和排队延迟，则端到端延迟de是多少？\n若dp\u0026gt;dt，则t=dt时刻，分组的第一个比特在哪里？\n若V=250000km/s，L=512比特，R=100 Mbps，则使带宽时延积刚好为一个分组长度（即512比特）的链路长度M是多少？\n(注：1k=10^3,1M=10^6)\n解答：\r【解】1）传播时延dp = 信道长度(m) / 电磁波在信道上的传播速率(m/s) = M / V\n2）传输延迟dt = 数据帧长度(b) / 信道带宽(b/s) = L / R\n3）总延迟de = 传播时延 + 传输延迟 = M / V + L / R\n4）dp \u0026gt; dt意味着最早发送的信号没有到达目的主机之前，数据分组的最后一个比特已经发送出来了，所以分组的第一个比特在距离主机的V * dt米的链路上\n5）时延带宽积 = 传播时延 * 带宽 = M / V * R = 512，解之得M = 1280米\n流量强度\r定义：\r若R=链路带宽（链路宽度），L=分组长度（一个分组的大小），a=分组到达队列的平均速率（分组数量），流量强度公式 ：$I = La/R$\n对于流量强度的理解：\n计算机网络中的流量强度通常是指在给定时间内网络中传输的数据量，反映了网络的负载程度和资源使用情况。 高流量强度：网络中传输的数据量大，可能导致带宽饱和，进而引起延迟、丢包等问题，影响用户体验。 由图，如果流量强度$≥1$，排队延时会占总延时的主导，甚至让排队延时趋于无穷大\n所以我们不能让流量强度$＞1$;\nGBN，SR和TCP\r我们以一个具体的事例来展示三种协议的工作流程：\n假设有两台服务器，A和B，它们之间通过不可靠的网络传输数据。A服务器需要向B服务器发送5个数据分组：P1, P2, P3, P4, P5。在传输过程中，由于网络问题，P3丢失了。以下是三种协议处理这种情况的具体示例：\n回退N步（Go-Back-N, GBN）\r步骤：\nA发送P1, P2, P3, P4, P5。 B接收到P1和P2，但由于P3丢失，B不会确认P2及之后的任何分组。 A的定时器超时，未收到P3的确认。 A从P3开始重新发送所有未确认的分组，即P3, P4, P5。 B接收到P3, P4, P5，并发送确认。 A收到P3, P4, P5的确认，继续后续数据传输。 注意：GBN会回退到上一个已知正确的分组（P2），然后重新发送之后的所有分组。\n选择重传（Selective Repeat, SR）\r步骤：\nA发送P1, P2, P3, P4, P5。 B接收到P1和P2，但由于P3丢失，B只确认P1和P2。 A的定时器超时，未收到P3的确认。 A仅重传P3。 B接收到P3，并发送确认。 A收到P3的确认，继续后续数据传输。 注意：SR只会重传丢失的分组（P3），而不需要重传P3之后的其他分组。\nTCP协议\r步骤：\nA与B建立TCP连接，进行三次握手。 A发送P1, P2, P3, P4, P5。 B接收到P1和P2，并发送确认ACK2。 A发送窗口滑动，继续发送P3, P4, P5。 B发现P3丢失，不会发送ACK3。 A的定时器超时，未收到P3的确认。 A重传P3。 B接收到P3，并发送确认ACK3。 A收到ACK3，窗口滑动，继续发送P4和P5。 B接收到P4和P5，并发送确认ACK5。 A收到ACK5，数据传输完成。 A与B断开连接，进行四次挥手。 注意：TCP使用序列号、确认号、滑动窗口、超时重传等机制来确保数据的可靠传输。在上述示例中，TCP会针对每个丢失的分组进行单独重传，并维护序列号和确认号来确保数据的顺序和完整性。\nTCP超时重传定时器的选择\rSampleRTT(样本往返时间)\rsampleRTT（样本往返时间）是指在TCP连接中，测量数据包从发送方发送到接收方并返回的时间。\nsampleRTT通常是动态的;\nestimatedRTT（估计往返时间）\restimatedRTT（估计往返时间）是TCP协议中用于预测网络延迟的一个重要指标。它基于多个sampleRTT（样本往返时间）值的加权平均计算，旨在提供一个更稳定和可靠的RTT估计，以便用于调整重传定时器（RTO）。\n注意：EstimatedRTT的计算公式是一个编程语法，即右值赋值给左边，而且每一次的SampleRTT是最新的测量数据，因为最近的样本能更好的反映网络的当前拥塞状况，称为指数加权移动平均\n测量RTT的变化也是有价值的，DevRTT用于估测RTT的变化\n计算公式：\rEstimatedRTT 估算RTT：\r$\\text{EstimatedRTT} = (1 - \\alpha) \\times \\text{EstimatedRTT} + \\alpha \\times \\text{SampleRTT}$\nDevRTT RTT偏差：\r$\\text{DevRTT} = (1 - \\beta) \\times \\text{DevRTT} + \\beta \\times \\left| \\text{SampleRTT} - \\text{EstimatedRTT} \\right|$\nTimeoutInterval 超时时间间隔：\r$\\text{TimeoutInterval} = \\text{EstimatedRTT} + 4 \\times \\text{DevRTT}$\n例题\r假设有5个 SampleRTT（样本往返时延）测量值，且已知：\n已获得前5个样本之后，EstimatedRTT 的初始值为 100ms， 已获得前5个样本之后，DevRTT 的初始值为 5ms， SampleRTT 的测量值分别为： 90ms, 110ms, 95ms, 105ms, 100ms。 假设使用标准的加权因子：\nα=0.125\\alpha = 0.125（用于计算 EstimatedRTT）， β=0.25\\beta = 0.25（用于计算 DevRTT）。 问题： 计算 TimeoutInterval，即超时时间间隔。\n解答步骤：\r计算新的 EstimatedRTT：\n使用 EstimatedRTT 的更新公式：\n$\\text{EstimatedRTT} = (1 - \\alpha) \\times \\text{EstimatedRTT}_{\\text{old}} + \\alpha \\times \\text{SampleRTT}$\n其中 $\\text{EstimatedRTT}_{\\text{old}}$是初始值 100ms，而 SampleRTT 为每次测量的值。\n计算步骤如下：\n$\\text{EstimatedRTT}_1 = (1 - 0.125) \\times 100 + 0.125 \\times 90 = 98.75 , \\text{ms}$\n$\\text{EstimatedRTT}_2 = (1 - 0.125) \\times 98.75 + 0.125 \\times 110 = 99.84 , \\text{ms}$\n$\\text{EstimatedRTT}_3 = (1 - 0.125) \\times 99.84 + 0.125 \\times 95 = 98.88 , \\text{ms}$\n$\\text{EstimatedRTT}_4 = (1 - 0.125) \\times 98.88 + 0.125 \\times 105 = 100.16 , \\text{ms}$\n$\\text{EstimatedRTT}_5 = (1 - 0.125) \\times 100.16 + 0.125 \\times 100 = 100.12 , \\text{ms}$\n所以，最终的 EstimatedRTT 为 100.12ms。\n计算新的 DevRTT：\n使用 DevRTT 的更新公式：\n$\\text{DevRTT} = (1 - \\beta) \\times \\text{DevRTT}_{\\text{old}} + \\beta \\times \\left| \\text{SampleRTT} - \\text{EstimatedRTT} \\right|$\n初始的 DevRTT 为 5ms。现在逐步计算每个样本的偏差：\n$\\text{DevRTT}_1 = (1 - 0.25) \\times 5 + 0.25 \\times \\left| 90 - 98.75 \\right| = 5 + 0.25 \\times 8.75 = 6.19 , \\text{ms}$\n$\\text{DevRTT}_2 = (1 - 0.25) \\times 6.19 + 0.25 \\times \\left| 110 - 99.84 \\right| = 5.24 + 0.25 \\times 10.16 = 6.81 , \\text{ms}$\n$\\text{DevRTT}_3 = (1 - 0.25) \\times 6.81 + 0.25 \\times \\left| 95 - 98.88 \\right| = 5.10 + 0.25 \\times 3.88 = 6.10 , \\text{ms}$\n$\\text{DevRTT}_4 = (1 - 0.25) \\times 6.10 + 0.25 \\times \\left| 105 - 100.16 \\right| = 4.58 + 0.25 \\times 4.84 = 6.00 , \\text{ms}$\n$\\text{DevRTT}_5 = (1 - 0.25) \\times 6.00 + 0.25 \\times \\left| 100 - 100.12 \\right| = 4.50 + 0.25 \\times 0.12 = 4.53 , \\text{ms}$\n所以，最终的 DevRTT 为 4.53ms。\n计算 TimeoutInterval：\n使用 TimeoutInterval 的计算公式：\n$\\text{TimeoutInterval} = \\text{EstimatedRTT} + 4 \\times \\text{DevRTT}$\n将上面得到的 EstimatedRTT 和 DevRTT 代入公式：\n$\\text{TimeoutInterval} = 100.12 + 4 \\times 4.53 = 100.12 + 18.12 = 118.24 , \\text{ms}$\n答案：\r最终的 TimeoutInterval 为 118.24ms\nTCP拥塞控制\rTCP拥塞控制-CSDN博客\n要点：\n拥塞窗口cwnd的值是几，就能发送几个数据报文段 在一个发送方中未被确认的数据量不会超过cwnd与rwnd的最小值。因为在上面假设了接收方的接收缓存足够大，所以可以忽略接收窗口rwnd的限制，因此在发送方中未被确认的报文段仅受限于cwnd 例题\r考虑仅有一条单一的TCP连接使用一条10Mbps的链路[1],且该链路没有缓存任何数据，假设这条链路是发送主机和接收主机之间的唯一拥塞链路。假定某TCP发送方向接收方有一个大文件要发送，而接收方的接收缓存比拥塞窗口[2]要大得多。假设每个TCP报文段长度为1500字节；该连接的双向传播时延是120ms;假设该TCP连接能够取得的最大发送窗口长度(以报文段计) 是100，并且该TCP连接总是处于拥塞避免阶段(即忽略了慢启动[3]),拥塞后执行快速恢复算法。请回答以下问题，要求写出具体分析计算过程，只有结果且结果正确得2分。\n(1)这条TCP连接的平均窗口长度(以报文段计)和平均吞吐量(单位Mbps，保留1位小数)是多少？平均信道利用率是多少？\n(2)这条TCP连接在从丢包恢复后，忽略发送时延的情况下，再次到达其最大窗口要经历多长时间(单位ms)?\n解答：\n（1）最大窗口是100，然后降为50，平均窗口长度为（100+50）/2=75，\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;2分 发送一个报文段时间是15008/10^7=1.2ms，一个周期的时间是120ms+1.2=121.2ms 均吞吐量为： 7515008/(121.210^-3)=7.4Mbps， \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;2分\n信道利用率=75*1.2/121.2=74.3% \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;2分\n（2）当数据报[4]丢包后，执行快速恢复算法，拥塞窗口变为原来的1/2即50， \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;2分 *\n再次恢复到最大窗口执行拥塞避免算法，每一个轮次拥塞窗口增加1，需要100-50=50个轮次，所以需要120ms*50=6000ms. \u0026mdash;\u0026mdash;\u0026mdash;-2分\n以下是问题的详细解析：\n问题描述：\r带宽：链路带宽为 10 Mbps，无缓存数据。 TCP 报文段：每个报文段长度为 1500 字节。 双向传播时延：RTT = 150 ms。 TCP 初始阶段：假设 TCP 始终处于拥塞避免阶段。 a. 最大窗口长度（以报文段计算）是多少？\r公式： 最大窗口长度$ W_{max} $是由**带宽时延积（BDP）**决定的： $W_{max} = \\frac{\\text{带宽} \\times \\text{RTT}}{\\text{每个报文段的大小}}$\n计算：\n带宽 =$10 , \\text{Mbps} = 10^7 , \\text{bps}$ RTT =$ 150 , \\text{ms} = 0.15 , \\text{s}$ 每个报文段大小 =$1500 , \\text{字节} = 1500 \\times 8 , \\text{bits} = 12000 , \\text{bits}$ 带宽时延积（BDP）： $\\text{BDP} = \\text{带宽} \\times \\text{RTT} = 10^7 \\times 0.15 = 1.5 \\times 10^6 , \\text{bits}$\n最大窗口长度（报文段数）： $W_{max} = \\frac{\\text{BDP}}{\\text{报文段大小}} = \\frac{1.5 \\times 10^6}{12000} = 125 , \\text{报文段}$\n答案：最大窗口长度是 125 报文段。\nb. 平均窗口长度（报文段）与吞吐量（bps）是多少？\r在 拥塞避免阶段，窗口大小会在 1 到最大窗口之间线性增长，因此平均窗口长度为： $W_{avg} = \\frac{W_{max}}{2} = \\frac{125}{2} = 62.5 , \\text{报文段}$\n吞吐量公式： $\\text{吞吐量} = \\frac{W_{avg} \\times \\text{报文段大小}}{\\text{RTT}}$\n计算：\n$W_{avg} = 62.5 , \\text{报文段}$ $每个报文段大小 =1500 , \\text{字节} = 12000 , \\text{bits}$ RTT =$0.15 , \\text{s}$ $\\text{吞吐量} = \\frac{62.5 \\times 12000}{0.15} = 5 \\times 10^6 , \\text{bps}$\n答案：\n平均窗口长度：62.5 报文段 吞吐量：5 Mbps c. 从丢包恢复到达到最大窗口要经历多长时间？\r在丢包后，TCP Reno 的窗口会减半，从$W_{max}/2 开始，并以线性增长至 W_{max}。$ 需要时间计算如下： $\\text{时间} = \\frac{W_{max}/2}{RTT}$\n计算：\n$W_{max} = 125 , \\text{报文段}$ RTT =$0.15 , \\text{s}$ 时间： $\\text{时间} = \\frac{125/2}{0.15} = 62.5 \\times 0.15 = 9.375 , \\text{s}$\n答案：需要 9.375 秒。\n总结答案：\ra. 最大窗口长度：125 报文段 b. 平均窗口长度：62.5 报文段，吞吐量：5 Mbps c. 恢复到最大窗口需要：9.375 秒\n子网分配\r考虑一个具有前缀128.119.40.128/26的子网。给出能被分配给该网络的一个IP地址(形式为xXX.xXX.xXX.xXx)的例子，假定一个ISP拥有形式为128.119.40.64/26的地址块。假定它要从该地址块生成4个子网，每块具有相同数量的IP地址。这4个子网(形式为a.b.c.d/x)的前缀\n为前缀128.119.40.128/26指定一个IP地址: 任何IP地址，其前26位与128.119.40.128相同，但其余位可变均可以。例如，128.119.40.129 就是一个合适的IP地址。\n从128.119.40.64/26划分出4个子网:\n由于2²=4，我们需要增加2位子网位来得到4个子网。所以，新的子网掩码应为/28。 根据这个新的子网掩码，我们可以得到以下4个子网的前缀： 128.119.40.64/28 128.119.40.80/28 128.119.40.96/28 128.119.40.112/28 每个子网都有16个IP地址，但需要注意的是，每个子网的第一个地址是网络地址，最后一个地址是广播地址，中间的地址可以分配给主机。\nRIP协议\r解释RIP协议为什么会有“好消息传得快，坏消息传得慢。”的现象？（解释超详细）_绘图表示为什么“好消息传的快,坏消息传的慢”-CSDN博客\n轮询协议\r【计算机网络】数据链路层 : 轮询访问 介质访问控制 ( 轮询协议 | 令牌传递协议 )_multiple access control-CSDN博客\n轮询协议的工作原理：\r中央控制节点： 轮询协议通常有一个主节点，称为轮询节点。这个节点负责控制访问信道的顺序，轮流让每个节点发送数据。轮询节点按照预定的顺序，逐个询问网络中的各个节点，是否有数据要发送。 节点响应： 每当轮询节点轮到某个节点时，轮到的节点可以检查是否有待发送的数据。如果有数据要发送，节点将数据发送到信道；如果没有数据要发送，节点将直接跳过，等待下次轮询。 时间分配： 每个节点在轮询周期内有一个固定的时间窗口，通常称为轮询时隙（polling slot）。在这个时隙内，节点可以发送最多一定数量的数据。如果节点没有数据要发送，该时隙就被空闲浪费。 轮询周期： 所有节点都会轮流被询问，这个过程会不断循环。每完成一次轮询，称为一个轮询周期。每个节点在其轮询时隙内必须完成数据发送，或者在没有数据时等待下次轮询。 例题：\r考虑有N个节点和传输速率为Rbps的一个广播信道。假设该广播信道为多路访问而使用轮询[1(有一个附加的轮询节点)。假设从某节点完成传输到后续节点允许传输的时间量(即轮询时延)是$d_{poll}$。假设在一个轮询周期中，一个给定的节点允许传输至多Q比特。该广播信道的最大吞吐量是多少？\n解答：\r由题可知：轮询时延为$d_{poll}$，每个节点传输耗费的时间$t=Q/R$,那么一个轮询周期即为$N(Q/R+d_{poll})$; 一周期传输总比特为$NQ$，由此可得吞吐量：$NQ/N(Q/R+d_{poll})=\\frac{Q}{\\frac{Q}{R} + d_{\\text{poll}}}$； 吞吐量：吞吐量一般表示为每单位时间成功传输的数据量\n","date":"2024-12-06T09:51:53+08:00","permalink":"https://fsj2009yx.github.io/posts/post_132911105916910/","title":"计算机网络计算"},{"content":"IPV4\rIP数据报\rTCP的数据传输基于字节流，而网络层的分组称为数据报：\n一个标准的 IPv4 数据报总共有** 20 字节的头部**（不包括可选字段），以及可变长度的数据部分。下面是 IPv4 数据报头部各字段的详细解释：\n1. 版本 (Version)\r大小: 4 位 含义: 指定 IP 协议的版本。IPv4 中该字段的值为 4（即 0100 二进制），表示使用 IPv4 协议。 2. 头部长度 (IHL - Internet Header Length)\r大小: 4 位 含义: 指定 IPv4 头部的长度（单位是 4 字节）。最小值是 5，表示头部长度为 5 × 4 = 20 字节。若有可选字段，则该值会更大。 3. 服务类型 (Type of Service, ToS)\r大小: 8 位\n含义: 指定数据包的优先级和服务质量（QoS）。它可以用来表示优先级和处理策略，如最小延迟、最大吞吐量等。包括以下几个字段：\n优先级 (Precedence): 3 位 延迟 (Delay): 1 位 吞吐量 (Throughput): 1 位 可靠性 (Reliability): 1 位 保留位 (Reserved): 2 位 4. 总长度 (Total Length)\r大小: 16 位 含义: 数据报的总长度，包括头部和数据部分，单位是字节。最大长度为 65535 字节。 5. 标识符 (Identification)\r大小: 16 位 含义: 用于唯一标识一个数据报，特别是在数据包分片时。分片的各部分会使用相同的标识符，以便接收方将它们重新组装成完整的数据报。 6. 标志 (Flags)\r大小: 3 位\n含义: 用来控制或标识数据报是否可以分片。包括：\n第 0 位 (保留，必须为 0) 第 1 位 (Don\u0026rsquo;t Fragment, DF): 如果为 1，表示数据包不能被分片；如果为 0，允许分片。 第 2 位 (More Fragments, MF): 如果为 1，表示数据报后面还有分片；如果为 0，表示这是最后一个分片。 7. 片偏移 (Fragment Offset)\r大小: 13 位 含义: 如果数据包被分片，这个字段表示当前分片相对于原始数据报的偏移量，单位是 8 字节。这个字段帮助接收方重组分片。 8. 生存时间 (Time to Live, TTL)\r大小: 8 位 含义: 控制数据包在网络中能够经过的最大跳数。每经过一个路由器，该值减 1，当值为 0 时，数据包被丢弃。防止数据包在网络中无限循环。 9. 协议 (Protocol)\r大小: 8 位\n含义: 指定数据部分使用的协议类型，如：\n1 - ICMP 6 - TCP 17 - UDP 等等。 10. 头部校验和 (Header Checksum)\r大小: 16 位 含义: 用于检测头部数据的错误。发送方计算并加入这个值，接收方也会重新计算，若校验和不一致，则丢弃数据包。 11. 源 IP 地址 (Source IP Address)\r大小: 32 位 含义: 指示数据包的发送者的 IP 地址。 12. 目的 IP 地址 (Destination IP Address)\r大小: 32 位 含义: 指示数据包的接收者的 IP 地址。 13. 选项 (Options) (可选字段)\r大小: 可变 含义: 用于实现某些特殊功能，如时间戳、源路由等。选项字段不常用，且通常只有当头部长度大于 20 字节时才出现。 14. 填充 (Padding)\r大小: 可变 含义: 确保头部长度为 4 字节的倍数。如果选项字段的大小不是 4 字节的倍数，就会使用填充位来补齐。 IP编址\r首先理解IP地址和接口：\nIP地址：32位的二进制标识，对主机或者路由器的接口编址\n接口：主机/路由器和物理链路的链接处\n路由器通常拥有多个接口 主机也可能拥有多个接口 IP地址和每一个接口关联 一台路由器上有多个接口，不同的接口分配不同的IP地址，而如果主机上有多个网卡或者使用虚拟网卡（如VMware），也可以具有多个网络接口\n由图，一台路由器的三个网络接口连接了三个不同的IP地址，分别是223.1.1.x、223.1.2.x 和 223.1.3.x\n以左上角的三台主机为例，它们共用了一个路由器接口，而且IP地址中最左侧的24比特相同\n说明该网络可能由一个不包含路由器的网络互联，可能是通过以太网交换机或者无线网络WIFI实现\n在IP的术语中，这3个主机的网络接口和1个路由器接口构成了一个子网\n子网\r一个子网有这两点性质：\n一个子网内的节点（主机或者路由器），它们的IP地址高位部分相同，这些节点构成的网络叫做子网 子网内各主机可以在物理上相互直接到达，无需借助路由器 判断子网的方法：\n为了确定子网，分开主机和路由器的每个接口，产生几个隔离的网络岛，使用接口端连接这些隔离的网络的端点\n这些隔离的网络中的每一个都是一个子网\n子网掩码\r子网掩码可以分离出IP地址中的网络地址和主机地址，因为两台主机要通信，首先要判断是否处于同一网段，即网络地址是否相同。如果相同，那么可以把数据包直接发送到目标主机，否则就需要路由网关将数据包转发送到目的地。\n子网掩码的表示方法：\n点分十进制表示法\n二进制转换十进制，每8位用点号隔开\n例如：子网掩码二进制11111111.11111111.11111111.00000000，表示为255.255.255.0 CIDR斜线记法\nIP地址/n\n例1：192.168.1.100/24，其子网掩码表示为255.255.255.0，二进制表示为11111111.11111111.11111111.00000000\n例2：172.16.198.12/20，其子网掩码表示为255.255.240.0，二进制表示为11111111.11111111.11110000.00000000\n不难发现，例1中共有24个１，例2中共有20个１，所以n是这么来的。运营商ISP常用这样的方法给客户分配IP地址。 ++形如++++223.1.1.0/24++++的子网地址，其中的++++/24++++即++++子网掩码++++,表示32个比特中++++最左侧的24比特++++定义了++++子网的地址++++，后面的++++8比特++++定义了++++子网内主机的地址++++，即++++网络地址++++和++++主机地址++\n223.1.1.0即网络地址也可以称为该IP地址的前缀\nIP地址的分类\rABC类地址\rA类IP地址：\n网络地址范围：0.0.0.0 到 127.255.255.255\n网络位：8位\n主机位：24位\n数量：\n每个A类网络可以有 2^24 - 2 个可用主机地址（减去网络地址和广播地址），即：16,777,214 个主机。 A类IP地址的网络数量：2^7 = 128 个网络（因为A类的网络地址范围从 0.0.0.0 到 127.255.255.255，而第一位是固定的）。 B类IP地址：\n网络地址范围：128.0.0.0 到 191.255.255.255\n网络位：16位\n主机位：16位\n数量：\n每个B类网络可以有 2^16 - 2 个可用主机地址，即：65,534 个主机。 B类IP地址的网络数量：2^14 = 16,384 个网络（因为B类的网络地址范围从 128.0.0.0 到 191.255.255.255，而前两位是固定的）。 C类IP地址：\n网络地址范围：192.0.0.0 到 223.255.255.255\n网络位：24位\n主机位：8位\n数量：\n每个C类网络可以有 2^8 - 2 个可用主机地址，即：254 个主机。 C类IP地址的网络数量：2^21 = 2,097,152 个网络（因为C类的网络地址范围从 192.0.0.0 到 223.255.255.255，而前三位是固定的）。 总结：\nA类IP：128个网络，每个网络有 16,777,214 个主机。 B类IP：16,384个网络，每个网络有 65,534 个主机。 C类IP：2,097,152个网络，每个网络有 254 个主机。 一些特定的IP地址\r子网部分:全为 0\u0026mdash;本网络 主机部分:全为0\u0026mdash;本主机 主机部分:全为1\u0026ndash;广播地址，这个网络的所有主机 内网（专用）IP地址\r++这些IP地址只在局部网络中有意义，且不会当作公用地址来分配++\nCIDR\r**CIDR（无类域间路由，Classless Inter-Domain Routing）**是一种用于 IP 地址分配和路由的方式，取代了早期基于 A、B、C 类网络的方式，使 IP 地址分配更灵活和高效。\nCIDR 表示法：\nCIDR 表示法通常写成 IP地址/前缀长度，例如 192.168.1.0/24。其中：\nIP地址 指定网络的起始地址。 前缀长度 表示网络位数，即从左到右用于定义网络部分的位数。 在 192.168.1.0/24 中，/24 表示前 24 位是网络位，剩下的 8 位是主机位。这表示一个包含 256 个地址的网络范围（从 192.168.1.0 到 192.168.1.255）\nCIDR的转发表和转发算法：\n其中的默认表项也称为默认网关\n默认网关（Default Gateway） 是指在计算机网络中，当计算机需要与其他网络（如互联网）上的设备通信时，无法直接找到目的地的IP地址时，计算机会将数据包发送到目的路由器或网关设备。\n它充当了一个桥梁，帮助本地网络与外部网络（如互联网）进行通信\n下一跳（Next Hop）\r下一跳（Next Hop）指的是数据包在传输过程中经过的下一个路由器或网络设备。它是数据包从源设备到目标设备之间的一个转发步骤、\n在路由器的路由表中，每一条路由规则都指定了一个目标网络和一个下一跳地址。下一跳是数据包在经过当前路由器后需要发送的下一个路由器或网络设备的IP地址。\n下一跳通常出现在分组访问互联网或者同一路由器的不同子网访问之间：\n分组的目标IP指向外部网络（互联网）\n举例说明：\n设备A需要向设备B发送数据包（192.168.2.10）。 设备A会检查目标IP地址192.168.2.10，发现它不在本地子网内，因此将数据包发送给默认网关192.168.1.1。 路由器192.168.1.1收到数据包后，查找其路由表，发现到192.168.2.0/24子网的路由条目，下一跳地址是192.168.1.2。 路由器192.168.1.1将数据包转发给下一跳路由器192.168.1.2。 路由器192.168.1.2根据自己的路由表，继续将数据包转发，直到数据包到达设备B。 分组的目标IP指向同一路由器下的不同子网\n当数据包需要在同一个路由器的不同子网之间转发时，下一跳的概念依然适用，但这里的“下一跳”指的是路由器内部的++不同网络接口++，而不是不同的路由器。\n举例说明：\n设备A的IP是192.168.1.10，子网掩码是255.255.255.0（/24）。 设备A要访问的目标是设备B的IP 192.168.2.10，设备A会首先检查目标IP是否在同一子网内。由于192.168.2.10不在设备A的子网192.168.1.0/24内，设备A会将数据包发送到默认网关192.168.1.1。 路由器192.168.1.1接收到设备A发来的数据包后，会查看路由表，决定如何处理该数据包。由于目标地址192.168.2.10位于192.168.2.0/24子网，而路由器的接口2（192.168.2.1）已经连接到这个子网，路由器将数据包转发到接口2。 路由器通过接口2将数据包转发到目标设备B（192.168.2.10）。 设备B收到数据包后，检查目标IP并处理数据包。 IP地址的获取\r有两种方法可以获取到IP地址：\n由网络管理员分配IP地址到你的主机，通常配置在一个系统文件中 通过DHCP从服务器中动态获取IP地址 DHCP\r作用：允许主机在加入网络时，动态地从服务器中获取IP地址\n网络管理员能够配置DHCP，以使某给定主机每次与网络连接时能得到一个相同的IP地址，或者某主机被分配一个临时的IP地址\n除了主机IP地址分配外， DHCP还允许一台主机得到其他信息，比如子网掩码，第一跳路由器地址，和本地DNS服务器地址\nDHCP作用及特点：\nDHCP可以自动分配IP、子网掩码、网关、DNS。 DHCP客户端使用的端口68，服务端使用端口67，使用的UDP应用层的协议。 DHCP一般不为服务器分配IP，因为他们要使用固定IP，所以DHCP一般只为办公环境的主机分配IP。 DHCP服务器和客户端需要在一个局域网内，在为客户端分配IP的时候需要进行多次广播。但DHCP也可以为其他网段内主机分配IP，只要连接两个网段中间的路由器能转发DHCP配置请求即可，但这要求路由器配置中继功能。 下面是一个使用DHCP协议配置IP地址的示例：\nDHCP（动态主机配置协议）分配IP地址的过程涉及以下几个步骤：\n1. DHCP Discover（客户端请求）\r背景：当一个新的设备（客户端）接入网络时，它不知道自己的IP地址，因此需要通过DHCP来自动获取一个可用的IP地址。\n过程：客户端通过广播（255.255.255.255）向网络发送一个 DHCP Discover (DHCP发现报文) 消息。这一消息的目的是通知网络上的所有DHCP服务器，客户端正在请求一个IP地址。\n该消息中并不包含具体的IP地址，仅仅是一个寻求服务的请求。 2. DHCP Offer（服务器提供IP）\r背景：当网络中的DHCP服务器收到 DHCP Discover 请求后，它会根据服务器的IP地址池选择一个可用的IP地址，并返回一个 DHCP Offer（DHCP提供报文） 消息给客户端。\n过程：DHCP服务器发送的 DHCP Offer 包含以下信息：\n提供的IP地址（从可用池中分配） 子网掩码 默认网关 租约时间（IP地址的有效期） DHCP服务器的IP地址 这个过程是由DHCP服务器针对客户端的 DHCP Discover 消息做出的响应。重要的是，多个DHCP服务器可能会对同一个客户端的请求作出响应，因此客户端可能会收到多个 DHCP Offer 消息。\n3. DHCP Request（客户端确认）\r背景：客户端收到一个或多个 DHCP Offer 后，会选择一个提供的IP地址，并通知所有DHCP服务器它选择了哪一个。\n过程：客户端通过广播发送一个 DHCP Request（DHCP请求报文） 消息。这个消息包含：\n确认选中的DHCP服务器的IP地址 请求使用的IP地址 在这个阶段，客户端告诉DHCP服务器它接受某个 DHCP Offer 中的IP地址，并且请求分配该IP地址。其他DHCP服务器收到这个请求后，会知道该客户端已经选择了其他服务器的IP，因此不再做回应。\n4. DHCP ACK（服务器确认）\r背景：当DHCP服务器收到客户端的 DHCP Request 消息后，表示客户端已经确认接受了该服务器提供的IP地址。服务器会确认并完成地址分配过程。\n过程：DHCP服务器通过发送 DHCP ACK（DHCP ACK报文） 消息来确认该IP地址已经分配给客户端。DHCP ACK 包含：\n确认客户端请求的IP地址 该IP地址的租约期 其他配置参数（如网关、DNS服务器等） 网络地址转换NAT技术\r网络地址转换技术NAT（Network Address Translation）主要用于实现位于内部网络的主机访问外部网络的功能。\n当局域网内的主机需要访问外部网络时，通过NAT技术可以将其私网地址转换为公网地址，并且多个私网用户可以共用一个公网地址，这样既可保证网络互通，又节省了公网地址。\n技术原理\rNAT通过转换数据包中的源IP地址或目标IP地址，使得多个设备能够通过一个公网IP访问互联网。\n这通常用于私有网络（如家庭或公司网络），其中内部设备使用私有IP地址，而公网IP地址由网络的NAT设备进行共享。\nNAT使能路由器对外界来说不像路由器，它对外界的行为如同一个具有单一IP地址的单一设备。 所有离开家庭路由器流向更大因特网的报文都拥有同一个源IP地址，且所有进入家庭路由器的报文都拥有同一个目标IP地址 NAT路由器对外隐藏了家庭网络（内网）的细节 即家庭网络设备共享同一个IPV4地址，它们的内网地址为私有地址，或者是32位子网地址\nNAT穿越问题\rNAT穿越问题是指在NAT（网络地址转换）环境下，如何让位于私有网络中的设备能够与外部网络（通常是互联网）中的设备直接通信。\n由于NAT在处理数据包时会修改源IP地址和端口号，这可能会导致内部设备无法直接被外部设备访问，从而阻碍了某些类型的通信，特别是端到端（P2P）通信\nNAT（网络地址转换）转换表的实现方式主要有几种方案，具体取决于NAT类型、使用的协议以及应用的需求。不同的方案对于IP地址和端口的映射方式有所不同。以下是常见的几种NAT转换表方案：\n1. 静态NAT转换表\r概述：在静态NAT中，内网的私有IP地址被永久映射到外网的一个公网IP地址。这种映射是一对一的，即每个私有IP地址始终对应一个公网IP地址。\n表项：每个静态映射条目包含以下信息：\n内部私有IP地址 外部公网IP地址 优点：\n适合需要长期固定公网IP地址的设备，如服务器。 转换过程简单，不需要动态更新。 缺点：\n公网IP地址的浪费，因为每个私有IP都需要一个单独的公网IP。 2. 动态NAT转换表\r概述：动态NAT将内网设备的私有IP地址映射到一个公网IP池中的公网IP地址。每当内网设备请求外部连接时，NAT设备会从公网IP池中分配一个公网IP地址给其使用，映射可能会在会话结束后解除。\n表项：每个动态映射条目包含以下信息：\n内部私有IP地址 映射的公网IP地址（来自公网IP池） 映射的端口号 优点：\n更灵活，适合大规模的动态分配。 缺点：\n内网设备可能会使用不同的公网IP地址，增加了管理复杂性。 3. 端口地址转换（PAT，Port Address Translation）\r概述：PAT（也叫做过载NAT）是动态NAT的一种特殊形式，多个内网设备共享一个公网IP地址，通过不同的端口号来区分每个会话。它通过对端口号进行映射，允许多个内网设备同时使用一个公网IP地址访问外部网络。\n表项：每个PAT映射条目包含以下信息：\n内部私有IP地址 映射的公网IP地址 内部端口号 映射的外部端口号 优点：\n大量节省公网IP地址，一个公网IP就可以支持多个内网设备同时访问外部网络。 缺点：\n内网设备的外部连接通过端口号来区分，可能会有端口冲突问题（尤其是在大量设备同时访问时）。 一些协议（如FTP）可能需要额外的处理，因为它们会在数据包中包含端口号信息。 4. 双向NAT（Bi-directional NAT）\r概述：双向NAT是一种更复杂的转换方式，通常用于需要双向通信的场景（如P2P连接）。双向NAT允许在两个NAT设备之间的连接时，进行双向IP和端口映射。\n表项：除了映射的IP地址外，还可能包括外部端口与内部端口之间的双向映射。\n优点：\n支持双向通信，常用于P2P和某些即时通讯应用。 缺点：\n增加了转换的复杂性，通常需要更加动态的表项管理。 nat技术的争议和不足\rNAT（网络地址转换）技术广泛应用于解决IPv4地址短缺问题，它通过将内网设备的私有IP地址映射到公网IP地址，从而使多个内网设备共享一个公网IP。\n这种技术的普及，尤其是在家庭和企业网络中，有许多好处，但也存在一些争议和不足：\n1. NAT与端到端通信模型的冲突\r争议点：NAT技术的最大争议之一在于它破坏了传统的“端到端”通信模型。在没有NAT的情况下，互联网中的每个设备都可以直接访问其他设备，确保了点对点通信的透明性。NAT通过修改IP地址和端口号，将内网设备隐藏在一个公网IP地址后面，从而阻止了外部设备直接访问内网设备。 不足之处：这种干预使得许多基于端到端通信的协议（如某些P2P协议、VoIP、FTP等）无法正常工作，或者需要复杂的NAT穿越技术来确保通信的畅通。这样不仅增加了通信的复杂性，还可能带来性能下降和安全问题。 2. NAT穿越问题\r争议点：NAT穿越是指如何使得位于NAT背后的内网设备能够与外部设备进行直接通信。为了实现NAT穿越，通常需要使用额外的技术（如STUN、TURN、UPnP等），但这些技术并非总是有效，尤其是在更复杂的NAT类型（如对称NAT）下。 不足之处：NAT穿越问题使得P2P通信、VoIP通话、远程桌面等应用变得复杂且不稳定，特别是当NAT设备的配置无法灵活调整时。此外，很多NAT穿越技术（如STUN）在某些网络环境下并不起作用，这导致了用户在尝试进行某些类型的连接时遇到困难。 3. IP地址和端口号的混淆\r争议点：NAT通过将内网设备的私有IP地址和端口号映射到公网IP地址和端口号，导致了IP地址和端口号之间的混淆。特别是在端口地址转换（PAT）中，多个内网设备会共享一个公网IP地址，不同的设备通过不同的端口进行区分。这种方式虽然节省了公网IP地址，但也带来了端口管理的复杂性。 不足之处：端口号的映射带来了许多挑战，包括端口冲突（当多个设备尝试使用相同的端口号时）、端口跟踪问题（例如在多个会话同时进行时难以跟踪每个会话的状态）以及性能瓶颈。此外，某些协议对端口映射的依赖可能会导致数据包在NAT设备前后出现不一致，从而影响协议的正确性。 4. 网络性能的潜在影响\r争议点：NAT的使用虽然减少了对公网IP地址的需求，但也可能影响网络性能，特别是在使用PAT（端口地址转换）时。NAT设备需要对每个数据包进行地址和端口号的修改，可能会导致一定的延迟。 不足之处：当多个内网设备同时访问外部网络时，NAT设备可能会成为瓶颈，导致性能下降。特别是在使用NAT时，数据包的处理、映射表的管理以及会话跟踪可能需要消耗较多的CPU和内存资源，增加了网络的延迟和复杂性。 5. 安全性问题\r争议点：虽然NAT可以隐藏内网设备的真实IP地址，从而在一定程度上提供了“安全性”，但它并不是一种有效的安全机制。NAT并没有从根本上解决网络攻击问题，反而可能带来一些隐性风险。\n不足之处：\n伪装性：NAT隐藏了内网设备的IP地址，外部攻击者无法直接针对内网设备发起攻击，但这并不意味着内网就安全。攻击者仍然可以通过NAT设备的公网IP进行某些类型的攻击，如DoS（拒绝服务攻击）和端口扫描等。 协议不兼容性：某些协议依赖于源IP和端口信息进行正常通信（如FTP、SIP、RTSP等），而NAT设备通常会修改这些信息，这导致了协议的不兼容和漏洞。例如，在没有适当的NAT支持的情况下，FTP和SIP可能无法正常工作。 安全性管理的复杂性：NAT在一定程度上增加了网络配置和安全管理的复杂性。为了保证网络安全，管理员需要处理更多的配置细节，如端口映射、会话跟踪和访问控制等。 6. IPv6的挑战\r争议点：IPv6设计之初就不依赖NAT，因为IPv6提供了几乎无限的IP地址空间，可以为每个设备分配一个独立的公网IP，这样就不需要NAT。然而，在IPv6逐步普及之前，NAT依然是IPv4环境中的主要解决方案。 不足之处：虽然NAT可以延缓IPv4地址枯竭，但它并没有从根本上解决IPv4的地址空间问题。而且，随着IPv6的普及，NAT的存在被认为是一种过渡技术，并不符合现代网络架构的要求。尽管IPv6解决了IP地址分配问题，但要实现全球范围的IPv6迁移仍然需要时间和努力。 ","date":"2024-12-04T23:25:47+08:00","permalink":"https://fsj2009yx.github.io/posts/post_16861929726775/","title":"IPV4"},{"content":"JAVA流对象\rStream流\rStream是Java 8 API添加的一个新的抽象，称为流Stream，以一种声明性方式处理数据集合（侧重对于源数据计算能力的封装，并且支持序列与并行两种操作方式）\n1、代码简洁：函数式编程写出的代码简洁且意图明确，使用stream接口让你从此告别for循环\n2、多核友好：Java函数式编程使得编写并行程序如此简单，就是调用一下方法\nJava中的Stream流是一种用于处理集合数据的高级API，它引入于Java 8，并大大简化了集合数据的操作。通过流，您可以以声明性方式（而非命令式方式）处理数据，从而使代码更加简洁、可读和易于并行化。以下是Stream的一些基本使用示例：\n创建流\r流可以通过不同方式创建，最常见的有通过集合的stream()方法或通过Stream.of()方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 import java.util.*; import java.util.stream.*; public class StreamExample { public static void main(String[] args) { // 从集合创建流 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 3, 4, 5); Stream\u0026lt;Integer\u0026gt; numberStream = numbers.stream(); // 使用Stream.of()创建流 Stream\u0026lt;String\u0026gt; stringStream = Stream.of(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;); } } 中间操作（Intermediate Operations）\r流的中间操作是惰性执行的，只有在流被消费时才会实际执行。常用的中间操作有filter(), map(), sorted(), distinct()等。\nfilter(): 过滤\r筛选符合条件的元素：filter() 通过给定的条件来筛选流中的元素，仅保留符合条件的元素。\n惰性执行：流的操作是惰性执行的，即只有在执行终止操作时（例如 collect()、forEach()）才会真正执行过滤操作。\n1 2 3 4 5 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6); List\u0026lt;Integer\u0026gt; evenNumbers = numbers.stream() .filter(n -\u0026gt; n % 2 == 0) .collect(Collectors.toList()); System.out.println(evenNumbers); // [2, 4, 6] 收集方法collect负责收集流，将collect(Collectors.toList()收集为List。\nmap(): 转换\r元素转换：map() 的作用是将流中的每个元素应用一个函数，从而转换成另一种类型或形态的元素。 映射操作：通过传递一个函数给 map()，该函数会被应用于流中的每个元素，从而生成一个新的元素。 惰性执行：map() 是惰性执行的，只有在流的终止操作（如 collect()、forEach() 等）触发时，映射操作才会真正执行。 1 2 3 4 5 List\u0026lt;String\u0026gt; words = Arrays.asList(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;); List\u0026lt;Integer\u0026gt; wordLengths = words.stream() .map(String::length) .collect(Collectors.toList()); System.out.println(wordLengths); // [5, 6, 6] sorted(): 排序\r1 2 3 4 5 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 1, 4, 1, 5, 9); List\u0026lt;Integer\u0026gt; sortedNumbers = numbers.stream() .sorted() .collect(Collectors.toList()); System.out.println(sortedNumbers); // [1, 1, 3, 4, 5, 9] distinct(): 去重\r1 2 3 4 5 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 2, 3, 4, 4, 5); List\u0026lt;Integer\u0026gt; distinctNumbers = numbers.stream() .distinct() .collect(Collectors.toList()); System.out.println(distinctNumbers); // [1, 2, 3, 4, 5] 终止操作（Terminal Operations）\r流的终止操作触发流的计算，常见的终止操作有forEach(), collect(), reduce(), count(), anyMatch()等。\nforEach(): 遍历\r1 2 3 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 3, 4, 5); numbers.stream() .forEach(System.out::println); collect(): 收集\r1 2 3 4 List\u0026lt;String\u0026gt; words = Arrays.asList(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;); Set\u0026lt;String\u0026gt; wordSet = words.stream() .collect(Collectors.toSet()); System.out.println(wordSet); // [banana, apple, cherry] reduce(): 聚合\r1 2 3 4 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 3, 4, 5); int sum = numbers.stream() .reduce(0, Integer::sum); System.out.println(sum); // 15 anyMatch(): 匹配\r1 2 3 4 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 3, 4, 5); boolean anyEven = numbers.stream() .anyMatch(n -\u0026gt; n % 2 == 0); System.out.println(anyEven); // true 并行流\r流支持并行处理，可以使用parallelStream()来替代stream()，让操作并行执行，充分利用多核CPU的优势。\n1 2 3 4 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6); int sum = numbers.parallelStream() .reduce(0, Integer::sum); System.out.println(sum); // 21 链式调用\r流的操作可以链式调用，这使得代码更加简洁、易读。\n1 2 3 4 5 6 7 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); List\u0026lt;Integer\u0026gt; result = numbers.stream() .filter(n -\u0026gt; n % 2 == 0) .map(n -\u0026gt; n * n) .sorted() .collect(Collectors.toList()); System.out.println(result); // [4, 16, 36, 64] 示例\r如图所示：\n如图所示，将list转为stream流后，先用filter条件筛选出以张开头的（1）长度为3的（2）字符串元素，使用forEach方法遍历输出并终止流的计算\n收集方法collection\rStream流操作===“集合”===收集方法collect_stream流collect-CSDN博客\n总结\rJava的Stream API提供了丰富的功能来简化集合的操作。它不仅支持常见的操作如过滤、映射和排序，还允许您进行更复杂的数据转换和聚合。通过中间操作和终止操作的组合，您可以写出简洁且高效的数据处理代码。\nIO流\r【Java基础-3】吃透Java IO：字节流、字符流、缓冲流_javaio-CSDN博客\nJava IO（输入/输出）流是 Java 中用于处理输入和输出操作的一种机制，它允许程序与外部世界（如文件、网络、内存等）进行数据交换。Java IO 流是一种抽象概念，它允许程序对数据进行读写操作，不关心数据的来源或去向。\nIO 流分为两大类：\n字节流（Byte Streams）：以字节为单位进行读写操作。 字符流（Character Streams）：以字符为单位进行读写操作，通常用于处理文本文件。 对于不同类型的文件，有不同的读取方式：\n对于纯文本文件（如.txt、.md）通常建议使用字符流读取，因为字符流能自动处理读取时的编码问题 对于.doc等文件，它们其实属于二进制文件，需要使用字节流读取并利用特定解析库解析内容 Java IO 流的分类\r1. 字节流（Byte Streams）\r字节流是以字节为单位进行数据传输，它可以处理所有类型的 I/O 操作（包括图片、音频等二进制数据）。字节流有两个主要的抽象类：InputStream 和 OutputStream，它们分别表示输入流和输出流。\nInputStream：用于从数据源读取字节流。 OutputStream：用于向目标写入字节流。 常见的字节流类：\nFileInputStream 和 FileOutputStream：用于文件的字节输入和输出。 BufferedInputStream 和 BufferedOutputStream：用于缓冲输入和输出流，以提高读取和写入效率。 DataInputStream 和 DataOutputStream：用于读取和写入基本数据类型（如 int、float、double 等）。 ObjectInputStream 和 ObjectOutputStream：用于读取和写入对象。 2. 字符流（Character Streams）\r字符流是以字符为单位进行数据传输，专门用于处理文本数据。字符流在内部使用了默认的字符编码（如 UTF-8、ISO-8859-1 等），适合处理文本文件。\nReader：用于从字符输入流读取字符。 Writer：用于向字符输出流写入字符。 常见的字符流类：\nFileReader 和 FileWriter：用于文件的字符输入和输出。 BufferedReader 和 BufferedWriter：用于缓冲字符输入和输出，以提高性能。 PrintWriter：用于格式化输出，并提供更方便的打印方法。 字节流和字符流的其他区别：\n字节流一般用来处理图像、视频、音频、PPT、Word等类型的文件。字符流一般用于处理纯文本类型的文件，如TXT文件等，但不能处理图像视频等非文本文件。（用一句话说就是：字节流可以处理一切文件，而字符流只能处理纯文本文件） 字节流本身没有缓冲区，缓冲字节流相对于字节流，效率提升非常高。而字符流本身就带有缓冲区，缓冲字符流相对于字符流效率提升就不是那么大了。详见文末效率对比。 3.字符缓冲流\r在诸多处理流中，有一个非常重要，那就是缓冲流。\n我们知道，程序与磁盘的交互相对于内存运算是很慢的，容易成为程序的性能瓶颈。减少程序与磁盘的交互，是提升程序效率一种有效手段。缓冲流，就应用这种思路：普通流每次读写一个字节，而缓冲流在内存中设置一个缓存区，缓冲区先存储足够的待操作数据后，再与内存或磁盘进行交互。这样，在总数据量不变的情况下，通过提高每次交互的数据量，减少了交互次数。\n字符缓冲流是在字符流基础上进行的封装，字符流负责将字节转换为字符，而缓冲流则负责提供缓冲区，减少 I/O 操作的次数。缓冲流通过将数据读取到内存中的缓冲区里，再从缓冲区中读取和写入，从而优化了性能。\nBufferedReader：用于从文件读取文本数据。它将数据一次性读取到缓冲区，然后按行逐个返回。 BufferedWriter：用于将文本数据写入文件。它将数据一次性写入缓冲区，然后批量写入文件。 BufferedReader 示例：读取文本文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import java.io.BufferedReader; import java.io.FileReader; import java.io.IOException; public class BufferedReaderExample { public static void main(String[] args) { String filePath = \u0026#34;example.txt\u0026#34;; // 文件路径 // 使用 BufferedReader 逐行读取文件 try (BufferedReader br = new BufferedReader(new FileReader(filePath))) { String line; // 逐行读取文件内容 while ((line = br.readLine()) != null) { System.out.println(line); // 打印每一行 } } catch (IOException e) { e.printStackTrace(); // 异常处理 } } } BufferedWriter 示例：写入文本文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import java.io.BufferedWriter; import java.io.FileWriter; import java.io.IOException; public class BufferedWriterExample { public static void main(String[] args) { String filePath = \u0026#34;output.txt\u0026#34;; // 输出文件路径 String content = \u0026#34;Hello, World! This is a test.\u0026#34;; // 要写入的文本内容 // 使用 BufferedWriter 将文本内容写入文件 try (BufferedWriter bw = new BufferedWriter(new FileWriter(filePath))) { bw.write(content); // 写入单行内容 bw.newLine(); // 写入换行符 bw.write(\u0026#34;This is a new line.\u0026#34;); } catch (IOException e) { e.printStackTrace(); // 异常处理 } } } 字符缓冲流的工作原理：\n读取过程（BufferedReader）： BufferedReader 使用 FileReader 将文件内容按字符读取。 它将字符读取到内存中的缓冲区，通常一次读取的字符数比直接使用 FileReader 更大（默认大小为 8192 字节）。 BufferedReader 提供的 readLine() 方法使得按行读取更加高效，不需要频繁从硬盘读取每一行。 写入过程（BufferedWriter）： BufferedWriter 使用 FileWriter 将字符数据写入文件。 它将字符数据先写入到缓冲区中，直到缓冲区满了或者调用 flush() 或 close() 方法，才将缓冲区中的数据一次性写入文件。 这种方式减少了磁盘写入操作的次数，提高了效率。 为什么使用字符缓冲流：\n性能优化：缓冲流通过内部的缓冲区来减少每次读写文件时的物理 I/O 操作，使得在处理大文件或高频繁 I/O 操作时，性能会有明显的提升。 简化编码：字符缓冲流可以自动处理字符编码，而不需要手动转换字节与字符之间的关系。 按行读取/写入：BufferedReader 提供了 readLine() 方法，使得按行读取文件变得非常简单和高效，而 BufferedWriter 可以通过 newLine() 方法写入换行符。 字符集\r乱码\r乱码通常发生在编码与解码不一致时。为了理解乱码的原因，我们需要了解字符编码、字节流和字符流是如何工作的，以及它们是如何影响我们处理文本文件时的数据表示的。\n1. 字符编码和字符集\r字符编码是将字符（例如字母、数字、符号等）映射为字节的规则。不同的字符编码使用不同数量的字节来表示一个字符。常见的字符编码包括：\nASCII：使用 7 位来表示字符，只能表示 128 个字符（包括英文字符、数字、符号等）。 UTF-8：可变长度编码，1 到 4 个字节来表示一个字符，广泛用于网页和现代应用程序，兼容 ASCII。 UTF-16：使用 2 或 4 个字节表示字符，广泛用于 Windows 系统。 字符集是字符的集合，而字符编码是如何将这些字符映射为字节的标准。\n2. 乱码的根本原因\r乱码发生的根本原因通常是字符编码和解码不一致，即：文件或数据的编码方式与读取时使用的编码方式不一致。\n示例：\r假设有一个文件是用 UTF-8 编码的，但你用 ISO-8859-1 编码来读取它。读取过程中，字符的字节流会被错误地解码，从而导致乱码。\n写入文件时使用 UTF-8 编码： 例如，写入文本 \u0026quot;你好\u0026quot;，在 UTF-8 编码下，它会被存储为一系列的字节（例如：E4 BD A0 E5 A5 BD）。\n用错误的编码读取文件（比如用 ISO-8859-1 解码）： 当你使用 ISO-8859-1 解码时，它不会按照 UTF-8 的方式来解码字节，而是会将每个字节直接映射到字符。ISO-8859-1 只支持 256 个字符，它无法正确解码 UTF-8 的字节序列。因此，字节 E4 会被错误地解析为某个特定字符（如 ä），接下来的字节 BD、A0 等也会被错误地映射成其他字符，最终显示为乱码。\n常见的乱码情况\n读取文件时的编码不一致：例如，文件用 UTF-8 编码保存，但使用其他编码（如 ISO-8859-1 或 GBK）读取，导致字节被误解码成错误的字符。 写入文件时的编码不一致：例如，你用 UTF-8 编码写入文件，但将它以 GBK 编码打开，或者相反，也会导致乱码。 4. 乱码示例\r例子 1：UTF-8 编码的文件，错误地用 GBK 编码读取：\n假设有一个 UTF-8 编码的文本文件，其中包含中文字符 你好，该字符在 UTF-8 中的字节是：\n1 E4 BD A0 E5 A5 BD 如果你错误地用 GBK 编码来读取这个文件，那么 GBK 会按它自己的规则解码这些字节，而不是按照 UTF-8 来处理。这时，你会看到一串无法识别的字符，像是 ä½ çœŸ 这样的乱码。\n例子 2：字节流和字符流使用不当：\n字节流：如 FileInputStream 和 FileOutputStream，这些流以字节为单位读取和写入数据，通常不进行编码或解码。如果你用字节流读取文本文件，你会得到原始的字节数据，必须手动使用合适的编码格式进行转换（例如：InputStreamReader）。 字符流：如 FileReader 和 BufferedReader，这些流以字符为单位读取和写入数据，并会根据字符编码（如 UTF-8、GBK）自动进行解码。如果你用字符流读取文件，而文件的编码与流的默认编码不一致，也会导致乱码。 转换流\r转换流定义\r首先来看看转换流在 IO体系 中的位置。\n转换流属于字符流，它本身也是一种高级流，用来包装基本流的。\n其中输入流叫做 InputStreamReader，输出流叫做 OutputStreamWriter。\n转换流：是字符流和字节流之间的桥梁。\n首先我们来看读取数据，读取数据首先要有一个数据源，在读取的时候就是将数据源的数据读取到内存中。\n当我们创建了转换流对象的时候，其实是需要包装一个 字节输入流 的。在包装之后这个字节流就变成字符流了，就可以拥有字符流的特性了。\n例如：读取数据不会乱码了、可以指定字符集一次读取多个字节。\n转换流主要用于将字节流（如 InputStream、OutputStream）转换为字符流（如 Reader、Writer），以便处理字符编码问题。\nInputStreamReader：将字节输入流（InputStream）转换为字符输入流（Reader）。 OutputStreamWriter：将字符输出流（Writer）转换为字节输出流（OutputStream）。 InputStreamReader 示例：将字节流转换为字符流\rInputStreamReader 将字节输入流（如 FileInputStream）转换为字符输入流（Reader）。它负责将字节流中的字节数据解码成字符数据，通常使用某种字符编码（如 UTF-8）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import java.io.FileInputStream; import java.io.InputStreamReader; import java.io.BufferedReader; import java.io.IOException; public class InputStreamReaderExample { public static void main(String[] args) { String filePath = \u0026#34;example.txt\u0026#34;; // 文件路径 // 使用 InputStreamReader 将字节流转换为字符流 try (FileInputStream fis = new FileInputStream(filePath); InputStreamReader isr = new InputStreamReader(fis, \u0026#34;UTF-8\u0026#34;); // 使用 UTF-8 编码 BufferedReader br = new BufferedReader(isr)) { String line; // 逐行读取文件内容 while ((line = br.readLine()) != null) { System.out.println(line); // 打印每一行 } } catch (IOException e) { e.printStackTrace(); // 异常处理 } } } 代码说明：\rFileInputStream：读取字节流数据。 InputStreamReader：将 FileInputStream（字节流）转换为 InputStreamReader（字符流），并使用 UTF-8 编码进行字符解码。 BufferedReader：提供高效的逐行读取功能。 readLine()：按行读取文件内容，直到文件结束。 OutputStreamWriter 示例：将字符流转换为字节流\rOutputStreamWriter 将字符输出流（如 FileWriter）转换为字节输出流（OutputStream）。它负责将字符数据编码成字节数据，通常使用某种字符编码（如 UTF-8）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import java.io.FileOutputStream; import java.io.OutputStreamWriter; import java.io.BufferedWriter; import java.io.IOException; public class OutputStreamWriterExample { public static void main(String[] args) { String filePath = \u0026#34;output.txt\u0026#34;; // 输出文件路径 String content = \u0026#34;Hello, World! 这是一个测试。\u0026#34;; // 要写入的内容 // 使用 OutputStreamWriter 将字符流转换为字节流 try (FileOutputStream fos = new FileOutputStream(filePath); OutputStreamWriter osw = new OutputStreamWriter(fos, \u0026#34;UTF-8\u0026#34;); // 使用 UTF-8 编码 BufferedWriter bw = new BufferedWriter(osw)) { bw.write(content); // 写入字符数据 bw.newLine(); // 写入换行符 bw.write(\u0026#34;新的一行内容\u0026#34;); // 写入新的一行 } catch (IOException e) { e.printStackTrace(); // 异常处理 } } } 代码说明：\rFileOutputStream：将数据写入字节流。 OutputStreamWriter：将 FileOutputStream（字节流）转换为 OutputStreamWriter（字符流），并使用 UTF-8 编码将字符数据编码为字节。 BufferedWriter：提供高效的逐行写入功能。 write()：将字符写入文件。 newLine()：写入平台特定的换行符。 字符编码的选择\r转换流（InputStreamReader 和 OutputStreamWriter）可以指定字符编码。常见的字符编码包括：\nUTF-8：一种变长的编码方式，能够表示所有 Unicode 字符，常用于网页和大多数现代应用程序。 GBK：一种常用于中文的编码方式，兼容 GB2312。 ISO-8859-1：西欧字符集，通常用于英语和西欧语言。 例如：\nInputStreamReader isr = new InputStreamReader(fis, \u0026quot;UTF-8\u0026quot;); OutputStreamWriter osw = new OutputStreamWriter(fos, \u0026quot;UTF-8\u0026quot;); 如果不指定编码，Java 默认使用操作系统的默认字符编码，但建议始终明确指定编码，以避免不同操作系统间的兼容性问题。\n转换流的作用\r字节流与字符流的桥梁：转换流是字节流与字符流之间的桥梁，用于处理不同字符编码的数据。 自动编码解码：转换流自动处理字节和字符之间的转换，并根据指定的编码格式进行字符解码或编码，简化了代码。 支持多种编码格式：通过指定不同的字符编码，可以支持多种编码格式的数据处理，避免字符乱码问题。 序列化和反序列化流\r序列化流\r序列化流的作用是直接将java对象写入文件中，通常是二进制或文本格式。序列化流使得对象能够：\n存储：将对象的状态存储到磁盘、数据库或其他持久化存储中。 传输：通过网络传输对象，以便在不同的系统之间交换数据。比如，在分布式系统中，通过网络传输对象，或者将对象存储在文件中后，另一个程序可以读取并反序列化它。 对象克隆：通过序列化和反序列化的过程，可以实现对象的深度复制（克隆），这通常用于复制复杂对象。 跨平台和语言间的兼容性：将对象转换为平台无关的格式（如JSON、XML、Protobuf等），使得不同平台和编程语言的程序可以共享数据。 序列化生成的文件是无法直接读取数据的，需要通过反序列流还原。\n反序列化流\r反序列化流（Deserialization Stream）的作用是将之前序列化存储或传输的字节流或文本数据恢复成原始对象的状态。具体来说，反序列化流的作用包括：\n恢复对象的状态：将存储在磁盘、数据库或通过网络传输的字节流或文本数据反向转换回对象，使得程序能够继续使用这些对象。 数据传输：在分布式系统或网络通信中，通过反序列化流可以将远程发送的对象恢复为本地可操作的对象。通常，在客户端和服务器之间交换数据时，数据会通过序列化传输，而接收方通过反序列化将数据还原为对象。 兼容性：反序列化流支持不同平台、不同编程语言之间的数据交换。通过反序列化，将在一种平台或语言中序列化的对象恢复到另一种平台或语言中所能理解的对象结构。例如，JSON、XML等格式的数据可以在不同的系统和编程语言中使用反序列化恢复成相应的对象。 序列化流（ObjectOutputStream）将对象转化为字节流并保存到文件中。 反序列化流（ObjectInputStream）从文件中读取字节流并恢复对象。 通过这种方式，Java 可以**将对象的状态持久化（即保存到文件）**或在网络上传输对象，而无需显式地管理内存。\n代码示例：\r序列化流：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package IOtest; import java.io.*; class Person implements Serializable { private String name; private int age; // 构造函数 public Person(String name, int age) { this.name = name; this.age = age; } // Getter 方法 public String getName() { return name; } public int getAge() { return age; } // 重写 toString 方法 @Override public String toString() { return \u0026#34;Person{name=\u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } } public class SerializationExample { public static void main(String[] args) { // 创建一个 Person 对象 Person person = new Person(\u0026#34;Alice\u0026#34;, 30); // 序列化对象到文件 try (ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\u0026#34;person.ser\u0026#34;))) { oos.writeObject(person); System.out.println(\u0026#34;对象已成功序列化！\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } } 由此，生成了一个.per文件，其中的内容是序列化生成的，不可直接读取\n反序列化流：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package IOtest; import java.io.*; public class DeserializationExample { public static void main(String[] args) { // 反序列化对象从文件 try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\u0026#34;person.ser\u0026#34;))) { Person person = (Person) ois.readObject(); System.out.println(\u0026#34;反序列化对象：\u0026#34; + person); } catch (IOException | ClassNotFoundException e) { e.printStackTrace(); } } } 注意：要序列化的对象的类需要实现Serializable接口，表示该对象可以序列化\nSerializable接口本身没有任何方法，它属于一种标记接口\n序列号/Javabean版本号serialVersionUID\rserialVersionUID 是 Java 序列化机制的一部分，用于确保在反序列化过程中，反序列化的类和序列化的类之间的兼容性。\n在 Java 中，当对象被序列化时，类的信息（包括字段和方法的签名）被保存下来。如果反序列化时，类的结构发生了变化（例如，添加、删除或修改字段），Java 反序列化机制会通过 serialVersionUID 来验证版本是否匹配。\n如果 版本号一致，即 serialVersionUID 相同，则可以安全地反序列化。 如果 版本号不一致，即 serialVersionUID 不同，通常会抛出 InvalidClassException 异常，表示类结构发生了不兼容的变化。 如果javabean类的代码被修改，java底层会重新计算出一个serialVersionUID，导致版本号不匹配，不能反序列化\n为了处理这种冲突，我们可以显示指定版本号\n示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class Person implements Serializable { // 2. 显式指定 serialVersionUID，确保版本的一致性 @Serial private static final long serialVersionUID = 123456789L; // 指定版本号 private String name; private int age; // 构造函数 public Person(String name, int age) { this.name = name; this.age = age; } // getter 和 setter public String getName() { return name; } public int getAge() { return age; } // toString 方法 @Override public String toString() { return \u0026#34;Person{name=\u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;, age=\u0026#34; + age + \u0026#34;}\u0026#34;; } 其中，我们显示指定了private static final long serialVersionUID的变量值，以保证该类的所有对象都共享这一固定的serialVersionUID\nfinal：final 关键字修饰的变量表示它是一个常量，即值一旦被初始化，就无法再改变。在 serialVersionUID 的例子中，final 确保了 serialVersionUID 的值在类加载后不会发生变化。\n代码中serialVersionUID不可以使用其他的变量名，否则将无法被编译器识别\njava16之后引入了注解@Serial，它可以放在serialVersionUID之前以表明该变量与对象的序列化有关，增强了代码的可读性\n如果使用不同版本的类反序列化文件，会产生报错，如图所示：\n打印流\rJava打印流（PrintStream/PrintWriter）-CSDN博客\n压缩流/解压缩流\r在 Java 中，压缩和解压缩操作通常涉及到 流（Streams）。Java 提供了几种常见的类和库来处理文件的压缩与解压缩，常用的有 java.util.zip 包，它包含了处理 ZIP 文件和其他压缩格式的类。以下是常用的压缩和解压缩流的介绍与示例：\n1. 压缩流（Compression Streams）\r压缩流用于将数据流中的内容压缩，常见的压缩格式包括 ZIP、GZIP、Deflate 等。Java 提供了以下几种压缩流：\nGZIPOutputStream：用于将数据流压缩为 .gz 格式。 ZipOutputStream：用于将多个文件压缩成 .zip 文件。 DeflaterOutputStream：用于将数据流压缩为 Deflate 格式。 示例：使用 GZIPOutputStream 进行压缩\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import java.io.*; import java.util.zip.GZIPOutputStream; public class GzipCompressionExample { public static void main(String[] args) { String inputFile = \u0026#34;example.txt\u0026#34;; String outputFile = \u0026#34;example.txt.gz\u0026#34;; try ( FileInputStream fis = new FileInputStream(inputFile); FileOutputStream fos = new FileOutputStream(outputFile); GZIPOutputStream gzipOS = new GZIPOutputStream(fos) ) { byte[] buffer = new byte[1024]; int len; while ((len = fis.read(buffer)) != -1) { gzipOS.write(buffer, 0, len); } System.out.println(\u0026#34;File successfully compressed.\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } } 2. 解压缩流（Decompression Streams）\r解压缩流用于读取和解压缩压缩文件。常见的解压缩流类包括：\nGZIPInputStream：用于解压缩 .gz 格式的文件。 ZipInputStream：用于解压缩 .zip 格式的文件。 InflaterInputStream：用于解压缩 Deflate 格式的文件。 示例：使用 GZIPInputStream 解压缩文件\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import java.io.*; import java.util.zip.GZIPInputStream; public class GzipDecompressionExample { public static void main(String[] args) { String inputFile = \u0026#34;example.txt.gz\u0026#34;; String outputFile = \u0026#34;example.txt\u0026#34;; try ( FileInputStream fis = new FileInputStream(inputFile); GZIPInputStream gzipIS = new GZIPInputStream(fis); FileOutputStream fos = new FileOutputStream(outputFile) ) { byte[] buffer = new byte[1024]; int len; while ((len = gzipIS.read(buffer)) != -1) { fos.write(buffer, 0, len); } System.out.println(\u0026#34;File successfully decompressed.\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } } 3. 使用 ZipOutputStream 压缩多个文件成一个 .zip 文件\rZipOutputStream 可以将多个文件压缩成一个 .zip 文件。每个文件会被封装成一个压缩条目（entry）。\n示例：压缩多个文件成 .zip\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import java.io.*; import java.util.zip.ZipEntry; import java.util.zip.ZipOutputStream; public class ZipCompressionExample { public static void main(String[] args) { String outputFile = \u0026#34;archive.zip\u0026#34;; String[] filesToZip = {\u0026#34;file1.txt\u0026#34;, \u0026#34;file2.txt\u0026#34;, \u0026#34;file3.txt\u0026#34;}; try ( FileOutputStream fos = new FileOutputStream(outputFile); ZipOutputStream zipOS = new ZipOutputStream(fos) ) { for (String fileName : filesToZip) { File file = new File(fileName); try (FileInputStream fis = new FileInputStream(file)) { ZipEntry zipEntry = new ZipEntry(file.getName()); zipOS.putNextEntry(zipEntry); byte[] buffer = new byte[1024]; int len; while ((len = fis.read(buffer)) != -1) { zipOS.write(buffer, 0, len); } zipOS.closeEntry(); } } System.out.println(\u0026#34;Files successfully zipped.\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } } 4. 解压 .zip 文件\rZipInputStream 用于读取 .zip 文件，提取每个条目（file entry）。\n示例：解压 .zip 文件\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import java.io.*; import java.util.zip.ZipEntry; import java.util.zip.ZipInputStream; public class ZipDecompressionExample { public static void main(String[] args) { String zipFile = \u0026#34;archive.zip\u0026#34;; String outputDir = \u0026#34;output/\u0026#34;; try (FileInputStream fis = new FileInputStream(zipFile); ZipInputStream zipIS = new ZipInputStream(fis)) { ZipEntry entry; while ((entry = zipIS.getNextEntry()) != null) { String fileName = entry.getName(); File outputFile = new File(outputDir + fileName); // 创建目录结构（如果需要） if (entry.isDirectory()) { outputFile.mkdirs(); } else { // 解压文件 try (FileOutputStream fos = new FileOutputStream(outputFile)) { byte[] buffer = new byte[1024]; int len; while ((len = zipIS.read(buffer)) != -1) { fos.write(buffer, 0, len); } } } zipIS.closeEntry(); } System.out.println(\u0026#34;Files successfully extracted.\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } } 5. 其他压缩与解压缩类\rDeflater 和 Inflater 类：它们分别实现了 Deflate 压缩算法的压缩和解压缩功能。\nDeflater 负责数据的压缩。 Inflater 负责数据的解压缩。 示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 import java.io.*; import java.util.zip.Deflater; import java.util.zip.Inflater; public class DeflateExample { public static void main(String[] args) throws IOException { String data = \u0026#34;This is the data that needs to be compressed using Deflate.\u0026#34;; // 压缩 byte[] compressedData = compress(data); System.out.println(\u0026#34;Compressed data: \u0026#34; + new String(compressedData)); // 解压 String decompressedData = decompress(compressedData); System.out.println(\u0026#34;Decompressed data: \u0026#34; + decompressedData); } private static byte[] compress(String data) throws IOException { Deflater deflater = new Deflater(); deflater.setInput(data.getBytes()); deflater.finish(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; while (!deflater.finished()) { int count = deflater.deflate(buffer); baos.write(buffer, 0, count); } baos.close(); return baos.toByteArray(); } private static String decompress(byte[] compressedData) throws IOException { Inflater inflater = new Inflater(); inflater.setInput(compressedData); ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; try { while (!inflater.finished()) { int count = inflater.inflate(buffer); baos.write(buffer, 0, count); } baos.close(); } catch (DataFormatException e) { e.printStackTrace(); } return baos.toString(); } } 总结\r在 Java 中，压缩和解压缩操作常常使用 java.util.zip 包中的类来实现：\nGZIPOutputStream 和 GZIPInputStream：用于 .gz 格式。 ZipOutputStream 和 ZipInputStream：用于 .zip 格式。 DeflaterOutputStream 和 InflaterInputStream：用于 Deflate 格式。 你可以根据需求选择合适的类来进行文件压缩和解压缩。\nCommons-io\rCommoms-io是apache提供的有关IO操作的工具包\n作用：提高IO流的开发效率\n","date":"2024-12-04T12:16:49+08:00","permalink":"https://fsj2009yx.github.io/posts/post_16852325024037/","title":"JAVA流对象"},{"content":"Java 类基础知识\rJava 是一种面向对象的编程语言，类是 Java 中的核心构建块之一。类用于定义对象的结构、属性和行为。Java 中的类可以包含字段（成员变量）、方法、构造方法、构造器以及其他成员。本文将介绍 Java 类的基础知识，包括类的定义、成员、构造方法和常见的类方法。\n1. Java 类的定义\rJava 类的定义包括类声明和类体。类体包含类的成员变量、构造方法和方法等。\n1.1 类的定义结构\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class ClassName { // 成员变量（字段） private int memberVariable; // 构造方法 public ClassName() { // 构造方法体 } // 成员方法 public void method() { // 方法体 } } class ClassName: class 关键字用于定义一个类，后面跟着类的名字。 成员变量: 类中的字段，通常用于存储类的状态。 成员方法: 类中的方法，定义类的行为。 构造方法: 用于创建类的实例（对象）。 2. 类的成员\r2.1 成员变量（字段）\r类的成员变量是定义在类中的变量，用于存储对象的状态。可以指定变量的访问修饰符，如 private、protected、public 等。\n1 2 3 4 public class Car { private String model; // 字段：存储模型 private int year; // 字段：存储年份 } 2.2 成员方法\r成员方法用于定义类的行为。方法可以有返回值类型，也可以没有返回值（即 void）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Car { private String model; private int year; // 方法：获取模型 public String getModel() { return model; } // 方法：设置模型 public void setModel(String model) { this.model = model; } } 返回类型: 方法可以返回一个值，例如 int、String，或者 void（没有返回值）。 参数: 方法可以有参数，也可以没有。 2.3 构造方法\r构造方法是类的特殊方法，用于初始化对象。当创建类的实例时，构造方法会自动调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Car { private String model; private int year; // 默认构造方法 public Car() { this.model = \u0026#34;Unknown\u0026#34;; this.year = 0; } // 带参数的构造方法 public Car(String model, int year) { this.model = model; this.year = year; } } 如果没有定义构造方法，Java 会自动提供一个默认构造方法。 构造方法没有返回类型，并且其名称与类名相同。 3. 访问修饰符\rJava 中有四种访问修饰符：\npublic: 公开访问，任何地方都可以访问。 protected: 受保护访问，仅限同包和子类访问。 private: 私有访问，仅限类内部访问。 default（无修饰符）：默认访问，仅限同包内访问。 示例\r1 2 3 4 5 public class MyClass { public int publicField; private int privateField; protected int protectedField; } publicField 可以被任何地方访问。 privateField 只能在 MyClass 类内部访问。 protectedField 可以在同一包中的类或继承 MyClass 的子类中访问。 4. 常见的类方法\r4.1 toString() 方法\rtoString() 方法是 Object 类中的一个方法，所有的 Java 类都会继承它。它通常被重写，以便输出对象的描述。\n1 2 3 4 5 6 7 8 9 public class Car { private String model; private int year; @Override public String toString() { return \u0026#34;Car model: \u0026#34; + model + \u0026#34;, Year: \u0026#34; + year; } } toString() 方法返回类的字符串表示，通常用于打印对象信息。 4.2 equals() 方法\requals() 方法用于比较两个对象是否相等。默认的 equals() 方法比较对象的引用，但可以根据需要重写它。\n1 2 3 4 5 6 7 8 9 10 11 12 public class Car { private String model; private int year; @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null || getClass() != obj.getClass()) return false; Car car = (Car) obj; return year == car.year \u0026amp;\u0026amp; model.equals(car.model); } } equals() 方法用于比较两个对象的内容是否相等，通常需要重写它。 4.3 hashCode() 方法\rhashCode() 方法用于返回对象的哈希码，它常常与 equals() 方法一起使用。当我们重写 equals() 方法时，通常也需要重写 hashCode() 方法。\n1 2 3 4 @Override public int hashCode() { return Objects.hash(model, year); } hashCode() 是为对象生成一个哈希值，常用于哈希数据结构（如 HashMap）中。 4.4 clone() 方法\rclone() 方法是 Object 类中的方法，用于创建并返回当前对象的一个副本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Car implements Cloneable { private String model; private int year; @Override public Car clone() { try { return (Car) super.clone(); } catch (CloneNotSupportedException e) { return null; } } } 如果类想要支持对象克隆，必须实现 Cloneable 接口。 5. 类的继承\rJava 支持类的继承。子类可以继承父类的成员变量和方法，并可以重写父类的方法来实现不同的行为。\n1 2 3 4 5 6 7 8 9 10 11 12 public class Vehicle { public void start() { System.out.println(\u0026#34;Vehicle is starting...\u0026#34;); } } public class Car extends Vehicle { @Override public void start() { System.out.println(\u0026#34;Car is starting...\u0026#34;); } } Car 类继承了 Vehicle 类，并重写了 start() 方法。 6. 静态成员\r6.1 静态变量\r静态变量是属于类而不是对象的变量。所有类的实例共享同一个静态变量。\n1 2 3 4 5 6 7 public class Car { public static int carCount = 0; // 静态变量 public Car() { carCount++; // 每创建一个实例，静态变量 carCount 增加 } } 静态变量使用 static 关键字声明，并且可以通过类名访问，例如 Car.carCount。 6.2 静态方法\r静态方法是属于类的，可以在没有创建对象的情况下调用。\n1 2 3 4 5 public class Car { public static void displayInfo() { System.out.println(\u0026#34;Car information...\u0026#34;); } } 静态方法通过 Car.displayInfo() 调用，而无需创建 Car 的实例。 总结\r类的定义：类包含成员变量、构造方法、方法等。 成员方法：定义类的行为，可以有返回类型和参数。 构造方法：用于初始化对象，构造方法的名称与类名相同。 访问修饰符：控制类成员的访问权限，如 public、private、protected 和默认修饰符。 常见类方法：toString()、equals()、hashCode()、clone() 等。 继承：子类可以继承父类的成员和方法，支持方法重写。 静态成员：静态变量和静态方法属于类，而不是实例。 Java 类是面向对象编程的基础，通过类可以创建对象，定义属性和行为，从而构建复杂的应用程序。\n","date":"2024-12-04T12:06:05+08:00","permalink":"https://fsj2009yx.github.io/posts/my-first-post/","title":"Java类基础"},{"content":"搜索结构\r搜索方法取决于搜索结构中数据元素的组织方式。例如，电话号码簿的搜索，可建立分类目录，采用分块（索引顺序）搜索；英汉词典是有序表，可采用折半搜索（或分块搜索）。\n搜索结构分为静态搜索结构和动态搜索结构\n平均搜索长度（ASL）\r搜索过程中关键码的平均比较次数或平均读写磁盘次数\n顺序搜索\r在顺序结构查找中，可以设置监视哨以减少搜索时间。\n监视哨是一个特殊的值，通常用于标记搜索的结束，避免了对数组边界的额外检查，从而简化了循环条件\n1 2 3 4 5 6 7 8 9 10 template \u0026lt;class E, class K\u0026gt; int searchList\u0026lt;E, K\u0026gt; :: SeqSearch(const K x) const { //顺序搜索关键码为x的数据元素, 第CurrentSize号位置 //作为控制搜索自动结束的“监视哨”使用 Element[CurrentSize].key=x; //设置“监视哨” int i=0; while (Element[i].key!=x) i++; //从前向后顺序搜索 if (i==CurrentSize) return 0; //搜索失败 else return i+1; //搜索成功 } 表中最后一个元素（即 Element[CurrentSize]）的关键字设置为目标值 x。这是典型的监视哨技术的实现。\n监视哨的作用是将目标值 x 放置到表的末尾，这样在执行顺序搜索时，无论目标值是否存在，都会在最后找到一个 key == x 的元素。这避免了在循环中每次都需要检查数组边界。\n例如，如果目标元素 x 存在于表中，那么它将出现在某个位置 i，并且当 i 达到 CurrentSize 时，循环自然会停止。\n顺序搜索递归算法\r1 2 3 4 5 6 7 8 template \u0026lt;class E, class K\u0026gt; int searchList\u0026lt;E, K\u0026gt;::SeqSearch1(const K x, int loc) const { //在搜索表中递归搜索其关键码与给定值x匹配的数据元素, //函数返回其表中位置。参数 loc 是在表中开始搜索位置，调用时赋初值1 if ( loc \u0026gt; CurrentSize ) return 0; //搜索失败 else if ( Element[loc-1].key == x ) return loc; //搜索成功 else return SeqSearch1( x, loc+1); //继续递归搜索 } 顺序搜索的平均搜索长度\r折半搜索\r折半搜索即二分查找，不多加以解释，附上代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 int binarySearch(vector\u0026lt;int\u0026gt; \u0026amp;arr, int left, int right, int target) { int mid; while (left \u0026lt; right) { mid = left + (right - left) / 2; if (arr[mid] == target) { return mid; // 找到 } else if (arr[mid] \u0026lt; target) // 说明在右边 { left = mid + 1; } else // 说明在左边 { right = mid; } } return -1; // 未找到 } 注意：在二分查找前必须保证顺序表是有序的，即按照递增或递减（代码中为递增）排列\nBST（Binary Search Tree）、AVL 树和红黑树（RB 树）的底层逻辑都基于折半搜索\n分块搜索\r分块查找，也称为块搜索或索引-顺序搜索，是一种常见的查找算法，主要用于在已排序的数据块或块中快速定位目标元素。它结合了顺序查找和二分查找的优点，并使得在大规模数据集中进行查找更加高效。\n分块查找的基本思想是将数据划分为多个块，并对每个块进行排序。\n分块查找的优点是在执行查找时可以跳过一些不必要的块，从而提高查找效率。它适用于静态数据集（即不经常更新的数据集）以及对内存敏感的应用程序。然而，由于需要预处理数据集，因此在数据集经常变化的情况下，它的效率可能会降低。\n算法工作流程\r分块预处理\n将数据分成多个块：首先，将整个数据集分成多个较小的块。每个块的大小相同，通常是一个固定的大小。例如，图中展示的将数据划分为 4 个块，每个块包含 5 个元素。 构建块的标识：为了加速搜索，可以为每个块记录一个块的最大值或最小值（通常是最大值），用作块的“代表值”。这些代表值将被用来决定哪个块可能包含目标元素。例如，图中每个块的最大值会被存储，以便快速定位可能的块。 块的选择\n首先使用代表值进行搜索：在搜索时，首先通过比较目标值 x 和每个块的代表值来确定目标值可能在哪个块中。也就是说，你首先检查目标值与各个块的代表值进行比较，寻找目标值所在的块。 定位目标块：例如，如果目标值 x 小于第一个块的最大值，但大于第二个块的最大值，则可以确定目标值在第二个块中。 在块内线性查找\n块内搜索：一旦确定目标值位于某个块内，接下来只需要对该块进行线性搜索（顺序查找）。由于块内的元素较少，线性查找相较于全局查找会更高效。 查找成功或失败：如果在块内找到目标元素，搜索成功。如果块内没有找到目标元素，则可以搜索下一个块，直到找到目标值或搜索结束。 代码示例\r定义一个方法利用分块查找，数据如下：{16, 5, 9, 12,21, 18, 32, 23, 37, 26, 45, 34, 50, 48, 61, 52, 73, 66}\n要求：查询某个元素是否存在\n代码如下（JAVA）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 package text.text02; /* 分块查找： 当数据表中的数据元素很多时，可以采用分块查找。汲取了顺序查找和折半查找各自的优点，既有动态结构，又适于快速查找 分块查找适用于数据较多，但是数据不会发生变化的情况。 分块查找的过程： 1. 需要把数据分成N多小块，块与块之间不能有数据重复的交集。 2. 给每一块创建对象单独存储到数组当中 3. 查找数据的时候，先在数组查，当前数据属于哪一块 4. 再到这一块中顺序查找 */ public class text10A { public static void main(String[] args) { //定义个数组存储所有元素 int[] arr = {16, 5, 9, 12, 21, 18, 32, 23, 37, 26, 45, 34, 50, 48, 61, 52, 73, 66}; //定义两个要查询的数（一个能查到，一个查不到） int number1 = 23; int number2 = 49; //创建块对象，将arr数组按照一定的规律分块(块内无序，块间有序) Block block1 = new Block(21, 0, 5); Block block2 = new Block(45, 6, 11); Block block3 = new Block(73, 12, 17); //定义数组，将块对象添加进数组 Block[] blocks = {block1, block2, block3}; System.out.println(\u0026#34;==========基本查找/顺序查找==========\u0026#34;); //调用judgeIndex1方法，判断要查询的数在块对象中的索引 （judgeIndex1方法用的是基本查找） int index1 = judgeIndex1(blocks, number1); int index2 = judgeIndex1(blocks, number2); //调用judgeNumber方法，根据judgeIndex1方法返回的索引判断要查询的数在该arr数组中是否存在 judgeNumber(arr, blocks, index1, number1); //23存在，该数在数组中的索引为：7 judgeNumber(arr, blocks, index2, number2); //49不存在 System.out.println(\u0026#34;==========二分查找/折半查找==========\u0026#34;); // 调用judgeIndex2方法，判断要查询的数在块对象中的索引 （judgeIndex2方法用的是折半查找/二分查找） int index3 = judgeIndex2(blocks, number1); int index4 = judgeIndex2(blocks, number2); //调用judgeNumber方法，根据judgeIndex2方法返回的索引判断要查询的数在该arr数组中是否存在 judgeNumber(arr, blocks, index1, number1); //23存在，该数在数组中的索引为：7 judgeNumber(arr, blocks, index2, number2); //49不存在 } //创建方法，判断要查询的数在哪块对象中，即在块对象中的索引（基本查找/顺序查找） public static int judgeIndex1(Block[] blocks, int number) { //利用循环遍历块对象数组，查找要查询的数的索引 for (int i = 0; i \u0026lt; blocks.length; i++) { //如果要查询的数小于该块对象中的最大值 if (number \u0026lt;= blocks[i].getMax()) { //返回该块对象的索引 return i; } } return -1; } //创建方法，判断要查询的数在哪块对象中，即在块对象中的索引（折半查找/二分查找） public static int judgeIndex2(Block[] blocks, int number) { //折半查找中的起始索引 int min = 0; //折半查找中的结束索引 int max = blocks.length - 1; //折半查找中的中间索引 int mid = (min + max) / 2; //利用循环查找要查找的数在块对象数组中的索引 while (true) { //如果起始索引小于结束索引，表明没找到 if (min \u0026lt; max) { return -1; } //如果要查找的数大于块对象数组中间索引的最大值 if (number \u0026gt; blocks[mid].getMax()) { min = mid + 1; } //如果要查找的数小于块对象数组中间索引-1的最小值 else if (number \u0026lt; blocks[mid - 1].getMax()) { max = mid - 1; } //如果要查找的数大于块对象数组中间索引-1的最小值并且小于块对象数组中间索引的最大值 else if (number \u0026lt; blocks[mid].getMax() \u0026amp; number \u0026gt; blocks[mid - 1].getMax()) { return mid; } } } //创建方法，判断要查找的数在judgeIndex块对象中已经确定的块对象区域中是否存在 public static void judgeNumber(int[] arr, Block[] blocks, int index, int number) { //index为blocks块对象数组中的索引 for (int i = blocks[index].getStartIndex(); i \u0026lt;= blocks[index].getEndIndex(); i++) { if (arr[i] == number) { System.out.println(number + \u0026#34;存在，该数在数组中的索引为：\u0026#34; + i); return; } } System.out.println(number + \u0026#34;不存在\u0026#34;); } } //创建块类 class Block { //定义一个变量记录每块中的最大值 private int max; //定义一个变量记录每块中的起始索引 private int startIndex; //定义一个变量记录每块中的结束索引 private int endIndex; public Block() { } public Block(int max, int startIndex, int endIndex) { this.max = max; this.startIndex = startIndex; this.endIndex = endIndex; } /** * 获取 * * @return max */ public int getMax() { return max; } /** * 设置 * * @param max */ public void setMax(int max) { this.max = max; } /** * 获取 * * @return startIndex */ public int getStartIndex() { return startIndex; } /** * 设置 * * @param startIndex */ public void setStartIndex(int startIndex) { this.startIndex = startIndex; } /** * 获取 * * @return endIndex */ public int getEndIndex() { return endIndex; } /** * 设置 * * @param endIndex */ public void setEndIndex(int endIndex) { this.endIndex = endIndex; } public String toString() { return \u0026#34;Block{max = \u0026#34; + max + \u0026#34;, startIndex = \u0026#34; + startIndex + \u0026#34;, endIndex = \u0026#34; + endIndex + \u0026#34;}\u0026#34;; } } 分块搜索性能分析\r二叉搜索树（BST）\rBST基本概念\r二叉搜索树的定义\r若它的左子树不空，则左子树上所有结点的值均小于它根结点的值。 若它的右子树不空，则右子树上所有结点的值均大于它根结点的值。 它的左、右树又分为⼆叉排序树 二叉搜索树的性质\r中序遍历该树可以按从小到大的顺序将各个结点的关键码排列起来。所以二叉搜索树也称为二叉排序树。\n（注：这可以作为判断一棵二叉树是否为二叉搜索树的方法！） 若从根结点到某个叶结点有一条路径，则路径上经过的结点的关键码不一定构成一个有序序列。\nBST搜索算法\r基本思想\r假设要搜索关键码为x的元素，先从根结点开始，如果根指针为空，则搜索失败；否则将给定值x与根结点的关键码进行比较：\n如果 x等于根结点的关键码，则搜索成功，返回搜索到的结点地址；\n如果 x小于根结点的关键码，则在左子树中继续搜索；\n如果 x大于根结点的关键码，则在右子树中继续搜索。\n二叉搜索树的效率就在于只需搜索两个子树之一。\n给出递归和非递归代码：\n递归实现：\n1 2 3 4 5 6 7 8 9 10 template \u0026lt;class E, class K\u0026gt; BSTNode\u0026lt;E, K\u0026gt; *BST\u0026lt;E, K\u0026gt; :: Search( const K x, BSTNode\u0026lt;E, K\u0026gt; *ptr) { //私有函数：在以ptr为根的二叉搜索树中递归搜索结点x if ( ptr == NULL ) return NULL; //搜索失败 else if (x \u0026lt; ptr-\u0026gt;data ) //在左子树搜索 return Search( x, ptr-\u0026gt;left );\telse if ( x \u0026gt; ptr-\u0026gt;data ) //在右子树搜索 return Search( x, ptr-\u0026gt;right );\telse return ptr; //相等，搜索成功 } 非递归实现：\n1 2 3 4 5 6 7 8 9 10 template \u0026lt;class E, class K\u0026gt; BSTNode\u0026lt;E, K\u0026gt; *BST\u0026lt;E, K\u0026gt; :: Search( const K x, BSTNode\u0026lt;E, K\u0026gt; *ptr) const { //二叉搜索树的迭代的搜索算法 BSTNode\u0026lt;E, K\u0026gt; *p = ptr; //从根开始搜索 while ( p != NULL ) if ( x == p-\u0026gt;data ) return p; //搜索成功 else if ( x \u0026lt; p-\u0026gt;data ) p = p-\u0026gt;left; //沿左子树搜索 else p = p-\u0026gt;right; //沿右子树搜索 return p; //搜索失败 } BST插入算法\r基本思想\r若要在二叉搜索树中插入一个新元素，首先要使用搜索算法检查该元素在树中是否存在； 如果搜索成功，树中已有这个元素，不再插入； 如果搜索不成功，则生成新元素结点，把新结点作为叶结点插入到搜索操作停止的地方。 插入实际是先搜索，再插入的过程\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 TreeNode* insert(TreeNode* node, const string\u0026amp; key, const string\u0026amp; value) { // 如果树为空，直接返回新节点作为根节点 if (node == nullptr) { return new TreeNode(key, value); } TreeNode* cur = node; while (cur != nullptr) { // 如果键小于当前节点的键，向左子树插入 if (key \u0026lt; cur-\u0026gt;key) { // 如果左子节点为空，则插入 if (cur-\u0026gt;left == nullptr) { cur-\u0026gt;left = new TreeNode(key, value); return node; // 返回根节点 } cur = cur-\u0026gt;left; // 否则继续向左子树移动 } // 如果键大于当前节点的键，向右子树插入 else if (key \u0026gt; cur-\u0026gt;key) { // 如果右子节点为空，则插入 if (cur-\u0026gt;right == nullptr) { cur-\u0026gt;right = new TreeNode(key, value); return node; // 返回根节点 } cur = cur-\u0026gt;right; // 否则继续向右子树移动 } // 如果键相等，更新节点的值 else { cur-\u0026gt;value = value; return node; // 返回根节点 } } return node; // 返回根节点 } BST删除算法\r删除就稍微比查找与插入复杂一点，因为需要分类讨论了。\n被删除结点为叶子结点\r直接从二叉排序中删除即可，不会影响到其他结点\n被删除结点D仅有一个孩子\r如果只有左孩子，没有右孩子，那么只需要把要删除结点的左孩子连接到要删除结点的父亲结点，然后删除D结点； 如果只有右孩子，没有左孩子，那么只要将要删除结点D的右孩子连接到要删除结点D的父亲结点，然后删除D结点。 被删除结点左右孩子都在\r当前节点有两个子节点，找到右子树的最小节点替代当前节点\n以图示流程帮助理解：\n我们的目标依然是要保证删除结点8后，再次中序遍历它，仍不改变其升序的排列方式。 那么我们只有用7或者10来替换8原来的位置。\n我们先看7来顶替位置\n我们再看10来顶替位置\n由图得知，用7和用10顶替被删除节点的位置都是可行的\n即使用待删除结点下右子树的最小结点或左子树的最大结点\n也就是与待删除结点大小最接近的两个结点\n为遵循一般习惯，我们通常使用右子树的最小结点来顶替待删除结点\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 TreeNode* remove(TreeNode* node, const string\u0026amp; key) { if (node == nullptr) { return nullptr; } if (key \u0026lt; node-\u0026gt;key) { node-\u0026gt;left = remove(node-\u0026gt;left, key); } else if (key \u0026gt; node-\u0026gt;key) { node-\u0026gt;right = remove(node-\u0026gt;right, key); } else { // 当前节点是要删除的节点 if (node-\u0026gt;left == nullptr) { TreeNode* temp = node-\u0026gt;right; delete node; return temp; } else if (node-\u0026gt;right == nullptr) { TreeNode* temp = node-\u0026gt;left; delete node; return temp; } // 当前节点有两个子节点，找到右子树的最小节点替代当前节点 TreeNode* temp = minNode(node-\u0026gt;right); node-\u0026gt;key = temp-\u0026gt;key; node-\u0026gt;value = temp-\u0026gt;value; node-\u0026gt;right = remove(node-\u0026gt;right, temp-\u0026gt;key); } return node; } BST性能分析\rBST的性能与二叉搜索树的形态直接相关\n因此我们要尽量控制对节点元素的插入顺序，避免其退化成单支树\nASL的计算：\nASL的计算公式如下：\n成功的平均搜索长度($ASL_{succ}$) = $\\frac{1}{n}\\sum_{i=1}^{n} (树的深度)*(当前深度下节点的个数)$ 失败的平均搜索长度($ASL_{unsucc}$) = $\\frac{1}{n+1}\\sum_{i=1}^{n+1} (搜索失败节点的深度)*(当前深度下搜索失败节点的个数)$ 由图，以搜索失败的ASL来解释，由于搜索失败只会在子节点出现：\n第三层的失败节点个数为3 第四层的失败节点为4 由公式得5×3+6×4，除以（n+1），得到搜索失败的平均搜索长度。\n平衡二叉搜索树（AVL树）\r由于二叉搜索树BST的性能受输入顺序影响，当输入顺序不好时会让BST退化\n而AVL树在每一次插入后都会调整树的结构，以达到高度平衡化\nAVL树的性质\r当我们向二叉搜索树中插入新节点时，如果能用某种方法时刻保证树中每个节点的左右子树高度之差不超过1，就可以降低整棵树的高度，保证每条分支的平衡\nAVL树的性质如下：\nAVL树可以是空树 一颗AVL树的左右子树都是AVL树 一颗AVL树的左右子树高度差不超过1 结点的平衡因子（bf）\rAVL树的左右子树高度差不能超过1，但是如何便捷的去检测该性质是否被打破呢？\n我们可以在节点中定义一个平衡因子：如果左子树比右子树高一层，那么平衡因子就为-1；如果左右子树一样高，平衡因子就为0；如果右子树比左子树高一层，那么平衡因子就为1，这三种情况下AVL树的性质都没有被打破。\n按照这个规则，如果平衡因子为-2、2或其他值，则说明左右子树已经失衡，性质被打破。\n在调整失衡的AVL树时，我们需要频繁的访问父节点，所以在AVL树中我们需要使用三叉链，因此AVL树的节点除了包含左右子节点的指针，还需要一个指向父节点的指针。\n平衡化旋转\r平衡化旋转有两类：\n单旋转（左单旋和右单旋）\n双旋转（先左后右双旋和先右后左双旋）\n如果这三个结点处于一条直线（不平衡情况为LL型和RR型）上，则采用单旋转进行平衡化。\n如果这三个结点处于一条折线（不平衡情况为LR型和RL型）上，则采用双旋转进行平衡化。\n单旋转\r以**LL型（右单旋转）**为例：\n操作步骤：\n选择根节点的左子节点作为新的根节点。 根节点变为新的根节点的右子节点。 原来左子节点的右子树变为新根节点的左子树。 图示如下：\n右单旋转的示例代码如下：\n1 2 3 4 5 6 7 8 9 10 template \u0026lt;class E, class K\u0026gt; void AVLTree\u0026lt;E, K\u0026gt; :: RotateR ( AVLNode\u0026lt;E, K\u0026gt; *\u0026amp; ptr ) { //对以ptr为根的AVL树做右单旋转，旋转后新根在ptr AVLNode\u0026lt;E, K\u0026gt; *subR = ptr; //保存要右旋的根结点 ptr = subR-\u0026gt;left; //ptr指向原根的左子女 subR-\u0026gt;left = ptr-\u0026gt;right; //ptr成为新根前卸掉右边负载 ptr-\u0026gt;right = subR; //右单旋转：ptr成为新根，原根成为ptr的右子女 ptr-\u0026gt;bf = subR-\u0026gt;bf = 0; } **RR型（左单旋转）**的算法与LL型同理，不多解释\n双旋转\r以**LR型（先左后右双旋转）**为例：\n左右旋操作用于解决左子树的右子树过高的问题（称为左右情况）。这是一个复合旋转，先进行左旋，再进行右旋。\n操作步骤：\n首先对左子节点进行左旋（使得左子节点的右子树下降）。 然后对当前根节点进行右旋。 图示如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 void RotateLR(Node *parent) { Node *subL = parent-\u0026gt;_left; Node *subLR = subL-\u0026gt;_right; int bf = subLR-\u0026gt;_bf; //记录插入节点后subLR的平衡因子 RotateLeft(subL); //先左单旋 RotateRight(parent); //再右单旋 //更新平衡因子 //通过前面记录的平衡因子判断更新的情况 if (bf == 0) { parent-\u0026gt;_bf = subL-\u0026gt;_bf = subLR-\u0026gt;_bf = 0; } else if (bf == 1) { subL-\u0026gt;_bf = -1; parent-\u0026gt;_bf = subLR-\u0026gt;_bf = 0; } else if (bf == -1) { parent-\u0026gt;_bf = 1; subL-\u0026gt;_bf = subLR-\u0026gt;_bf = 0; } else { assert(false); } } AVL的插入算法\rAVL树的删除算法\rAVL树的删除与BST类似，也是先搜索再删除\n只是当删除完结点后可能破坏原本的平衡，此时还需做平衡化处理\nm路搜索树\r二叉搜索树适合于组织在内存中的较小的索引（或目录）。对于存放在外存中的较大的文件系统\n对于存放在外存中的较大的文件系统，用二叉搜索树来组织索引就不太合适。若以结点作为内外存交换的单位，则在搜索过程中需对外存进行**O(log2n)**次访问，显然很费时\n于是我们引入多路搜索树：\n多路搜索树既可能是静态索引结构，也可能是动态索引结构 现在所讨论的 m 路搜索树多为可以动态调整的多路搜索树，即树的结构随数据的增删及时调整，以保持最佳的搜索效率 m路搜索树基本概念\rm路搜索树的定义\rm 叉搜索树（m-way search tree）可以是一棵空树，如果非空，它必须满足以下特征：\n在相应的扩充搜索树中（用外部节点替换零指针），每个内部节点最多可以有m 个子女及1～m-1个元素（外部节点不含元素和子女）。 每个含p个元素的节点，有p+1个子女。 考察含p 个元素的任意节点。设k1 , …, kp 是这些元素的关键值。这些元素升序排列，即有k1 \u0026lt; k2 \u0026lt; . . . \u0026lt;kp。设c0 , c1 , …, cp 是节点的p+1个孩子。以c0 根的子树中的元素关键值小于k1，而以cp 为根的子树中的元素关键值大于kp，并且以ci 为根的子树中的元素关键值会大于ki 而小于ki+1，其中1≤i≤p。 m路搜索树的示例如下：\nm路搜索树的性质\r由于高度为h的m叉搜索树中元素的个数在$h$到$m^{h} - 1$之间，所以一棵n元素的m叉搜索树的高度在$\\log_m(n+1)$到$n$之间。\nm路搜索树的搜索算法\r在 m 路搜索树上的搜索过程是一个在结点内搜索和自根结点开始循某一条路径向下一层结点搜索的交替的过程。 结点内的搜索一般采用顺序搜索，当m较大时，可采用折半搜索。 搜索算法的基本思路如下：\n开始于根节点： 搜索从树的根节点开始进行。 逐层比较： 在每个节点，首先检查节点的关键字（存储的值）。 比较目标值与当前节点的所有关键字。 选择子节点： 如果目标值等于某个关键字，搜索结束，找到目标值。 如果目标值小于当前节点的最小关键字，进入第一个子树。 如果目标值介于两个关键字之间，进入相应的子树（例如，第 $i$ 个关键字和第 $i+1$ 个关键字之间）。 如果目标值大于某个关键字，选择右边的子树。 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 template \u0026lt;class T\u0026gt; Triple\u0026lt;T\u0026gt; Mtree\u0026lt;T\u0026gt; :: Search ( const T\u0026amp; x ) { //用关键码x搜索驻留在磁盘上的m路搜索树，函数返回类型为三元组（r, i, tag） Triple result; //记录搜索结果三元组 GetNode ( root ); //从磁盘读入根结点（内外存数据交换，非常耗时） MtreeNode \u0026lt;T\u0026gt; *p = root, *q = NULL; //q是p的父结点指针 while ( p != NULL ) { //从根开始检测 int i = 0; p-\u0026gt;key[(p-\u0026gt;n)+1] = MaxValue; //监视哨 while ( p-\u0026gt;key[i+1] \u0026lt; x ) i++; //结点内顺序搜索 if ( p-\u0026gt;key[i+1] == x ) { //搜索成功 result.r = p; result.i = i+1; result.tag = 0; return result; } //本结点无x，q记下本结点 q = p; p = p-\u0026gt;ptr[i]; // p向下一层结点搜索 GetNode (p); //从磁盘上读入该结点（内外存数据交换，非常耗时） } result.r = q; result.i = i; result.tag = 1; //x可能落入q结点的区间[ki, ki+1] return result; //搜索失败，返回插入位置 } m路搜索树的搜索性能\rB-树\r**m树B树（B-Tree of order m）**是一棵m叉搜索树，如果B树非空，那么相应的扩充树满足以下特征：\n根节点至少有两个孩子 除了根节点以外，所有内部节点至少有[m/2]个孩子 所有外部节点位于同一层上，叶节点不包含任何关键字信息 每个节点至多有m个孩子 有k个孩子的非叶节点恰好包含k-1个关键字 一棵B 树是平衡的 m 路搜索树，但一棵平衡的 m 路搜索树不一定是B 树。\n我们以七阶B树为例：\n由其余非失败结点至少有 n（[m/2]≤n≤m）棵子树。这条性质，对$m/2$向上取整得到每个节点中至少4个孩子 且失败节点全部挂载在子节点上\n一些特殊的m阶B树：\n二阶B-树：满二叉树 三阶B-树：内部可以有2个或者3个孩子，也叫做2-3树 四阶B-树：内部可以有2个、3个或者4个孩子，也叫做2-3-4树 其中红黑树就是四阶B-树的一种\nB树搜索性能\rm值的选择：应使得在B树中找到关键码x的时间总量达到最小\n如果提高B树的阶数m，可以减少树的高度，从而减少读入节点的次数 m受到内存可使用空间的限制，所以m的值不能很大 B树插入算法\rB树是从空树起，逐个插入关键码而形成的;\n插入关键码时，首先要调用搜索算法，若搜索成功，则不能插入；若搜索失败，则得到要插入的节点的地址\n这里我们分两种情况：\n若找到的结点关键码个数少于m-1，直接插入； 若找到的结点已经饱和，插入后结点中的关键码个数超出了上界 m-1 ，则该结点需要**“分裂”** 结点“分裂”\r设结点 p 中已经有 m-1 个关键码，当再插入一个关键码后结点的状态为( m, P0, K1, P1, K2, P2, ……, $K_m$, $P_m$)；\n由于每个结点最多m棵子树，m-1个关键码，再插入关键码后我们必须对结点进行**“分裂“**操作以维持B树的正确结构\n分裂操作的步骤如下：\n例如：一棵三阶B-树的某个子结点内有53,75两个关键码 此时插入关键码139，关键码个数溢出了，我们对其分裂：\n将结点分裂成两个结点p和q，p结点的关键码为$P_0$到$P_{[m/2]-1}$，q结点为$P_{[m/2]}$到$P_m$ 该节点按照上面的规则，分为53和139两个子结点挂载在75结点的上面，75即原先未分裂的结点的位置 B树删除算法\r在B树上删除一个关键码时，若结点中所剩关键码个数少于下限，要考虑结点的调整或合并问题\nB树的删除步骤如下：\n首先调用搜索算法，找到要删除的关键码所在的结点, 从中删去这个关键码\n若该结点不是叶结点，且被删关键码为 $K_i$，1≤i≤n，则在删去该关键码之后，应**以该结点 $P_i$ 所指示子树中的最小关键码（或以$P_{i-1}$ 所指示子树中的最大关键码 $x$ **来代替被删关键码 $K_{i}$ 所在的位置\n在 x 所在的叶结点中删除 x\n关键码删除的三种情况\r情况1：被删关键码所在叶结点同时又是根结点，且删除前该结点中关键码个数 n≥2：\n直接删去该关键码即可 情况2：被删关键码所在叶结点不是根结点，且删除前该结点中关键码个数 n≥[m/2]\n同理，直接删除 情况3：被删关键码所在叶结点删除前关键码个数n=[m/2]-1，若这时与该结点相邻的右兄弟 (或左兄弟) 结点的关键码个数n≥[m/2]；\n我们需要按以下步骤调整该结点、右兄弟 (或左兄弟) 结点以及其双亲结点，以达到新的平衡\n将双亲结点中刚刚大于 (或小于) 该被删关键码的关键码 $K_i$ (1≤i≤n) 下移 将右兄弟 (或左兄弟) 结点中的最小 (或最大)关键码上移到双亲结点的 $K_i$ 位置 将右兄弟 (或左兄弟) 结点中的最左 (或最右) 子树指针平移到被删关键码所在结点中最后 (或最前) 子树指针位置 在右兄弟 (或左兄弟) 结点中，将被移走的关键码和指针位置用剩余的关键码和指针填补、调整。再将结点中的关键码个数减1 文字上可能不好理解，我们结合图示来解释：\n如果我们删除65关键码，该位置结点的关键码个数变为0，此时我们在兄弟结点（这里取右兄弟）中的最小关键码75上移到父节点$c$中，在$c$中下移最接近65但比65的关键码70到空子节点g中\n注意：这里取的是右兄弟的结点，所以使用的是右兄弟节点中的最小关键码；\n如果选择左兄弟节点，则按删除规则，与之相反\n给出删除关键码的另一种情况：\n这里由于右兄弟结点只有一个关键码80，所以我们选取左兄弟结点f，按照删除规则完成删除操作\n情况4：结点合并：\n简单记忆，若按前三种删除操作不能达成维持B树结构的目的时，采用合并操作\n依旧以图示说明：\n如果我们直接删除关键码55，由于父结点中的58小于60，不符合B-树的条件；而采用情景3中的方法将60上移，58或者75下移更是不可能的，因此我们采取合并操作：\n首先删除55，剩下60和80 将父节点中最接近但是大于待删除关键码的关键码58下移并与60进行合并 下面是另一种情况：\n可以看到，这里选取的是父结点中最接近但是小于待删除关键码的关键码\n删除的关键在于，能否在删除调整后维持B-树的正常结构，因为B-树是高度平衡化的，每个关键码的位置相对比较固定，不会因插入顺序变化而太多改变。维持B-树的正常结构可以作为删除操作的方法，也可以作为检查手段\n下面用文字举例B树中关键码删除的流程：\n假设我们有一棵3阶B树（每个节点最多有2个关键码和3个子节点，至少有1个关键码），树的结构如下：\n1 2 3 [10 | 20] / | \\ [5] [15] [25 | 30] 我们尝试删除关键码20。\n1. 找到要删除的关键码位置\r在树中定位到20的位置。20位于根节点中，是一个内部节点。\n2. 判断关键码类型\r删除操作分两种情况：\n情况1：关键码在叶子节点中 如果20在叶子节点中，直接删除即可，同时检查节点是否仍满足最小关键码数要求。 情况2：关键码在内部节点中 这是当前情况。需要找到20的前驱关键码或后继关键码来替代它。 3. 替换关键码\r选择一个子树中最大的关键码作为前驱，或选择一个子树中最小的关键码作为后继。\n在这个例子中：\n前驱关键码：子树[15]的最大值为15。 后继关键码：子树[25 | 30]的最小值为25。 我们选择用25替代20。 B树现在变为：\n1 2 3 [10 | 25] / | \\ [5] [15] [30] 4. 删除前驱或后继关键码\r从相应的子树中删除25（这是一次递归删除操作）。 在此例中，25在叶子节点中，直接删除，最终树结构为：\n1 2 3 [10 | 25] / | \\ [5] [15] [30] B+树\rB+树的定义如下：\nB+树真的不难，楼下菜大爷都能学得会的B+树！（数据结构可视化神器推荐）_数据结构b+树可视化-CSDN博客\n","date":"2024-12-03T22:24:25+08:00","permalink":"https://fsj2009yx.github.io/posts/post_114514/","title":"搜索结构"}]